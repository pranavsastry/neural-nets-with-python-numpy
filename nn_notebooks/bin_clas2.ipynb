{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bin_clas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWIr65IilAMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3f0a4a84-50fb-4a79-95ff-6bd53220a7aa"
      },
      "source": [
        "#Importing libraries\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import pyplot\n",
        "from pandas import DataFrame"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R7vIDz5moGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "dc10a20d-09ab-44b1-9024-98fe416b3ad8"
      },
      "source": [
        "\"\"\"\n",
        "    DATA PREPARATION\n",
        "      > Loading the dataset and splitting it into train, cross validation and test sets\n",
        "      > The inputs are to be in the format of X.shape = (number_of_examples, number_of features)\n",
        "      > The outputs are to be in the format of y.shape = (number_of_output_units, number_of_examples)\n",
        "\"\"\"\n",
        "\n",
        "N_SAMPLES = 1000\n",
        "TEST_SIZE = 0.1\n",
        "X, y = make_moons(n_samples = N_SAMPLES, noise=0.2, random_state=100)\n",
        "X_tr, X_te, y_tr_t, y_te_t = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
        "y_tr_t = y_tr_t.reshape(y_tr_t.shape[0],1)\n",
        "y_te_t = y_te_t.reshape(y_te_t.shape[0],1)\n",
        "m_tr = y_tr_t.shape[0]\n",
        "m_te = y_te_t.shape[0]\n",
        "y_tr = y_tr_t.T\n",
        "y_te = y_te_t.T\n",
        "\n",
        "\n",
        "#Plotting the data\n",
        "\n",
        "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
        "colors = {0:'red', 1:'blue'}\n",
        "fig, ax = pyplot.subplots()\n",
        "grouped = df.groupby('label')\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "pyplot.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1V3Z1HpokA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    ACTIVATION FUNCTIONS\n",
        "      > Defining the activation functions for the neural network. Note here that \n",
        "         the \"tanh\" activation function is implemented as \"tang(x)\"\n",
        "\"\"\"\n",
        "\n",
        "def sigmoid(x):\n",
        "  return (1/(1+np.exp(-x)))\n",
        "def relu(x):\n",
        "    return np.maximum(0,x)\n",
        "def tang(x):\n",
        "  return np.tanh(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pR71Fydolfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    DEFINING UNITS AND ACTIVATION FUNCTIONS\n",
        "      > Here the number of units in each layer and as a result the number of layers\n",
        "         in our neural network is defined in a Python list \"layer_dims\"\n",
        "      > Activation functions for each of the layers is also defined in the Python\n",
        "         list \"act_fn\"\n",
        "      > Note here that the length of act_fn is one less than that of the length of\n",
        "         layer_dims\n",
        "\"\"\"\n",
        "\n",
        "layer_dims = [X_tr.shape[1],4,6,6,5,1]\n",
        "act_fn = [\"tang\",\"tang\",\"tang\",\"tang\",\"sigmoid\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqvuIXEDo2Ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    INITIALISING THE PARAMETERS\n",
        "      > The parameters of the neural network are 1.Weights and 2.Bias and these\n",
        "         parameters are tweaked while training the network. \n",
        "      > Weights and bias for each of the layers(excluding the input layer) are\n",
        "         initialised randomly and special weight initialisation techniques are\n",
        "         used depending on the activation function of the layer.\n",
        "      > Weights and bias are stored in the Python dictionary \"parameters\" and the\n",
        "         weights of the ith layer are stored by keyword Wi and the bias in bi\n",
        "      > Wi.shape = (number_of_units_in_(i-1)th_layer, number_of_units_in_(i)th_layer)\n",
        "      > bi.shape = (number_of_units_in_(i)th_layer,1)\n",
        "      > Arguments - layer_dims,act_fn\n",
        "\"\"\"\n",
        "\n",
        "def initialize_parameters(layer_dims,activation_fn):\n",
        "  parameters = {}\n",
        "  relu_init = 2\n",
        "  tang_init = 1\n",
        "  for i in range(1,len(layer_dims)):\n",
        "    if activation_fn[i-1] is \"relu\":\n",
        "      initi = relu_init\n",
        "    if activation_fn[i-1] is \"tang\":\n",
        "      initi = tang_init\n",
        "    parameters[\"W\"+str(i)] = np.random.randn(layer_dims[i],layer_dims[i-1])*np.sqrt(initi/layer_dims[i-1])\n",
        "    parameters[\"b\"+str(i)] = np.random.randn(layer_dims[i],1)*0.01\n",
        "  return parameters"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2szTq5wmo4OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    FORWARD PROPAGATION\n",
        "      > The forward propagation makes a forward pass through the neural net. The\n",
        "         outputs of all the layers are computed and then the activation\n",
        "         for that particular layer is calculated.\n",
        "      > The python dictionaries \"outputs\" are used to store the output of the dot\n",
        "         product between the weights and the inputs and \"activations\" are used to\n",
        "         store the activations of the outputs of that layer\n",
        "      > The \"outputs\" contain keywords of the format Zi for the outputs of the ith\n",
        "         layer and the \"activations\" contain keywords of the format Ai for the activations\n",
        "         of the ith layer based on its activations as specified in \"acts_fn\"\n",
        "      > The input data is also stored in A0 and is handy for back propagation\n",
        "      > Arguments - Input_Data, parameters, activation_fn\n",
        "\"\"\"\n",
        "\n",
        "def forw_prop(X,parameters,activation_fn):\n",
        "  outputs = {}\n",
        "  activations = {}\n",
        "  A_prev = X.T\n",
        "  for i in range(1,len(layer_dims)):\n",
        "    if activation_fn[i-1] is \"relu\":\n",
        "      activ = relu\n",
        "    if activation_fn[i-1] is \"tang\":\n",
        "      activ = tang\n",
        "    if activation_fn[i-1] is \"sigmoid\":\n",
        "      activ = sigmoid\n",
        "    outputs[\"Z\" + str(i)] = np.dot(parameters[\"W\" + str(i)],A_prev) + parameters[\"b\"+str(i)]\n",
        "    activations[\"A\" + str(i)] = activ(outputs[\"Z\" + str(i)])\n",
        "    A_prev = activations[\"A\" + str(i)]\n",
        "  \"\"\"A_prev = activations[\"A\" + str(len(layer_dims)-2)]\n",
        "  if activation_fn[len(layer_dims)-2] is \"relu\":\n",
        "    activ = relu\n",
        "  if activation_fn[len(layer_dims)-2] is \"tang\":\n",
        "    activ = tang\n",
        "  if activation_fn[len(layer_dims)-2] is \"sigmoid\":\n",
        "    activ = sigmoid\n",
        "  outputs[\"Z\" + str(len(layer_dims)-1)] = np.dot(parameters[\"W\" + str(len(layer_dims)-1)],A_prev) + parameters[\"b\"+str(len(layer_dims)-1)]\n",
        "  activations[\"A\" + str(len(layer_dims)-1)] = activ(outputs[\"Z\" + str(len(layer_dims)-1)])\"\"\"\n",
        "  activations[\"A0\"] = X.T\n",
        "  return outputs,activations"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgTZNoBko6H7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    COST FUNCTION\n",
        "      > Cost function is calculated using the activations of the final layer of\n",
        "         the network and the ground truth y\n",
        "      > Arguments - activation, y, number_of_examples\n",
        "\"\"\"\n",
        "\n",
        "def cost_func(A,y,m_ex):\n",
        "  cost = ((-1/m_ex)*(np.sum(np.sum((y*np.log(A)) + ((1-y)*np.log(1-A))))))\n",
        "  return cost"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMhW4VMNo-Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    GRADIENTS OF ACTIVATION FUNCTIONS\n",
        "      > Here the gradients of the activation functions are defined.\n",
        "      > This calculates the derivative of the activation of the ith layer to the\n",
        "         outputs of the ith layer\n",
        "      > Arguments - outputs Z\n",
        "\"\"\"\n",
        "\n",
        "def sigmoid_backward(z):\n",
        "  grad_back = np.exp(-z)/np.square(1+np.exp(-z))\n",
        "  return grad_back\n",
        "def relu_backward(x):\n",
        "  x[x<=0] = 0\n",
        "  x[x>0] = 1\n",
        "  return x\n",
        "def tang_backward(x):\n",
        "  return (1 - np.square(np.tanh(x)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5plu3-apArP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    PREDICTIONS\n",
        "      > The predictions for the outputs of the network are calculated given a\n",
        "         threshold value for predicting the class of the input data according to\n",
        "         the parameters learned by the network.\n",
        "      > Arguments - A(Activations),threshold_for_classification\n",
        "\"\"\"\n",
        "\n",
        "def predict(A,threshold):\n",
        "  predictions = np.zeros((A.shape))\n",
        "  for i in range(0,A.shape[0]):\n",
        "    for j in range(0,A.shape[1]):\n",
        "      if A[i,j]>threshold:\n",
        "        predictions[i,j]=1\n",
        "      else:\n",
        "        predictions[i,j]=0\n",
        "  return predictions"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSfxmf6TpFGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    FIT\n",
        "      > This function is used to train the network on training data and the weights\n",
        "         are updated by backpropagation through Optimization functions (Gradient descent,RMSprop,Adam)\n",
        "      > Returns \"costs\" a Python list consisting of all the costs through the iterations\n",
        "         and the updated \"parameters\" dictionary\n",
        "      > Arguments - X(train),Y(train),number_of_training_examples,number_of_iterations,\n",
        "         learning_rate,parameters,activation_fn,print_cost(True/False),callback\n",
        "\"\"\"\n",
        "\n",
        "def fit(X,Y,m_ex,num_iterations,alpha,parameters,activation_fn,print_cost,callback=None):\n",
        "  costs = []\n",
        "  p = 0\n",
        "  for i in range(1,num_iterations+1):\n",
        "    grads = {}\n",
        "    outputs,activations = forw_prop(X,parameters,activation_fn)\n",
        "    cost = cost_func(activations[\"A\" + str(len(layer_dims)-1)],Y,m_ex)\n",
        "    costs.append(cost)\n",
        "    predictions = predict(activations[\"A\" + str(len(layer_dims)-1)],0.5)\n",
        "    if activation_fn[len(layer_dims)-2] is \"relu\":\n",
        "      backward = relu_backward\n",
        "    if activation_fn[len(layer_dims)-2] is \"tang\":\n",
        "      backward = tang_backward\n",
        "    if activation_fn[len(layer_dims)-2] is \"sigmoid\":\n",
        "      backward = sigmoid_backward\n",
        "    grads[\"dA\" + str(len(layer_dims)-1)] = (1/m_ex)*(((1-Y)/(1-activations[\"A\" + str(len(layer_dims)-1)])) - (Y/activations[\"A\" + str(len(layer_dims)-1)]))\n",
        "    grads[\"dZ\" + str(len(layer_dims)-1)] = grads[\"dA\" + str(len(layer_dims)-1)]*backward(outputs[\"Z\" + str(len(layer_dims)-1)])\n",
        "    grads[\"dW\" + str(len(layer_dims)-1)] = np.dot(grads[\"dZ\" + str(len(layer_dims)-1)],activations[\"A\" + str(len(layer_dims)-2)].T)\n",
        "    grads[\"db\" + str(len(layer_dims)-1)] = np.sum(grads[\"dZ\" + str(len(layer_dims)-1)],axis=1,keepdims=True)\n",
        "    for j in reversed(range(1,len(layer_dims)-1)):\n",
        "      if activation_fn[j-1] is \"relu\":\n",
        "        backward = relu_backward\n",
        "      if activation_fn[j-1] is \"tang\":\n",
        "        backward = tang_backward\n",
        "      if activation_fn[j-1] is \"sigmoid\":\n",
        "        backward = sigmoid_backward\n",
        "      grads[\"dA\" + str(j)] = np.dot(parameters[\"W\" + str(j+1)].T,grads[\"dZ\" + str(j+1)])\n",
        "      grads[\"dZ\" + str(j)] = grads[\"dA\" + str(j)]*backward(outputs[\"Z\" + str(j)])\n",
        "      grads[\"dW\" + str(j)] = np.dot(grads[\"dZ\" + str(j)],activations[\"A\" + str(j-1)].T)\n",
        "      grads[\"db\" + str(j)] = np.sum(grads[\"dZ\" + str(j)],axis=1,keepdims=True)\n",
        "    for k in range(1,len(layer_dims)):\n",
        "      parameters[\"W\" + str(k)] -= (alpha*(grads[\"dW\" + str(k)]))\n",
        "      parameters[\"b\" + str(k)] -= (alpha*(grads[\"db\" + str(k)]))\n",
        "    if print_cost is True:\n",
        "      print(\"Cost after iteration \" + str(i) + \" is \" + str(costs[p]) + \" -------- \" + \"Training accuracy = \" + str(float(np.mean(predictions==Y,axis=1))*100))\n",
        "    p = p+1\n",
        "    if(i % 50 == 0):\n",
        "      if(callback is not None):\n",
        "                callback(i, parameters)\n",
        "  return costs, parameters"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1DSgF-3pIVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    PRECISION RECALL AND F1 SCORE\n",
        "      > Function is defined to calculate the precision, recall and F1 scores of the test and\n",
        "         cross validation data\n",
        "      > Returns the precision, recall and F1 score\n",
        "      > Arguments - Predictions_of_the_final_activation, y(ground_truth)\n",
        "\"\"\"\n",
        "\n",
        "def prec_rec(A,y):\n",
        "  tp = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  for i in range(0,y.shape[1]):\n",
        "    if ((A[0,i]==1)and(y[0,i]==1)):\n",
        "      tp = tp+1\n",
        "    if ((A[0,i]==1)and(y[0,i]==0)):\n",
        "      fp = fp+1\n",
        "    if (A[0,i]==0)and(y[0,i]==1):\n",
        "      fn = fn+1\n",
        "  prec = tp/(tp+fp)\n",
        "  rec = tp/(tp+fn)\n",
        "  f1 = (2*prec*rec)/(prec+rec)\n",
        "  return prec,rec,f1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzgIW2DZzJPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    PERFORMANCE ON TEST AND CROSS VALIDATION DATA\n",
        "      > This function evaluates the performance of the learning algorithm on test\n",
        "         and cross validation data\n",
        "      > Returns the accuracy, precision, recall and F1 score of test and cross validation\n",
        "         datasets\n",
        "      > Arguments - X,y,trained_parameters,print_values(True/False)\n",
        "\"\"\"\n",
        "\n",
        "def cross_val(X,y,params_tr,print_values):\n",
        "  out_cv,act_cv = forw_prop(X,params_tr,act_fn)\n",
        "  predictions_cv = predict(act_cv[\"A\" + str(len(layer_dims)-1)],0.5)\n",
        "  accu_cv = float(np.mean(predictions_cv==y,axis=1))*100\n",
        "  prec_cv,rec_cv,f1_cv = prec_rec(predictions_cv,y)\n",
        "  if print_values is True:\n",
        "    print(\"CROSS VAL RESULTS: \")\n",
        "    print(\"Cross val accuracy = \" + str(accu_cv))\n",
        "    print(\"Precision: \" + str(prec_cv))\n",
        "    print(\"Recall: \" + str(rec_cv))\n",
        "    print(\"F1 score: \" + str(f1_cv))\n",
        "    print('\\n')\n",
        "    print('\\n')\n",
        "  return accu_cv,prec_cv,rec_cv,f1_cv\n",
        "def test(X,y,params_tr,print_values):\n",
        "  out_te,act_te = forw_prop(X,params_tr,act_fn)\n",
        "  predictions_te = predict(act_te[\"A\" + str(len(layer_dims)-1)],0.5)\n",
        "  accu_te = float(np.mean(predictions_te==y,axis=1))*100\n",
        "  prec_te,rec_te,f1_te = prec_rec(predictions_te,y)\n",
        "  if print_values is True:\n",
        "    print(\"TEST RESULTS: \")\n",
        "    print(\"Testing accuracy = \" + str(accu_te))\n",
        "    print(\"Precision: \" + str(prec_te))\n",
        "    print(\"Recall: \" + str(rec_te))\n",
        "    print(\"F1 score: \" + str(f1_te))\n",
        "    print('\\n')\n",
        "    print('\\n')\n",
        "  return accu_te,prec_te,rec_te,f1_te"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFHen-5-pKrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "041f1a18-a741-458f-fe16-f28008977a84"
      },
      "source": [
        "#Training the network\n",
        "\n",
        "parameters_dat = initialize_parameters(layer_dims,act_fn)\n",
        "costs,parameters = fit(X_tr,y_tr,m_tr,10000,0.015,parameters_dat,act_fn,print_cost=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Cost after iteration 5002 is 0.09017789807467849 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5003 is 0.09017436204486028 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5004 is 0.09017082937247996 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5005 is 0.09016730005188296 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5006 is 0.09016377407742661 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5007 is 0.09016025144348032 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5008 is 0.09015673214442552 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5009 is 0.09015321617465563 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5010 is 0.09014970352857596 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5011 is 0.09014619420060381 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5012 is 0.09014268818516835 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5013 is 0.09013918547671056 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5014 is 0.09013568606968335 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5015 is 0.09013218995855128 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5016 is 0.09012869713779087 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5017 is 0.09012520760189027 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5018 is 0.09012172134534947 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5019 is 0.09011823836267997 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5020 is 0.09011475864840515 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5021 is 0.09011128219705986 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5022 is 0.09010780900319064 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5023 is 0.09010433906135563 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5024 is 0.09010087236612448 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5025 is 0.09009740891207839 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5026 is 0.0900939486938101 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5027 is 0.09009049170592379 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5028 is 0.09008703794303503 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5029 is 0.09008358739977095 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5030 is 0.09008014007076996 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5031 is 0.0900766959506819 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5032 is 0.09007325503416792 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5033 is 0.09006981731590048 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5034 is 0.09006638279056337 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5035 is 0.0900629514528516 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5036 is 0.09005952329747141 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5037 is 0.09005609831914028 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5038 is 0.09005267651258689 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5039 is 0.09004925787255097 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5040 is 0.09004584239378355 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5041 is 0.09004243007104659 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5042 is 0.09003902089911321 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5043 is 0.09003561487276762 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5044 is 0.09003221198680493 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5045 is 0.09002881223603136 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5046 is 0.0900254156152641 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5047 is 0.09002202211933126 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5048 is 0.09001863174307179 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5049 is 0.0900152444813357 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5050 is 0.09001186032898369 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5051 is 0.09000847928088747 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5052 is 0.09000510133192949 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5053 is 0.09000172647700291 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5054 is 0.08999835471101181 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5055 is 0.08999498602887093 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5056 is 0.08999162042550576 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5057 is 0.08998825789585241 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5058 is 0.08998489843485781 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5059 is 0.08998154203747932 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5060 is 0.08997818869868507 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5061 is 0.08997483841345374 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5062 is 0.08997149117677461 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5063 is 0.08996814698364738 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5064 is 0.08996480582908242 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5065 is 0.0899614677081005 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5066 is 0.08995813261573289 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5067 is 0.08995480054702125 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5068 is 0.08995147149701777 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5069 is 0.0899481454607849 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5070 is 0.08994482243339556 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5071 is 0.08994150240993298 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5072 is 0.08993818538549068 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5073 is 0.08993487135517256 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5074 is 0.08993156031409269 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5075 is 0.0899282522573754 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5076 is 0.08992494718015535 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5077 is 0.08992164507757729 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5078 is 0.08991834594479618 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5079 is 0.08991504977697717 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5080 is 0.08991175656929547 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5081 is 0.08990846631693643 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5082 is 0.08990517901509548 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5083 is 0.08990189465897806 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5084 is 0.08989861324379979 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5085 is 0.08989533476478612 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5086 is 0.08989205921717257 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5087 is 0.08988878659620461 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5088 is 0.08988551689713765 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5089 is 0.08988225011523708 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5090 is 0.08987898624577804 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5091 is 0.08987572528404565 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5092 is 0.08987246722533487 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5093 is 0.08986921206495045 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5094 is 0.08986595979820693 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5095 is 0.08986271042042868 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5096 is 0.08985946392694978 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5097 is 0.08985622031311402 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5098 is 0.089852979574275 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5099 is 0.08984974170579585 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5100 is 0.08984650670304954 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5101 is 0.08984327456141855 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5102 is 0.089840045276295 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5103 is 0.08983681884308067 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5104 is 0.08983359525718679 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5105 is 0.0898303745140343 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5106 is 0.08982715660905358 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5107 is 0.08982394153768446 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5108 is 0.08982072929537635 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5109 is 0.08981751987758806 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5110 is 0.08981431327978795 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5111 is 0.0898111094974536 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5112 is 0.08980790852607215 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5113 is 0.08980471036114004 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5114 is 0.08980151499816312 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5115 is 0.0897983224326565 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5116 is 0.08979513266014462 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5117 is 0.08979194567616124 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5118 is 0.08978876147624928 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5119 is 0.0897855800559611 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5120 is 0.08978240141085804 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5121 is 0.08977922553651085 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5122 is 0.0897760524284993 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5123 is 0.08977288208241238 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5124 is 0.08976971449384828 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5125 is 0.08976654965841419 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5126 is 0.08976338757172644 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5127 is 0.0897602282294104 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5128 is 0.08975707162710062 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5129 is 0.08975391776044045 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5130 is 0.0897507666250825 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5131 is 0.08974761821668817 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5132 is 0.08974447253092788 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5133 is 0.08974132956348106 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5134 is 0.08973818931003599 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5135 is 0.08973505176628989 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5136 is 0.0897319169279488 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5137 is 0.08972878479072777 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5138 is 0.08972565535035051 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5139 is 0.08972252860254964 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5140 is 0.0897194045430666 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5141 is 0.08971628316765154 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5142 is 0.0897131644720634 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5143 is 0.08971004845206994 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5144 is 0.08970693510344747 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5145 is 0.08970382442198117 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5146 is 0.08970071640346472 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5147 is 0.08969761104370066 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5148 is 0.08969450833849991 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5149 is 0.08969140828368233 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5150 is 0.08968831087507606 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5151 is 0.08968521610851803 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5152 is 0.0896821239798536 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5153 is 0.08967903448493679 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5154 is 0.08967594761963 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5155 is 0.08967286337980422 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5156 is 0.0896697817613389 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5157 is 0.08966670276012188 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5158 is 0.08966362637204955 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5159 is 0.08966055259302663 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5160 is 0.08965748141896629 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5161 is 0.08965441284579002 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5162 is 0.08965134686942772 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5163 is 0.08964828348581762 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5164 is 0.08964522269090626 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5165 is 0.08964216448064852 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5166 is 0.08963910885100747 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5167 is 0.08963605579795453 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5168 is 0.08963300531746932 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5169 is 0.08962995740553967 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5170 is 0.08962691205816173 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5171 is 0.08962386927133964 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5172 is 0.08962082904108587 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5173 is 0.08961779136342102 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5174 is 0.08961475623437366 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5175 is 0.08961172364998068 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5176 is 0.08960869360628695 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5177 is 0.08960566609934542 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5178 is 0.08960264112521711 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5179 is 0.0895996186799711 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5180 is 0.08959659875968441 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5181 is 0.08959358136044213 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5182 is 0.08959056647833727 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5183 is 0.08958755410947088 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5184 is 0.0895845442499519 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5185 is 0.08958153689589718 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5186 is 0.08957853204343151 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5187 is 0.08957552968868747 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5188 is 0.08957252982780571 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5189 is 0.08956953245693453 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5190 is 0.08956653757223015 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5191 is 0.08956354516985666 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5192 is 0.08956055524598583 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5193 is 0.08955756779679719 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5194 is 0.0895545828184782 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5195 is 0.08955160030722394 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5196 is 0.08954862025923724 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5197 is 0.08954564267072858 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5198 is 0.0895426675379162 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5199 is 0.08953969485702601 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5200 is 0.0895367246242915 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5201 is 0.08953375683595394 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5202 is 0.08953079148826203 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5203 is 0.08952782857747217 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5204 is 0.0895248680998484 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5205 is 0.08952191005166223 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5206 is 0.08951895442919267 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5207 is 0.0895160012287264 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5208 is 0.08951305044655758 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5209 is 0.08951010207898774 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5210 is 0.08950715612232604 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5211 is 0.08950421257288901 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5212 is 0.0895012714270007 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5213 is 0.08949833268099247 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5214 is 0.08949539633120315 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5215 is 0.08949246237397905 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5216 is 0.08948953080567369 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5217 is 0.08948660162264806 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5218 is 0.08948367482127044 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5219 is 0.08948075039791645 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5220 is 0.08947782834896904 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5221 is 0.0894749086708184 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5222 is 0.08947199135986203 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5223 is 0.08946907641250466 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5224 is 0.0894661638251583 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5225 is 0.0894632535942421 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5226 is 0.08946034571618251 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5227 is 0.08945744018741313 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5228 is 0.08945453700437475 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5229 is 0.08945163616351523 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5230 is 0.08944873766128969 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5231 is 0.08944584149416032 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5232 is 0.08944294765859641 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5233 is 0.08944005615107434 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5234 is 0.08943716696807756 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5235 is 0.08943428010609657 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5236 is 0.089431395561629 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5237 is 0.08942851333117936 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5238 is 0.08942563341125928 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5239 is 0.08942275579838736 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5240 is 0.08941988048908911 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5241 is 0.0894170074798971 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5242 is 0.08941413676735076 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5243 is 0.08941126834799654 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5244 is 0.08940840221838764 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5245 is 0.0894055383750844 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5246 is 0.08940267681465379 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5247 is 0.08939981753366984 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5248 is 0.08939696052871328 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5249 is 0.0893941057963718 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5250 is 0.08939125333323984 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5251 is 0.08938840313591861 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5252 is 0.0893855552010162 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5253 is 0.0893827095251474 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5254 is 0.08937986610493374 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5255 is 0.0893770249370036 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5256 is 0.08937418601799194 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5257 is 0.08937134934454052 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5258 is 0.08936851491329774 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5259 is 0.08936568272091876 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5260 is 0.08936285276406535 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5261 is 0.08936002503940589 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5262 is 0.0893571995436154 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5263 is 0.08935437627337564 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5264 is 0.08935155522537482 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5265 is 0.0893487363963078 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5266 is 0.089345919782876 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5267 is 0.0893431053817874 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5268 is 0.08934029318975659 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5269 is 0.08933748320350451 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5270 is 0.0893346754197588 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5271 is 0.08933186983525347 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5272 is 0.0893290664467291 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5273 is 0.0893262652509327 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5274 is 0.08932346624461769 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5275 is 0.08932066942454396 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5276 is 0.08931787478747785 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5277 is 0.08931508233019211 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5278 is 0.08931229204946584 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5279 is 0.08930950394208449 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5280 is 0.08930671800483996 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5281 is 0.08930393423453044 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5282 is 0.08930115262796054 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5283 is 0.089298373181941 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5284 is 0.0892955958932891 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5285 is 0.08929282075882825 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5286 is 0.08929004777538817 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5287 is 0.08928727693980493 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5288 is 0.08928450824892067 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5289 is 0.08928174169958399 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5290 is 0.08927897728864949 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5291 is 0.08927621501297814 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5292 is 0.089273454869437 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5293 is 0.08927069685489933 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5294 is 0.0892679409662446 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5295 is 0.08926518720035846 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5296 is 0.08926243555413248 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5297 is 0.08925968602446462 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5298 is 0.08925693860825878 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5299 is 0.08925419330242503 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5300 is 0.08925145010387944 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5301 is 0.08924870900954422 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5302 is 0.08924597001634763 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5303 is 0.08924323312122394 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5304 is 0.08924049832111342 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5305 is 0.08923776561296237 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5306 is 0.08923503499372315 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5307 is 0.08923230646035399 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5308 is 0.08922958000981913 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5309 is 0.08922685563908889 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5310 is 0.08922413334513929 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5311 is 0.08922141312495248 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5312 is 0.08921869497551645 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5313 is 0.0892159788938251 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5314 is 0.08921326487687818 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5315 is 0.08921055292168138 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5316 is 0.08920784302524622 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5317 is 0.08920513518459006 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5318 is 0.08920242939673607 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5319 is 0.08919972565871331 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5320 is 0.08919702396755663 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5321 is 0.0891943243203066 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5322 is 0.08919162671400967 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5323 is 0.08918893114571798 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5324 is 0.08918623761248953 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5325 is 0.08918354611138787 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5326 is 0.0891808566394825 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5327 is 0.08917816919384854 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5328 is 0.08917548377156675 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5329 is 0.08917280036972366 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5330 is 0.08917011898541147 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5331 is 0.08916743961572804 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5332 is 0.08916476225777688 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5333 is 0.08916208690866706 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5334 is 0.08915941356551342 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5335 is 0.0891567422254363 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5336 is 0.08915407288556174 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5337 is 0.08915140554302124 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5338 is 0.08914874019495203 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5339 is 0.08914607683849668 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5340 is 0.08914341547080352 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5341 is 0.08914075608902639 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5342 is 0.08913809869032453 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5343 is 0.0891354432718628 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5344 is 0.0891327898308115 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5345 is 0.08913013836434651 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5346 is 0.08912748886964907 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5347 is 0.08912484134390594 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5348 is 0.08912219578430934 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5349 is 0.08911955218805685 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5350 is 0.0891169105523516 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5351 is 0.08911427087440202 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5352 is 0.08911163315142204 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5353 is 0.08910899738063084 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5354 is 0.08910636355925317 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5355 is 0.08910373168451893 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5356 is 0.08910110175366355 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5357 is 0.08909847376392772 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5358 is 0.08909584771255744 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5359 is 0.08909322359680402 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5360 is 0.0890906014139242 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5361 is 0.08908798116117983 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5362 is 0.08908536283583819 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5363 is 0.0890827464351717 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5364 is 0.08908013195645814 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5365 is 0.08907751939698044 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5366 is 0.08907490875402696 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5367 is 0.08907230002489099 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5368 is 0.0890696932068712 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5369 is 0.08906708829727145 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5370 is 0.08906448529340082 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5371 is 0.0890618841925734 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5372 is 0.08905928499210865 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5373 is 0.08905668768933102 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5374 is 0.08905409228157017 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5375 is 0.08905149876616093 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5376 is 0.08904890714044314 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5377 is 0.0890463174017618 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5378 is 0.089043729547467 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5379 is 0.08904114357491393 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5380 is 0.08903855948146283 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5381 is 0.08903597726447898 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5382 is 0.08903339692133269 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5383 is 0.08903081844939942 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5384 is 0.08902824184605954 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5385 is 0.08902566710869839 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5386 is 0.08902309423470649 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5387 is 0.0890205232214792 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5388 is 0.0890179540664169 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5389 is 0.08901538676692496 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5390 is 0.08901282132041372 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5391 is 0.08901025772429835 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5392 is 0.08900769597599913 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5393 is 0.08900513607294111 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5394 is 0.08900257801255429 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5395 is 0.0890000217922737 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5396 is 0.08899746740953904 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5397 is 0.08899491486179512 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5398 is 0.08899236414649138 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5399 is 0.08898981526108234 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5400 is 0.08898726820302723 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5401 is 0.0889847229697901 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5402 is 0.08898217955883994 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5403 is 0.08897963796765049 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5404 is 0.08897709819370024 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5405 is 0.08897456023447257 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5406 is 0.0889720240874556 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5407 is 0.08896948975014217 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5408 is 0.08896695722002995 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5409 is 0.08896442649462133 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5410 is 0.08896189757142348 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5411 is 0.08895937044794822 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5412 is 0.08895684512171215 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5413 is 0.08895432159023654 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5414 is 0.08895179985104736 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5415 is 0.08894927990167534 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5416 is 0.08894676173965578 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5417 is 0.08894424536252869 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5418 is 0.08894173076783873 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5419 is 0.08893921795313521 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5420 is 0.08893670691597208 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5421 is 0.08893419765390786 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5422 is 0.08893169016450582 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5423 is 0.08892918444533365 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5424 is 0.08892668049396374 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5425 is 0.0889241783079731 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5426 is 0.08892167788494319 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5427 is 0.08891917922246013 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5428 is 0.08891668231811457 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5429 is 0.08891418716950164 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5430 is 0.08891169377422112 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5431 is 0.0889092021298772 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5432 is 0.08890671223407859 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5433 is 0.08890422408443859 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5434 is 0.08890173767857494 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5435 is 0.0888992530141098 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5436 is 0.08889677008866992 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5437 is 0.08889428889988638 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5438 is 0.08889180944539485 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5439 is 0.08888933172283534 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5440 is 0.0888868557298523 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5441 is 0.08888438146409466 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5442 is 0.08888190892321568 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5443 is 0.0888794381048731 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5444 is 0.08887696900672899 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5445 is 0.08887450162644986 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5446 is 0.08887203596170652 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5447 is 0.08886957201017424 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5448 is 0.08886710976953253 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5449 is 0.08886464923746532 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5450 is 0.08886219041166085 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5451 is 0.0888597332898117 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5452 is 0.08885727786961474 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5453 is 0.08885482414877115 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5454 is 0.08885237212498644 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5455 is 0.08884992179597029 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5456 is 0.08884747315943688 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5457 is 0.08884502621310439 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5458 is 0.08884258095469547 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5459 is 0.0888401373819369 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5460 is 0.0888376954925597 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5461 is 0.08883525528429924 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5462 is 0.08883281675489488 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5463 is 0.08883037990209049 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5464 is 0.08882794472363385 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5465 is 0.08882551121727712 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5466 is 0.08882307938077658 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5467 is 0.08882064921189267 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5468 is 0.08881822070839007 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5469 is 0.08881579386803744 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5470 is 0.08881336868860776 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5471 is 0.08881094516787814 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5472 is 0.08880852330362968 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5473 is 0.08880610309364773 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5474 is 0.08880368453572163 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5475 is 0.088801267627645 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5476 is 0.08879885236721531 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5477 is 0.08879643875223434 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5478 is 0.08879402678050778 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5479 is 0.08879161644984546 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5480 is 0.08878920775806126 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5481 is 0.08878680070297311 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5482 is 0.08878439528240288 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5483 is 0.08878199149417665 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5484 is 0.0887795893361244 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5485 is 0.08877718880608006 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5486 is 0.08877478990188169 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5487 is 0.08877239262137131 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5488 is 0.08876999696239483 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5489 is 0.08876760292280231 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5490 is 0.08876521050044758 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5491 is 0.08876281969318855 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5492 is 0.08876043049888706 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5493 is 0.08875804291540883 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5494 is 0.08875565694062364 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5495 is 0.08875327257240505 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5496 is 0.0887508898086306 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5497 is 0.08874850864718174 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5498 is 0.0887461290859438 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5499 is 0.08874375112280598 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5500 is 0.0887413747556614 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5501 is 0.08873899998240707 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5502 is 0.08873662680094371 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5503 is 0.08873425520917613 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5504 is 0.08873188520501281 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5505 is 0.08872951678636613 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5506 is 0.08872714995115222 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5507 is 0.0887247846972912 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5508 is 0.08872242102270683 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5509 is 0.08872005892532678 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5510 is 0.0887176984030824 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5511 is 0.08871533945390904 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5512 is 0.08871298207574554 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5513 is 0.08871062626653474 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5514 is 0.08870827202422316 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5515 is 0.08870591934676106 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5516 is 0.0887035682321024 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5517 is 0.08870121867820505 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5518 is 0.08869887068303037 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5519 is 0.08869652424454368 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5520 is 0.08869417936071382 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5521 is 0.08869183602951342 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5522 is 0.08868949424891881 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5523 is 0.08868715401690998 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5524 is 0.08868481533147063 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5525 is 0.08868247819058814 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5526 is 0.08868014259225346 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5527 is 0.08867780853446129 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5528 is 0.08867547601520996 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5529 is 0.08867314503250144 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5530 is 0.08867081558434133 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5531 is 0.08866848766873876 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5532 is 0.08866616128370666 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5533 is 0.08866383642726144 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5534 is 0.08866151309742315 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5535 is 0.0886591912922154 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5536 is 0.08865687100966542 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5537 is 0.08865455224780394 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5538 is 0.08865223500466543 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5539 is 0.08864991927828773 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5540 is 0.08864760506671236 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5541 is 0.08864529236798434 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5542 is 0.08864298118015217 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5543 is 0.08864067150126799 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5544 is 0.08863836332938735 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5545 is 0.08863605666256946 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5546 is 0.0886337514988769 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5547 is 0.08863144783637578 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5548 is 0.08862914567313578 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5549 is 0.08862684500722992 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5550 is 0.08862454583673485 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5551 is 0.08862224815973058 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5552 is 0.08861995197430063 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5553 is 0.08861765727853199 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5554 is 0.08861536407051504 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5555 is 0.08861307234834366 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5556 is 0.08861078211011508 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5557 is 0.08860849335393005 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5558 is 0.08860620607789266 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5559 is 0.08860392028011044 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5560 is 0.08860163595869436 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5561 is 0.08859935311175866 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5562 is 0.08859707173742112 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5563 is 0.0885947918338028 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5564 is 0.08859251339902818 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5565 is 0.08859023643122506 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5566 is 0.08858796092852464 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5567 is 0.08858568688906143 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5568 is 0.08858341431097336 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5569 is 0.08858114319240154 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5570 is 0.08857887353149062 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5571 is 0.08857660532638842 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5572 is 0.08857433857524608 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5573 is 0.08857207327621806 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5574 is 0.08856980942746226 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5575 is 0.08856754702713962 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5576 is 0.08856528607341453 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5577 is 0.0885630265644547 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5578 is 0.08856076849843095 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5579 is 0.08855851187351746 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5580 is 0.0885562566878917 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5581 is 0.08855400293973428 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5582 is 0.0885517506272292 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5583 is 0.08854949974856355 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5584 is 0.08854725030192771 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5585 is 0.08854500228551535 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5586 is 0.08854275569752322 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5587 is 0.08854051053615135 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5588 is 0.08853826679960303 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5589 is 0.08853602448608462 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5590 is 0.08853378359380572 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5591 is 0.08853154412097919 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5592 is 0.08852930606582093 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5593 is 0.08852706942655006 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5594 is 0.0885248342013889 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5595 is 0.0885226003885629 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5596 is 0.08852036798630059 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5597 is 0.0885181369928338 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5598 is 0.08851590740639728 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5599 is 0.08851367922522901 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5600 is 0.08851145244757018 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5601 is 0.08850922707166499 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5602 is 0.08850700309576069 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5603 is 0.08850478051810776 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5604 is 0.08850255933695965 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5605 is 0.08850033955057306 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5606 is 0.08849812115720757 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5607 is 0.08849590415512593 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5608 is 0.088493688542594 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5609 is 0.08849147431788064 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5610 is 0.08848926147925777 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5611 is 0.08848705002500033 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5612 is 0.08848483995338638 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5613 is 0.08848263126269697 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5614 is 0.0884804239512161 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5615 is 0.0884782180172309 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5616 is 0.08847601345903142 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5617 is 0.08847381027491089 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5618 is 0.08847160846316532 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5619 is 0.08846940802209385 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5620 is 0.08846720894999853 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5621 is 0.08846501124518447 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5622 is 0.08846281490595968 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5623 is 0.08846061993063521 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5624 is 0.08845842631752504 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5625 is 0.08845623406494608 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5626 is 0.08845404317121822 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5627 is 0.08845185363466429 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5628 is 0.08844966545361001 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5629 is 0.08844747862638412 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5630 is 0.0884452931513182 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5631 is 0.08844310902674683 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5632 is 0.08844092625100743 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5633 is 0.08843874482244031 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5634 is 0.08843656473938877 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5635 is 0.08843438600019896 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5636 is 0.08843220860321989 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5637 is 0.08843003254680344 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5638 is 0.08842785782930444 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5639 is 0.0884256844490805 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5640 is 0.08842351240449219 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5641 is 0.08842134169390281 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5642 is 0.08841917231567863 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5643 is 0.08841700426818871 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5644 is 0.08841483754980495 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5645 is 0.08841267215890208 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5646 is 0.08841050809385767 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5647 is 0.08840834535305207 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5648 is 0.08840618393486847 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5649 is 0.08840402383769294 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5650 is 0.0884018650599142 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5651 is 0.08839970759992392 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5652 is 0.08839755145611643 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5653 is 0.08839539662688897 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5654 is 0.0883932431106414 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5655 is 0.08839109090577653 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5656 is 0.08838894001069979 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5657 is 0.08838679042381942 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5658 is 0.08838464214354651 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5659 is 0.08838249516829472 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5660 is 0.08838034949648058 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5661 is 0.08837820512652333 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5662 is 0.08837606205684492 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5663 is 0.08837392028587004 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5664 is 0.0883717798120261 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5665 is 0.08836964063374322 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5666 is 0.08836750274945422 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5667 is 0.08836536615759466 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5668 is 0.08836323085660273 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5669 is 0.08836109684491938 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5670 is 0.0883589641209882 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5671 is 0.08835683268325549 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5672 is 0.08835470253017016 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5673 is 0.0883525736601839 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5674 is 0.08835044607175095 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5675 is 0.08834831976332826 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5676 is 0.08834619473337545 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5677 is 0.08834407098035475 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5678 is 0.08834194850273103 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5679 is 0.0883398272989718 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5680 is 0.0883377073675472 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5681 is 0.08833558870693003 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5682 is 0.08833347131559564 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5683 is 0.08833135519202208 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5684 is 0.08832924033468989 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5685 is 0.08832712674208229 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5686 is 0.08832501441268512 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5687 is 0.08832290334498674 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5688 is 0.08832079353747813 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5689 is 0.0883186849886528 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5690 is 0.08831657769700696 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5691 is 0.08831447166103923 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5692 is 0.08831236687925093 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5693 is 0.08831026335014584 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5694 is 0.08830816107223038 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5695 is 0.08830606004401337 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5696 is 0.08830396026400639 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5697 is 0.0883018617307233 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5698 is 0.08829976444268073 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5699 is 0.0882976683983977 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5700 is 0.08829557359639577 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5701 is 0.088293480035199 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5702 is 0.08829138771333404 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5703 is 0.08828929662932994 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5704 is 0.08828720678171831 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5705 is 0.08828511816903327 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5706 is 0.08828303078981137 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5707 is 0.08828094464259172 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5708 is 0.08827885972591572 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5709 is 0.08827677603832752 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5710 is 0.0882746935783736 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5711 is 0.08827261234460285 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5712 is 0.0882705323355667 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5713 is 0.08826845354981895 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5714 is 0.08826637598591598 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5715 is 0.08826429964241647 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5716 is 0.08826222451788165 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5717 is 0.08826015061087511 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5718 is 0.08825807791996285 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5719 is 0.08825600644371336 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5720 is 0.08825393618069752 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5721 is 0.0882518671294886 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5722 is 0.08824979928866232 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5723 is 0.08824773265679677 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5724 is 0.08824566723247237 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5725 is 0.0882436030142721 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5726 is 0.08824154000078117 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5727 is 0.08823947819058728 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5728 is 0.08823741758228036 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5729 is 0.08823535817445288 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5730 is 0.0882332999656996 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5731 is 0.08823124295461765 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5732 is 0.08822918713980647 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5733 is 0.08822713251986793 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5734 is 0.08822507909340617 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5735 is 0.08822302685902776 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5736 is 0.08822097581534154 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5737 is 0.08821892596095868 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5738 is 0.0882168772944927 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5739 is 0.08821482981455946 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5740 is 0.08821278351977709 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5741 is 0.08821073840876609 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5742 is 0.08820869448014923 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5743 is 0.08820665173255157 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5744 is 0.0882046101646005 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5745 is 0.08820256977492573 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5746 is 0.08820053056215917 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5747 is 0.08819849252493507 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5748 is 0.08819645566188995 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5749 is 0.08819441997166266 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5750 is 0.08819238545289419 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5751 is 0.088190352104228 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5752 is 0.08818831992430952 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5753 is 0.08818628891178672 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5754 is 0.08818425906530965 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5755 is 0.08818223038353068 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5756 is 0.08818020286510435 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5757 is 0.08817817650868755 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5758 is 0.08817615131293931 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5759 is 0.08817412727652091 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5760 is 0.08817210439809586 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5761 is 0.08817008267632992 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5762 is 0.08816806210989098 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5763 is 0.08816604269744922 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5764 is 0.08816402443767699 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5765 is 0.08816200732924882 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5766 is 0.08815999137084153 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5767 is 0.088157976561134 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5768 is 0.0881559628988074 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5769 is 0.08815395038254498 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5770 is 0.0881519390110323 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5771 is 0.08814992878295698 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5772 is 0.08814791969700887 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5773 is 0.08814591175187994 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5774 is 0.08814390494626435 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5775 is 0.08814189927885846 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5776 is 0.08813989474836066 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5777 is 0.0881378913534716 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5778 is 0.088135889092894 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5779 is 0.08813388796533277 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5780 is 0.08813188796949491 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5781 is 0.08812988910408959 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5782 is 0.08812789136782805 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5783 is 0.0881258947594237 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5784 is 0.08812389927759208 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5785 is 0.08812190492105078 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5786 is 0.0881199116885195 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5787 is 0.0881179195787201 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5788 is 0.08811592859037651 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5789 is 0.08811393872221471 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5790 is 0.08811194997296284 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5791 is 0.0881099623413511 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5792 is 0.0881079758261118 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5793 is 0.0881059904259792 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5794 is 0.0881040061396898 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5795 is 0.08810202296598207 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5796 is 0.08810004090359658 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5797 is 0.08809805995127593 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5798 is 0.08809608010776479 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5799 is 0.08809410137180988 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5800 is 0.08809212374216002 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5801 is 0.088090147217566 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5802 is 0.08808817179678063 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5803 is 0.08808619747855886 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5804 is 0.08808422426165756 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5805 is 0.08808225214483567 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5806 is 0.08808028112685422 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5807 is 0.08807831120647615 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5808 is 0.08807634238246648 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5809 is 0.08807437465359218 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5810 is 0.08807240801862226 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5811 is 0.08807044247632782 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5812 is 0.08806847802548179 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5813 is 0.08806651466485918 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5814 is 0.08806455239323704 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5815 is 0.08806259120939432 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5816 is 0.08806063111211193 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5817 is 0.0880586721001729 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5818 is 0.08805671417236208 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5819 is 0.08805475732746641 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5820 is 0.08805280156427468 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5821 is 0.0880508468815777 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5822 is 0.08804889327816826 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5823 is 0.08804694075284107 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5824 is 0.08804498930439282 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5825 is 0.08804303893162206 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5826 is 0.08804108963332939 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5827 is 0.08803914140831728 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5828 is 0.08803719425539022 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5829 is 0.08803524817335447 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5830 is 0.08803330316101837 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5831 is 0.08803135921719209 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5832 is 0.08802941634068773 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5833 is 0.08802747453031935 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5834 is 0.08802553378490291 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5835 is 0.08802359410325625 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5836 is 0.0880216554841991 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5837 is 0.0880197179265531 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5838 is 0.08801778142914184 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5839 is 0.08801584599079072 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5840 is 0.08801391161032704 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5841 is 0.08801197828658003 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5842 is 0.08801004601838078 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5843 is 0.08800811480456222 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5844 is 0.08800618464395919 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5845 is 0.08800425553540843 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5846 is 0.0880023274777484 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5847 is 0.08800040046981963 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5848 is 0.08799847451046433 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5849 is 0.08799654959852668 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5850 is 0.08799462573285262 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5851 is 0.08799270291228997 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5852 is 0.08799078113568842 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5853 is 0.08798886040189946 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5854 is 0.08798694070977643 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5855 is 0.0879850220581745 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5856 is 0.08798310444595064 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5857 is 0.08798118787196375 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5858 is 0.0879792723350744 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5859 is 0.08797735783414502 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5860 is 0.0879754443680399 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5861 is 0.0879735319356252 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5862 is 0.08797162053576862 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5863 is 0.08796971016734002 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5864 is 0.08796780082921075 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5865 is 0.08796589252025415 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5866 is 0.08796398523934522 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5867 is 0.08796207898536086 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5868 is 0.08796017375717971 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5869 is 0.08795826955368213 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5870 is 0.08795636637375032 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5871 is 0.08795446421626824 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5872 is 0.08795256308012163 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5873 is 0.08795066296419798 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5874 is 0.08794876386738654 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5875 is 0.0879468657885783 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5876 is 0.08794496872666609 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5877 is 0.08794307268054435 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5878 is 0.0879411776491094 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5879 is 0.08793928363125922 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5880 is 0.08793739062589358 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5881 is 0.08793549863191394 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5882 is 0.08793360764822353 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5883 is 0.08793171767372727 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5884 is 0.08792982870733194 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5885 is 0.08792794074794588 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5886 is 0.08792605379447918 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5887 is 0.08792416784584371 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5888 is 0.08792228290095301 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5889 is 0.08792039895872235 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5890 is 0.08791851601806867 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5891 is 0.08791663407791064 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5892 is 0.08791475313716868 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5893 is 0.08791287319476478 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5894 is 0.08791099424962277 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5895 is 0.08790911630066801 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5896 is 0.08790723934682772 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5897 is 0.08790536338703069 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5898 is 0.08790348842020738 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5899 is 0.08790161444528997 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5900 is 0.0878997414612123 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5901 is 0.08789786946690988 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5902 is 0.0878959984613199 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5903 is 0.08789412844338118 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5904 is 0.08789225941203423 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5905 is 0.08789039136622118 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5906 is 0.08788852430488586 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5907 is 0.08788665822697371 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5908 is 0.08788479313143185 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5909 is 0.08788292901720905 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5910 is 0.0878810658832556 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5911 is 0.08787920372852359 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5912 is 0.08787734255196666 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5913 is 0.08787548235254009 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5914 is 0.08787362312920083 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5915 is 0.08787176488090734 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5916 is 0.08786990760661977 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5917 is 0.08786805130529994 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5918 is 0.0878661959759112 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5919 is 0.08786434161741859 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5920 is 0.08786248822878864 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5921 is 0.0878606358089896 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5922 is 0.08785878435699128 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5923 is 0.08785693387176506 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5924 is 0.08785508435228394 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5925 is 0.0878532357975225 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5926 is 0.08785138820645692 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5927 is 0.08784954157806504 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5928 is 0.08784769591132609 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5929 is 0.08784585120522106 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5930 is 0.08784400745873244 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5931 is 0.08784216467084424 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5932 is 0.0878403228405422 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5933 is 0.08783848196681346 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5934 is 0.08783664204864683 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5935 is 0.08783480308503264 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5936 is 0.08783296507496273 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5937 is 0.0878311280174306 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5938 is 0.08782929191143123 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5939 is 0.08782745675596111 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5940 is 0.08782562255001841 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5941 is 0.0878237892926027 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5942 is 0.08782195698271521 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5943 is 0.08782012561935858 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5944 is 0.08781829520153708 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5945 is 0.08781646572825647 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5946 is 0.08781463719852403 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5947 is 0.08781280961134859 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5948 is 0.0878109829657405 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5949 is 0.0878091572607116 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5950 is 0.0878073324952753 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5951 is 0.08780550866844643 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5952 is 0.08780368577924141 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5953 is 0.08780186382667814 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5954 is 0.087800042809776 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5955 is 0.08779822272755597 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5956 is 0.08779640357904034 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5957 is 0.08779458536325307 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5958 is 0.08779276807921955 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5959 is 0.0877909517259666 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5960 is 0.08778913630252265 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5961 is 0.08778732180791747 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5962 is 0.08778550824118247 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5963 is 0.0877836956013504 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5964 is 0.08778188388745548 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5965 is 0.08778007309853353 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5966 is 0.08777826323362176 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5967 is 0.08777645429175882 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5968 is 0.08777464627198485 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5969 is 0.08777283917334147 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5970 is 0.08777103299487171 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5971 is 0.0877692277356201 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5972 is 0.0877674233946326 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5973 is 0.08776561997095667 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5974 is 0.08776381746364106 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5975 is 0.08776201587173614 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5976 is 0.08776021519429364 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5977 is 0.0877584154303667 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5978 is 0.08775661657901 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5979 is 0.0877548186392795 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5980 is 0.08775302161023277 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5981 is 0.0877512254909286 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5982 is 0.08774943028042739 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5983 is 0.08774763597779084 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5984 is 0.0877458425820821 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5985 is 0.08774405009236581 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5986 is 0.08774225850770785 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5987 is 0.08774046782717572 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5988 is 0.08773867804983813 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5989 is 0.08773688917476537 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5990 is 0.08773510120102898 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5991 is 0.08773331412770201 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5992 is 0.08773152795385881 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5993 is 0.08772974267857524 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5994 is 0.08772795830092843 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5995 is 0.08772617481999699 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5996 is 0.08772439223486084 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5997 is 0.08772261054460137 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5998 is 0.08772082974830128 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 5999 is 0.08771904984504462 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6000 is 0.08771727083391695 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6001 is 0.08771549271400504 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6002 is 0.08771371548439715 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6003 is 0.08771193914418281 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6004 is 0.087710163692453 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6005 is 0.08770838912830003 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6006 is 0.08770661545081755 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6007 is 0.08770484265910056 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6008 is 0.08770307075224547 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6009 is 0.08770129972934995 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6010 is 0.08769952958951314 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6011 is 0.08769776033183543 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6012 is 0.08769599195541856 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6013 is 0.08769422445936562 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6014 is 0.08769245784278114 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6015 is 0.08769069210477075 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6016 is 0.08768892724444166 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6017 is 0.0876871632609023 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6018 is 0.08768540015326241 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6019 is 0.08768363792063305 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6020 is 0.08768187656212673 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6021 is 0.08768011607685706 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6022 is 0.08767835646393915 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6023 is 0.08767659772248941 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6024 is 0.0876748398516254 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6025 is 0.08767308285046622 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6026 is 0.08767132671813212 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6027 is 0.0876695714537447 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6028 is 0.08766781705642686 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6029 is 0.08766606352530279 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6030 is 0.08766431085949801 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6031 is 0.08766255905813931 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6032 is 0.08766080812035475 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6033 is 0.08765905804527375 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6034 is 0.08765730883202698 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6035 is 0.08765556047974626 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6036 is 0.08765381298756503 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6037 is 0.08765206635461766 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6038 is 0.08765032058003998 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6039 is 0.08764857566296905 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6040 is 0.08764683160254319 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6041 is 0.08764508839790204 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6042 is 0.08764334604818645 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6043 is 0.0876416045525386 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6044 is 0.08763986391010188 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6045 is 0.08763812412002091 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6046 is 0.08763638518144168 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6047 is 0.08763464709351129 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6048 is 0.0876329098553783 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6049 is 0.08763117346619229 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6050 is 0.08762943792510423 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6051 is 0.08762770323126631 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6052 is 0.08762596938383192 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6053 is 0.08762423638195578 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6054 is 0.08762250422479377 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6055 is 0.08762077291150298 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6056 is 0.0876190424412419 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6057 is 0.08761731281317005 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6058 is 0.0876155840264483 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6059 is 0.08761385608023874 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6060 is 0.08761212897370464 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6061 is 0.08761040270601052 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6062 is 0.0876086772763221 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6063 is 0.08760695268380637 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6064 is 0.0876052289276315 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6065 is 0.08760350600696684 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6066 is 0.08760178392098304 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6067 is 0.0876000626688519 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6068 is 0.08759834224974637 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6069 is 0.08759662266284077 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6070 is 0.0875949039073104 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6071 is 0.087593185982332 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6072 is 0.08759146888708332 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6073 is 0.0875897526207434 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6074 is 0.08758803718249245 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6075 is 0.08758632257151182 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6076 is 0.0875846087869842 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6077 is 0.08758289582809327 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6078 is 0.08758118369402404 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6079 is 0.08757947238396266 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6080 is 0.08757776189709643 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6081 is 0.08757605223261387 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6082 is 0.08757434338970463 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6083 is 0.08757263536755955 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6084 is 0.0875709281653707 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6085 is 0.0875692217823312 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6086 is 0.08756751621763549 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6087 is 0.08756581147047904 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6088 is 0.08756410754005856 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6089 is 0.08756240442557184 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6090 is 0.08756070212621793 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6091 is 0.087559000641197 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6092 is 0.0875572999697103 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6093 is 0.08755560011096034 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6094 is 0.08755390106415076 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6095 is 0.08755220282848625 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6096 is 0.08755050540317273 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6097 is 0.0875488087874173 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6098 is 0.0875471129804281 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6099 is 0.08754541798141446 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6100 is 0.08754372378958691 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6101 is 0.08754203040415695 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6102 is 0.08754033782433733 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6103 is 0.08753864604934199 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6104 is 0.08753695507838581 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6105 is 0.087535264910685 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6106 is 0.08753357554545672 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6107 is 0.08753188698191942 -------- Training accuracy = 96.77777777777777\n",
            "Cost after iteration 6108 is 0.08753019921929248 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6109 is 0.08752851225679659 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6110 is 0.0875268260936534 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6111 is 0.08752514072908575 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6112 is 0.08752345616231763 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6113 is 0.08752177239257401 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6114 is 0.0875200894190811 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6115 is 0.08751840724106615 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6116 is 0.08751672585775751 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6117 is 0.08751504526838465 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6118 is 0.08751336547217811 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6119 is 0.08751168646836965 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6120 is 0.0875100082561919 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6121 is 0.08750833083487874 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6122 is 0.08750665420366519 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6123 is 0.08750497836178722 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6124 is 0.08750330330848193 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6125 is 0.08750162904298754 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6126 is 0.08749995556454333 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6127 is 0.08749828287238968 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6128 is 0.08749661096576801 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6129 is 0.0874949398439209 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6130 is 0.08749326950609186 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6131 is 0.08749159995152563 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6132 is 0.08748993117946788 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6133 is 0.08748826318916547 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6134 is 0.08748659597986626 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6135 is 0.08748492955081921 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6136 is 0.0874832639012743 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6137 is 0.0874815990304826 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6138 is 0.08747993493769622 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6139 is 0.08747827162216838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6140 is 0.08747660908315325 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6141 is 0.08747494731990622 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6142 is 0.08747328633168355 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6143 is 0.08747162611774267 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6144 is 0.08746996667734196 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6145 is 0.08746830800974101 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6146 is 0.08746665011420024 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6147 is 0.0874649929899813 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6148 is 0.08746333663634671 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6149 is 0.08746168105256019 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6150 is 0.08746002623788637 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6151 is 0.08745837219159106 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6152 is 0.0874567189129409 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6153 is 0.08745506640120375 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6154 is 0.08745341465564835 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6155 is 0.0874517636755446 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6156 is 0.0874501134601633 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6157 is 0.08744846400877639 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6158 is 0.08744681532065669 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6159 is 0.08744516739507822 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6160 is 0.08744352023131585 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6161 is 0.08744187382864557 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6162 is 0.08744022818634432 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6163 is 0.08743858330369014 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6164 is 0.08743693917996193 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6165 is 0.08743529581443972 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6166 is 0.08743365320640453 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6167 is 0.08743201135513838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6168 is 0.08743037025992424 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6169 is 0.08742872992004615 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6170 is 0.08742709033478911 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6171 is 0.08742545150343914 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6172 is 0.08742381342528321 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6173 is 0.08742217609960935 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6174 is 0.0874205395257065 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6175 is 0.08741890370286468 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6176 is 0.08741726863037481 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6177 is 0.08741563430752888 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6178 is 0.08741400073361985 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6179 is 0.08741236790794155 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6180 is 0.08741073582978896 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6181 is 0.0874091044984579 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6182 is 0.08740747391324523 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6183 is 0.08740584407344881 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6184 is 0.08740421497836741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6185 is 0.08740258662730083 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6186 is 0.0874009590195498 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6187 is 0.08739933215441603 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6188 is 0.08739770603120223 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6189 is 0.08739608064921199 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6190 is 0.08739445600774998 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6191 is 0.08739283210612171 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6192 is 0.08739120894363374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6193 is 0.08738958651959354 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6194 is 0.08738796483330956 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6195 is 0.08738634388409124 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6196 is 0.08738472367124882 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6197 is 0.08738310419409372 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6198 is 0.08738148545193809 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6199 is 0.0873798674440952 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6200 is 0.0873782501698792 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6201 is 0.08737663362860508 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6202 is 0.08737501781958897 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6203 is 0.08737340274214779 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6204 is 0.08737178839559949 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6205 is 0.08737017477926287 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6206 is 0.0873685618924577 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6207 is 0.08736694973450476 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6208 is 0.08736533830472569 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6209 is 0.087363727602443 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6210 is 0.08736211762698022 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6211 is 0.08736050837766188 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6212 is 0.0873588998538132 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6213 is 0.08735729205476057 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6214 is 0.08735568497983118 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6215 is 0.08735407862835308 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6216 is 0.08735247299965543 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6217 is 0.08735086809306812 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6218 is 0.087349263907922 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6219 is 0.08734766044354896 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6220 is 0.08734605769928164 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6221 is 0.08734445567445369 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6222 is 0.08734285436839959 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6223 is 0.08734125378045485 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6224 is 0.08733965390995571 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6225 is 0.08733805475623949 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6226 is 0.08733645631864427 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6227 is 0.0873348585965092 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6228 is 0.08733326158917416 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6229 is 0.08733166529597997 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6230 is 0.0873300697162684 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6231 is 0.0873284748493821 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6232 is 0.08732688069466459 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6233 is 0.08732528725146027 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6234 is 0.08732369451911448 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6235 is 0.08732210249697336 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6236 is 0.0873205111843841 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6237 is 0.08731892058069453 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6238 is 0.08731733068525362 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6239 is 0.08731574149741107 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6240 is 0.08731415301651745 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6241 is 0.08731256524192434 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6242 is 0.08731097817298401 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6243 is 0.0873093918090498 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6244 is 0.08730780614947577 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6245 is 0.08730622119361695 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6246 is 0.08730463694082918 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6247 is 0.08730305339046923 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6248 is 0.08730147054189465 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6249 is 0.08729988839446394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6250 is 0.08729830694753643 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6251 is 0.0872967262004723 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6252 is 0.08729514615263265 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6253 is 0.0872935668033794 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6254 is 0.08729198815207524 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6255 is 0.08729041019808388 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6256 is 0.08728883294076979 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6257 is 0.08728725637949834 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6258 is 0.08728568051363576 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6259 is 0.08728410534254898 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6260 is 0.08728253086560593 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6261 is 0.08728095708217547 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6262 is 0.08727938399162709 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6263 is 0.08727781159333126 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6264 is 0.08727623988665921 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6265 is 0.08727466887098316 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6266 is 0.08727309854567601 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6267 is 0.0872715289101116 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6268 is 0.08726995996366453 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6269 is 0.08726839170571031 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6270 is 0.08726682413562524 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6271 is 0.08726525725278647 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6272 is 0.08726369105657196 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6273 is 0.08726212554636056 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6274 is 0.08726056072153186 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6275 is 0.08725899658146638 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6276 is 0.08725743312554536 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6277 is 0.08725587035315097 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6278 is 0.08725430826366608 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6279 is 0.08725274685647452 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6280 is 0.08725118613096083 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6281 is 0.08724962608651039 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6282 is 0.08724806672250948 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6283 is 0.08724650803834509 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6284 is 0.08724495003340507 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6285 is 0.0872433927070781 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6286 is 0.08724183605875364 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6287 is 0.08724028008782199 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6288 is 0.0872387247936742 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6289 is 0.08723717017570222 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6290 is 0.08723561623329872 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6291 is 0.08723406296585719 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6292 is 0.08723251037277202 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6293 is 0.08723095845343827 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6294 is 0.08722940720725186 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6295 is 0.08722785663360952 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6296 is 0.08722630673190872 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6297 is 0.08722475750154783 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6298 is 0.08722320894192594 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6299 is 0.08722166105244286 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6300 is 0.08722011383249942 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6301 is 0.087218567281497 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6302 is 0.0872170213988379 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6303 is 0.08721547618392517 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6304 is 0.08721393163616267 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6305 is 0.08721238775495499 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6306 is 0.08721084453970758 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6307 is 0.08720930198982664 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6308 is 0.0872077601047191 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6309 is 0.08720621888379275 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6310 is 0.08720467832645615 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6311 is 0.08720313843211853 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6312 is 0.08720159920019006 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6313 is 0.08720006063008154 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6314 is 0.08719852272120467 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6315 is 0.08719698547297178 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6316 is 0.08719544888479615 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6317 is 0.08719391295609161 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6318 is 0.08719237768627291 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6319 is 0.0871908430747556 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6320 is 0.08718930912095582 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6321 is 0.08718777582429062 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6322 is 0.08718624318417778 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6323 is 0.08718471120003586 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6324 is 0.08718317987128414 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6325 is 0.08718164919734259 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6326 is 0.08718011917763212 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6327 is 0.08717858981157424 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6328 is 0.08717706109859127 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6329 is 0.08717553303810632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6330 is 0.08717400562954317 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6331 is 0.08717247887232639 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 6332 is 0.08717095276588135 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6333 is 0.08716942730963408 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6334 is 0.08716790250301137 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6335 is 0.08716637834544087 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6336 is 0.08716485483635084 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6337 is 0.0871633319751703 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6338 is 0.0871618097613291 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6339 is 0.08716028819425777 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6340 is 0.08715876727338749 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6341 is 0.08715724699815043 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6342 is 0.08715572736797918 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6343 is 0.08715420838230731 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6344 is 0.08715269004056893 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6345 is 0.08715117234219916 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6346 is 0.08714965528663356 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6347 is 0.08714813887330862 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6348 is 0.08714662310166138 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6349 is 0.08714510797112975 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6350 is 0.08714359348115235 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6351 is 0.08714207963116849 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6352 is 0.08714056642061817 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6353 is 0.08713905384894222 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6354 is 0.08713754191558205 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6355 is 0.08713603061997997 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6356 is 0.08713451996157881 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6357 is 0.0871330099398223 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6358 is 0.08713150055415475 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6359 is 0.08712999180402123 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6360 is 0.08712848368886755 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6361 is 0.0871269762081402 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6362 is 0.08712546936128646 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6363 is 0.08712396314775415 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6364 is 0.087122457566992 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6365 is 0.08712095261844931 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6366 is 0.08711944830157614 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6367 is 0.08711794461582326 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6368 is 0.0871164415606421 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6369 is 0.08711493913548486 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6370 is 0.08711343733980437 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6371 is 0.08711193617305421 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6372 is 0.08711043563468872 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6373 is 0.08710893572416277 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6374 is 0.0871074364409321 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6375 is 0.08710593778445298 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6376 is 0.08710443975418257 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6377 is 0.08710294234957852 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6378 is 0.08710144557009937 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6379 is 0.08709994941520421 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6380 is 0.08709845388435283 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6381 is 0.08709695897700581 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6382 is 0.08709546469262427 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6383 is 0.08709397103067017 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6384 is 0.0870924779906061 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6385 is 0.08709098557189526 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6386 is 0.08708949377400162 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6387 is 0.08708800259638977 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6388 is 0.08708651203852506 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6389 is 0.08708502209987352 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6390 is 0.08708353277990172 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6391 is 0.08708204407807703 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6392 is 0.08708055599386745 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6393 is 0.08707906852674177 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6394 is 0.08707758167616929 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6395 is 0.08707609544162007 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6396 is 0.08707460982256476 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6397 is 0.08707312481847483 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6398 is 0.08707164042882226 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6399 is 0.08707015665307985 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6400 is 0.08706867349072098 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6401 is 0.0870671909412197 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6402 is 0.08706570900405065 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6403 is 0.08706422767868935 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6404 is 0.08706274696461172 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6405 is 0.08706126686129458 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6406 is 0.08705978736821525 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6407 is 0.08705830848485174 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6408 is 0.08705683021068283 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6409 is 0.0870553525451878 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6410 is 0.08705387548784668 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6411 is 0.08705239903814009 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6412 is 0.08705092319554937 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6413 is 0.08704944795955652 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6414 is 0.0870479733296441 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6415 is 0.08704649930529541 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6416 is 0.08704502588599443 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6417 is 0.08704355307122559 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6418 is 0.08704208086047424 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6419 is 0.08704060925322615 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6420 is 0.08703913824896792 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6421 is 0.08703766784718665 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6422 is 0.08703619804737012 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6423 is 0.08703472884900683 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6424 is 0.0870332602515858 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6425 is 0.08703179225459674 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6426 is 0.08703032485753007 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6427 is 0.08702885805987677 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6428 is 0.08702739186112846 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6429 is 0.08702592626077742 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6430 is 0.08702446125831655 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6431 is 0.0870229968532394 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6432 is 0.08702153304504014 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6433 is 0.08702006983321357 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6434 is 0.08701860721725511 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6435 is 0.08701714519666084 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6436 is 0.08701568377092748 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6437 is 0.08701422293955231 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6438 is 0.08701276270203331 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6439 is 0.087011303057869 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6440 is 0.08700984400655862 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6441 is 0.08700838554760201 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6442 is 0.08700692768049956 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6443 is 0.08700547040475239 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6444 is 0.08700401371986212 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6445 is 0.08700255762533109 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6446 is 0.08700110212066221 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6447 is 0.08699964720535906 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6448 is 0.08699819287892574 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6449 is 0.0869967391408671 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6450 is 0.08699528599068843 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6451 is 0.08699383342789577 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6452 is 0.08699238145199574 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6453 is 0.08699093006249553 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6454 is 0.08698947925890302 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6455 is 0.08698802904072662 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6456 is 0.0869865794074754 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6457 is 0.08698513035865897 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6458 is 0.08698368189378765 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6459 is 0.08698223401237226 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6460 is 0.08698078671392431 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6461 is 0.08697933999795587 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6462 is 0.08697789386397956 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6463 is 0.08697644831150877 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6464 is 0.08697500334005726 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6465 is 0.08697355894913958 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6466 is 0.08697211513827077 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6467 is 0.08697067190696656 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6468 is 0.08696922925474317 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6469 is 0.08696778718111745 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6470 is 0.08696634568560695 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6471 is 0.08696490476772957 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6472 is 0.08696346442700409 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6473 is 0.08696202466294968 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6474 is 0.08696058547508623 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6475 is 0.08695914686293411 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6476 is 0.08695770882601431 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6477 is 0.08695627136384847 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6478 is 0.08695483447595873 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6479 is 0.08695339816186785 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6480 is 0.0869519624210992 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6481 is 0.08695052725317674 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6482 is 0.08694909265762493 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6483 is 0.0869476586339689 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6484 is 0.08694622518173437 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6485 is 0.08694479230044752 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6486 is 0.08694335998963522 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6487 is 0.0869419282488249 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6488 is 0.08694049707754456 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6489 is 0.08693906647532272 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6490 is 0.08693763644168857 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6491 is 0.08693620697617184 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6492 is 0.08693477807830279 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6493 is 0.08693334974761231 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6494 is 0.08693192198363178 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6495 is 0.0869304947858933 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6496 is 0.08692906815392938 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6497 is 0.08692764208727316 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6498 is 0.08692621658545842 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6499 is 0.08692479164801938 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6500 is 0.08692336727449092 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6501 is 0.08692194346440842 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6502 is 0.0869205202173079 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6503 is 0.08691909753272581 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6504 is 0.08691767541019937 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6505 is 0.08691625384926618 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6506 is 0.08691483284946444 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6507 is 0.08691341241033301 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6508 is 0.08691199253141117 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6509 is 0.08691057321223883 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6510 is 0.08690915445235646 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6511 is 0.08690773625130507 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6512 is 0.0869063186086262 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6513 is 0.08690490152386202 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6514 is 0.0869034849965552 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6515 is 0.08690206902624896 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6516 is 0.08690065361248704 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6517 is 0.08689923875481383 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6518 is 0.08689782445277412 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6519 is 0.08689641070591347 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6520 is 0.08689499751377774 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6521 is 0.08689358487591353 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6522 is 0.08689217279186791 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6523 is 0.08689076126118843 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6524 is 0.08688935028342332 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6525 is 0.08688793985812121 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6526 is 0.08688652998483146 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6527 is 0.08688512066310376 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6528 is 0.08688371189248842 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6529 is 0.08688230367253644 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6530 is 0.08688089600279912 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6531 is 0.08687948888282843 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6532 is 0.0868780823121769 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6533 is 0.08687667629039751 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6534 is 0.0868752708170438 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6535 is 0.08687386589166993 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6536 is 0.08687246151383043 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6537 is 0.08687105768308055 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6538 is 0.08686965439897595 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6539 is 0.08686825166107291 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6540 is 0.08686684946892806 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6541 is 0.0868654478220988 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6542 is 0.08686404672014289 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6543 is 0.08686264616261873 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6544 is 0.0868612461490851 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6545 is 0.08685984667910143 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6546 is 0.08685844775222772 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6547 is 0.08685704936802431 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6548 is 0.08685565152605224 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6549 is 0.08685425422587296 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6550 is 0.08685285746704854 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6551 is 0.08685146124914146 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6552 is 0.08685006557171482 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6553 is 0.0868486704343322 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6554 is 0.08684727583655764 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6555 is 0.08684588177795587 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6556 is 0.08684448825809192 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6557 is 0.08684309527653147 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6558 is 0.08684170283284072 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6559 is 0.08684031092658633 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6560 is 0.08683891955733548 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6561 is 0.08683752872465592 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6562 is 0.08683613842811576 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6563 is 0.08683474866728394 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6564 is 0.08683335944172951 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6565 is 0.0868319707510223 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6566 is 0.08683058259473254 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6567 is 0.08682919497243113 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6568 is 0.08682780788368917 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6569 is 0.08682642132807855 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6570 is 0.08682503530517158 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6571 is 0.08682364981454099 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6572 is 0.08682226485576013 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6573 is 0.08682088042840277 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6574 is 0.08681949653204324 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6575 is 0.08681811316625637 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6576 is 0.08681673033061746 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6577 is 0.08681534802470232 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6578 is 0.08681396624808728 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6579 is 0.0868125850003491 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6580 is 0.08681120428106512 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6581 is 0.08680982408981319 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6582 is 0.08680844442617158 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6583 is 0.08680706528971906 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6584 is 0.08680568668003498 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6585 is 0.0868043085966991 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6586 is 0.08680293103929171 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6587 is 0.08680155400739359 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6588 is 0.08680017750058595 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6589 is 0.08679880151845065 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6590 is 0.0867974260605699 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6591 is 0.08679605112652641 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6592 is 0.08679467671590345 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6593 is 0.0867933028282847 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6594 is 0.08679192946325437 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6595 is 0.08679055662039717 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6596 is 0.08678918429929827 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6597 is 0.08678781249954333 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6598 is 0.08678644122071848 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6599 is 0.08678507046241034 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6600 is 0.08678370022420612 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6601 is 0.08678233050569331 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6602 is 0.08678096130646 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6603 is 0.08677959262609476 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6604 is 0.08677822446418663 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6605 is 0.08677685682032514 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6606 is 0.08677548969410026 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6607 is 0.08677412308510246 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6608 is 0.0867727569929227 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6609 is 0.08677139141715239 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6610 is 0.08677002635738347 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6611 is 0.08676866181320823 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6612 is 0.08676729778421961 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6613 is 0.08676593427001088 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6614 is 0.08676457127017585 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6615 is 0.08676320878430878 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6616 is 0.08676184681200441 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6617 is 0.08676048535285792 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6618 is 0.08675912440646504 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6619 is 0.08675776397242187 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6620 is 0.08675640405032504 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6621 is 0.08675504463977161 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6622 is 0.08675368574035917 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6623 is 0.0867523273516857 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6624 is 0.08675096947334968 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6625 is 0.08674961210495004 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6626 is 0.08674825524608622 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6627 is 0.08674689889635805 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6628 is 0.0867455430553659 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6629 is 0.08674418772271054 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6630 is 0.08674283289799323 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6631 is 0.08674147858081567 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6632 is 0.08674012477078007 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6633 is 0.08673877146748901 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6634 is 0.08673741867054563 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6635 is 0.08673606637955344 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6636 is 0.08673471459411644 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6637 is 0.08673336331383914 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6638 is 0.0867320125383264 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6639 is 0.08673066226718362 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6640 is 0.0867293125000166 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6641 is 0.08672796323643167 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6642 is 0.0867266144760355 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6643 is 0.0867252662184353 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6644 is 0.08672391846323868 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6645 is 0.08672257121005376 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6646 is 0.08672122445848904 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6647 is 0.0867198782081535 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6648 is 0.08671853245865656 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6649 is 0.08671718720960812 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6650 is 0.08671584246061853 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6651 is 0.08671449821129852 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6652 is 0.08671315446125931 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6653 is 0.08671181121011254 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6654 is 0.08671046845747035 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6655 is 0.08670912620294527 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6656 is 0.08670778444615032 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6657 is 0.0867064431866989 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6658 is 0.0867051024242049 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6659 is 0.0867037621582826 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6660 is 0.08670242238854678 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6661 is 0.08670108311461266 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6662 is 0.08669974433609587 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6663 is 0.08669840605261242 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6664 is 0.0866970682637789 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6665 is 0.0866957309692122 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6666 is 0.08669439416852973 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6667 is 0.08669305786134927 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6668 is 0.08669172204728912 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6669 is 0.08669038672596796 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6670 is 0.08668905189700489 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6671 is 0.08668771756001947 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6672 is 0.08668638371463165 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6673 is 0.08668505036046192 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6674 is 0.08668371749713108 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6675 is 0.08668238512426042 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6676 is 0.08668105324147161 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6677 is 0.08667972184838685 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6678 is 0.08667839094462863 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6679 is 0.08667706052982001 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6680 is 0.08667573060358437 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6681 is 0.08667440116554562 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6682 is 0.08667307221532791 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6683 is 0.08667174375255601 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6684 is 0.08667041577685505 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6685 is 0.08666908828785055 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6686 is 0.08666776128516848 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6687 is 0.08666643476843523 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6688 is 0.08666510873727762 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6689 is 0.08666378319132287 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6690 is 0.08666245813019863 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6691 is 0.08666113355353294 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6692 is 0.0866598094609544 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6693 is 0.08665848585209182 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6694 is 0.08665716272657455 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6695 is 0.08665584008403238 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6696 is 0.08665451792409538 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6697 is 0.08665319624639423 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6698 is 0.08665187505055985 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6699 is 0.0866505543362237 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6700 is 0.08664923410301757 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6701 is 0.08664791435057373 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6702 is 0.08664659507852479 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6703 is 0.08664527628650384 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6704 is 0.08664395797414433 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6705 is 0.08664264014108015 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6706 is 0.08664132278694565 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6707 is 0.08664000591137547 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 6708 is 0.0866386895140047 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6709 is 0.08663737359446895 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6710 is 0.08663605815240412 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6711 is 0.08663474318744652 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6712 is 0.08663342869923292 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6713 is 0.08663211468740047 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6714 is 0.08663080115158668 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6715 is 0.08662948809142966 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6716 is 0.08662817550656758 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6717 is 0.08662686339663934 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6718 is 0.08662555176128409 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6719 is 0.08662424060014137 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6720 is 0.08662292991285123 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6721 is 0.08662161969905396 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6722 is 0.0866203099583904 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6723 is 0.0866190006905017 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6724 is 0.08661769189502949 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6725 is 0.08661638357161568 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6726 is 0.08661507571990272 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6727 is 0.08661376833953334 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6728 is 0.08661246143015072 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6729 is 0.08661115499139846 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6730 is 0.08660984902292047 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6731 is 0.08660854352436113 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6732 is 0.08660723849536525 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6733 is 0.08660593393557793 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6734 is 0.08660462984464469 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6735 is 0.08660332622221152 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6736 is 0.08660202306792474 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6737 is 0.08660072038143107 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6738 is 0.0865994181623776 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6739 is 0.08659811641041183 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6740 is 0.08659681512518173 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6741 is 0.08659551430633551 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6742 is 0.08659421395352183 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6743 is 0.0865929140663898 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6744 is 0.08659161464458887 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6745 is 0.0865903156877688 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6746 is 0.08658901719557995 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6747 is 0.08658771916767279 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6748 is 0.08658642160369845 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6749 is 0.0865851245033082 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6750 is 0.08658382786615385 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6751 is 0.0865825316918875 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6752 is 0.08658123598016174 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6753 is 0.08657994073062948 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6754 is 0.08657864594294401 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6755 is 0.086577351616759 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6756 is 0.08657605775172851 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6757 is 0.08657476434750697 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6758 is 0.08657347140374924 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6759 is 0.08657217892011049 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6760 is 0.08657088689624631 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6761 is 0.08656959533181263 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6762 is 0.08656830422646582 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6763 is 0.08656701357986255 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6764 is 0.08656572339165997 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6765 is 0.08656443366151548 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6766 is 0.08656314438908697 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6767 is 0.08656185557403263 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6768 is 0.08656056721601105 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6769 is 0.0865592793146812 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6770 is 0.08655799186970241 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6771 is 0.0865567048807344 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6772 is 0.08655541834743725 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6773 is 0.08655413226947137 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6774 is 0.08655284664649765 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6775 is 0.08655156147817727 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6776 is 0.08655027676417174 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6777 is 0.0865489925041431 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6778 is 0.08654770869775354 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6779 is 0.08654642534466578 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6780 is 0.08654514244454291 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6781 is 0.08654385999704825 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6782 is 0.08654257800184562 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6783 is 0.08654129645859915 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6784 is 0.08654001536697337 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6785 is 0.08653873472663311 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6786 is 0.08653745453724365 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6787 is 0.08653617479847059 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6788 is 0.08653489550997982 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6789 is 0.08653361667143775 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6790 is 0.08653233828251103 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6791 is 0.0865310603428667 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6792 is 0.08652978285217222 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6793 is 0.08652850581009533 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6794 is 0.08652722921630415 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6795 is 0.08652595307046722 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6796 is 0.08652467737225338 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6797 is 0.0865234021213318 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6798 is 0.08652212731737213 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6799 is 0.08652085296004422 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6800 is 0.08651957904901836 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6801 is 0.08651830558396527 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6802 is 0.08651703256455591 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6803 is 0.08651575999046159 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6804 is 0.08651448786135407 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6805 is 0.08651321617690541 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6806 is 0.08651194493678802 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6807 is 0.08651067414067465 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6808 is 0.08650940378823849 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6809 is 0.08650813387915296 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6810 is 0.08650686441309191 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6811 is 0.08650559538972952 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6812 is 0.08650432680874034 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6813 is 0.08650305866979927 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6814 is 0.08650179097258148 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6815 is 0.08650052371676259 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6816 is 0.08649925690201854 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6817 is 0.08649799052802563 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6818 is 0.08649672459446045 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6819 is 0.08649545910100004 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6820 is 0.08649419404732164 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6821 is 0.08649292943310298 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6822 is 0.08649166525802204 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6823 is 0.08649040152175726 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6824 is 0.08648913822398725 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6825 is 0.08648787536439115 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6826 is 0.08648661294264828 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6827 is 0.08648535095843843 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6828 is 0.08648408941144169 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6829 is 0.08648282830133845 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6830 is 0.08648156762780954 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6831 is 0.086480307390536 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6832 is 0.08647904758919929 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6833 is 0.08647778822348128 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6834 is 0.08647652929306401 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6835 is 0.08647527079763004 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6836 is 0.08647401273686209 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6837 is 0.08647275511044339 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6838 is 0.08647149791805735 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6839 is 0.08647024115938792 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6840 is 0.08646898483411913 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6841 is 0.08646772894193558 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6842 is 0.08646647348252202 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6843 is 0.08646521845556371 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6844 is 0.08646396386074609 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6845 is 0.08646270969775506 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6846 is 0.08646145596627677 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6847 is 0.08646020266599769 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6848 is 0.08645894979660476 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6849 is 0.0864576973577851 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6850 is 0.0864564453492262 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6851 is 0.08645519377061596 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6852 is 0.08645394262164255 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6853 is 0.08645269190199442 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6854 is 0.08645144161136042 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6855 is 0.08645019174942978 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6856 is 0.08644894231589192 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6857 is 0.08644769331043672 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6858 is 0.08644644473275433 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6859 is 0.08644519658253519 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6860 is 0.08644394885947014 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6861 is 0.08644270156325032 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6862 is 0.0864414546935672 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6863 is 0.08644020825011255 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6864 is 0.0864389622325785 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6865 is 0.0864377166406575 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6866 is 0.08643647147404232 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6867 is 0.086435226732426 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6868 is 0.08643398241550203 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6869 is 0.08643273852296413 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6870 is 0.08643149505450633 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6871 is 0.08643025200982302 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6872 is 0.08642900938860897 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6873 is 0.08642776719055911 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6874 is 0.08642652541536888 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6875 is 0.08642528406273395 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6876 is 0.08642404313235028 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6877 is 0.08642280262391416 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6878 is 0.08642156253712228 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6879 is 0.08642032287167153 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6880 is 0.08641908362725922 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6881 is 0.08641784480358293 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6882 is 0.0864166064003406 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6883 is 0.08641536841723037 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6884 is 0.08641413085395089 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6885 is 0.08641289371020093 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6886 is 0.0864116569856797 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6887 is 0.08641042068008666 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6888 is 0.08640918479312164 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6889 is 0.08640794932448478 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6890 is 0.08640671427387647 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6891 is 0.0864054796409975 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6892 is 0.08640424542554889 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6893 is 0.08640301162723199 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6894 is 0.08640177824574855 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6895 is 0.08640054528080053 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6896 is 0.08639931273209024 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6897 is 0.08639808059932033 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6898 is 0.08639684888219369 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6899 is 0.08639561758041357 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6900 is 0.08639438669368353 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6901 is 0.08639315622170744 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6902 is 0.08639192616418946 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6903 is 0.08639069652083407 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6904 is 0.08638946729134608 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6905 is 0.08638823847543048 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6906 is 0.0863870100727928 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6907 is 0.08638578208313866 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6908 is 0.08638455450617415 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6909 is 0.08638332734160549 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6910 is 0.0863821005891394 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6911 is 0.08638087424848274 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6912 is 0.08637964831934283 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6913 is 0.0863784228014271 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6914 is 0.0863771976944435 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6915 is 0.0863759729981001 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6916 is 0.08637474871210536 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6917 is 0.08637352483616809 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6918 is 0.08637230136999725 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6919 is 0.08637107831330226 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6920 is 0.08636985566579278 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6921 is 0.08636863342717874 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6922 is 0.08636741159717044 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6923 is 0.08636619017547838 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6924 is 0.08636496916181347 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6925 is 0.08636374855588684 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6926 is 0.08636252835740993 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6927 is 0.08636130856609453 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6928 is 0.0863600891816527 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6929 is 0.08635887020379673 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6930 is 0.08635765163223937 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6931 is 0.08635643346669342 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6932 is 0.08635521570687227 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6933 is 0.08635399835248934 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6934 is 0.08635278140325856 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6935 is 0.08635156485889395 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6936 is 0.08635034871910999 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6937 is 0.08634913298362146 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6938 is 0.08634791765214322 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6939 is 0.08634670272439074 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6940 is 0.08634548820007946 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6941 is 0.08634427407892539 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6942 is 0.08634306036064464 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6943 is 0.0863418470449537 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6944 is 0.08634063413156935 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6945 is 0.08633942162020865 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6946 is 0.0863382095105889 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6947 is 0.08633699780242779 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6948 is 0.08633578649544323 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6949 is 0.0863345755893534 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6950 is 0.08633336508387683 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6951 is 0.08633215497873234 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6952 is 0.08633094527363898 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6953 is 0.08632973596831615 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6954 is 0.08632852706248346 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6955 is 0.08632731855586089 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6956 is 0.08632611044816864 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6957 is 0.08632490273912727 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6958 is 0.08632369542845753 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6959 is 0.08632248851588056 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6960 is 0.0863212820011177 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6961 is 0.08632007588389058 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6962 is 0.08631887016392123 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6963 is 0.08631766484093183 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6964 is 0.08631645991464486 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6965 is 0.08631525538478316 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6966 is 0.08631405125106975 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6967 is 0.08631284751322803 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6968 is 0.08631164417098164 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6969 is 0.0863104412240545 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6970 is 0.08630923867217079 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6971 is 0.086308036515055 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6972 is 0.08630683475243191 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6973 is 0.0863056333840266 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6974 is 0.0863044324095643 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6975 is 0.08630323182877069 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6976 is 0.08630203164137162 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6977 is 0.0863008318470932 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6978 is 0.08629963244566198 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6979 is 0.08629843343680461 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6980 is 0.08629723482024805 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6981 is 0.08629603659571972 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6982 is 0.086294838762947 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6983 is 0.08629364132165775 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6984 is 0.08629244427158012 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6985 is 0.08629124761244245 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6986 is 0.0862900513439734 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6987 is 0.08628885546590191 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6988 is 0.08628765997795713 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6989 is 0.08628646487986863 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6990 is 0.08628527017136606 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6991 is 0.08628407585217944 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6992 is 0.08628288192203913 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6993 is 0.08628168838067568 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6994 is 0.08628049522781987 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6995 is 0.0862793024632029 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6996 is 0.08627811008655605 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6997 is 0.08627691809761107 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6998 is 0.08627572649609978 -------- Training accuracy = 97.0\n",
            "Cost after iteration 6999 is 0.0862745352817545 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7000 is 0.08627334445430752 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7001 is 0.08627215401349177 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7002 is 0.08627096395904009 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7003 is 0.08626977429068587 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7004 is 0.08626858500816258 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7005 is 0.08626739611120403 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7006 is 0.08626620759954433 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7007 is 0.08626501947291777 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7008 is 0.08626383173105899 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7009 is 0.0862626443737029 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7010 is 0.08626145740058459 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7011 is 0.08626027081143949 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7012 is 0.08625908460600325 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7013 is 0.08625789878401181 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7014 is 0.08625671334520146 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7015 is 0.08625552828930856 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7016 is 0.08625434361606993 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7017 is 0.08625315932522247 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7018 is 0.08625197541650353 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7019 is 0.08625079188965057 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7020 is 0.08624960874440143 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7021 is 0.08624842598049409 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7022 is 0.08624724359766693 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7023 is 0.08624606159565851 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7024 is 0.08624487997420761 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7025 is 0.08624369873305338 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7026 is 0.08624251787193514 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7027 is 0.08624133739059255 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7028 is 0.08624015728876544 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7029 is 0.08623897756619396 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7030 is 0.08623779822261851 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7031 is 0.08623661925777973 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7032 is 0.08623544067141851 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7033 is 0.08623426246327616 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7034 is 0.0862330846330939 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7035 is 0.08623190718061355 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7036 is 0.08623073010557701 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7037 is 0.08622955340772652 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7038 is 0.08622837708680445 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7039 is 0.0862272011425536 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7040 is 0.08622602557471688 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7041 is 0.08622485038303757 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7042 is 0.0862236755672591 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7043 is 0.08622250112712519 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7044 is 0.08622132706237985 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7045 is 0.08622015337276735 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7046 is 0.08621898005803218 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7047 is 0.08621780711791903 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7048 is 0.08621663455217296 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7049 is 0.08621546236053923 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7050 is 0.08621429054276328 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7051 is 0.08621311909859093 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7052 is 0.08621194802776815 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7053 is 0.08621077733004126 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7054 is 0.08620960700515673 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7055 is 0.08620843705286135 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7056 is 0.08620726747290212 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7057 is 0.08620609826502627 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7058 is 0.08620492942898138 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7059 is 0.08620376096451515 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7060 is 0.08620259287137565 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7061 is 0.0862014251493111 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7062 is 0.08620025779807002 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7063 is 0.0861990908174012 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7064 is 0.08619792420705362 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7065 is 0.08619675796677649 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7066 is 0.08619559209631934 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7067 is 0.08619442659543197 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7068 is 0.08619326146386436 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7069 is 0.08619209670136668 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7070 is 0.08619093230768947 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7071 is 0.08618976828258343 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7072 is 0.08618860462579958 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7073 is 0.08618744133708912 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7074 is 0.0861862784162035 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7075 is 0.08618511586289442 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7076 is 0.08618395367691387 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7077 is 0.08618279185801403 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7078 is 0.08618163040594734 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7079 is 0.0861804693204665 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7080 is 0.0861793086013244 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7081 is 0.08617814824827424 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7082 is 0.08617698826106938 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7083 is 0.08617582863946356 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7084 is 0.0861746693832106 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7085 is 0.08617351049206465 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7086 is 0.0861723519657801 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7087 is 0.08617119380411152 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7088 is 0.08617003600681383 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7089 is 0.08616887857364211 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7090 is 0.08616772150435165 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7091 is 0.08616656479869805 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7092 is 0.08616540845643711 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7093 is 0.08616425247732493 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7094 is 0.08616309686111771 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7095 is 0.08616194160757203 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7096 is 0.08616078671644468 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7097 is 0.0861596321874926 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7098 is 0.08615847802047306 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7099 is 0.08615732421514356 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7100 is 0.08615617077126174 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7101 is 0.08615501768858562 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7102 is 0.08615386496687333 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7103 is 0.08615271260588327 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7104 is 0.08615156060537417 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7105 is 0.0861504089651049 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7106 is 0.08614925768483453 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7107 is 0.08614810676432239 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7108 is 0.08614695620332817 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7109 is 0.08614580600161167 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7110 is 0.08614465615893288 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7111 is 0.08614350667505215 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7112 is 0.08614235754972997 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7113 is 0.08614120878272712 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7114 is 0.08614006037380456 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7115 is 0.08613891232272351 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7116 is 0.08613776462924541 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7117 is 0.08613661729313202 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7118 is 0.0861354703141451 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7119 is 0.08613432369204699 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7120 is 0.08613317742659987 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7121 is 0.08613203151756642 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7122 is 0.08613088596470952 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7123 is 0.08612974076779215 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7124 is 0.08612859592657762 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7125 is 0.08612745144082952 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7126 is 0.08612630731031146 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7127 is 0.08612516353478754 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7128 is 0.08612402011402188 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7129 is 0.08612287704777893 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7130 is 0.08612173433582339 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7131 is 0.0861205919779201 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7132 is 0.0861194499738342 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7133 is 0.08611830832333099 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7134 is 0.08611716702617604 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7135 is 0.08611602608213514 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7136 is 0.08611488549097436 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7137 is 0.08611374525245984 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7138 is 0.08611260536635815 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7139 is 0.08611146583243587 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7140 is 0.08611032665045998 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7141 is 0.0861091878201976 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7142 is 0.08610804934141608 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7143 is 0.08610691121388306 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7144 is 0.08610577343736625 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7145 is 0.08610463601163378 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7146 is 0.0861034989364538 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7147 is 0.08610236221159488 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7148 is 0.08610122583682564 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7149 is 0.08610008981191505 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7150 is 0.08609895413663222 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7151 is 0.08609781881074655 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7152 is 0.08609668383402756 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7153 is 0.0860955492062451 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7154 is 0.08609441492716917 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7155 is 0.08609328099657004 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7156 is 0.08609214741421814 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7157 is 0.08609101417988413 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7158 is 0.08608988129333899 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7159 is 0.08608874875435372 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7160 is 0.08608761656269978 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7161 is 0.08608648471814866 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7162 is 0.08608535322047213 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7163 is 0.08608422206944225 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7164 is 0.0860830912648311 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7165 is 0.08608196080641123 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7166 is 0.08608083069395525 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7167 is 0.08607970092723595 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7168 is 0.08607857150602655 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7169 is 0.0860774424301002 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7170 is 0.08607631369923045 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7171 is 0.08607518531319104 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7172 is 0.08607405727175592 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7173 is 0.0860729295746992 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7174 is 0.08607180222179531 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7175 is 0.08607067521281879 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7176 is 0.08606954854754441 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7177 is 0.08606842222574723 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7178 is 0.08606729624720245 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7179 is 0.08606617061168552 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7180 is 0.0860650453189721 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7181 is 0.08606392036883802 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7182 is 0.0860627957610594 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7183 is 0.08606167149541248 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7184 is 0.08606054757167375 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7185 is 0.08605942398962001 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7186 is 0.08605830074902811 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7187 is 0.08605717784967516 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7188 is 0.08605605529133857 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7189 is 0.08605493307379584 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7190 is 0.08605381119682479 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7191 is 0.08605268966020337 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7192 is 0.08605156846370976 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7193 is 0.08605044760712233 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7194 is 0.08604932709021976 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7195 is 0.0860482069127808 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7196 is 0.08604708707458447 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7197 is 0.08604596757541001 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7198 is 0.08604484841503689 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7199 is 0.08604372959324473 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7200 is 0.08604261110981339 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7201 is 0.08604149296452293 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7202 is 0.0860403751571536 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7203 is 0.08603925768748588 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7204 is 0.08603814055530051 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7205 is 0.0860370237603783 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7206 is 0.08603590730250037 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7207 is 0.08603479118144806 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7208 is 0.08603367539700284 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7209 is 0.08603255994894639 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7210 is 0.08603144483706067 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7211 is 0.08603033006112781 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7212 is 0.08602921562093009 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7213 is 0.0860281015162501 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7214 is 0.08602698774687051 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7215 is 0.0860258743125743 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7216 is 0.08602476121314459 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7217 is 0.08602364844836473 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7218 is 0.08602253601801829 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7219 is 0.08602142392188898 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7220 is 0.08602031215976078 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7221 is 0.08601920073141783 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7222 is 0.08601808963664452 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7223 is 0.08601697887522537 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7224 is 0.08601586844694513 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7225 is 0.0860147583515888 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7226 is 0.08601364858894152 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7227 is 0.08601253915878865 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7228 is 0.08601143006091576 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7229 is 0.08601032129510865 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7230 is 0.08600921286115318 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7231 is 0.08600810475883561 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7232 is 0.08600699698794227 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7233 is 0.08600588954825975 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7234 is 0.08600478243957474 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7235 is 0.08600367566167427 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7236 is 0.08600256921434547 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7237 is 0.08600146309737568 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7238 is 0.08600035731055244 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7239 is 0.08599925185366357 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7240 is 0.08599814672649697 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7241 is 0.08599704192884076 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7242 is 0.08599593746048334 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7243 is 0.08599483332121322 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7244 is 0.08599372951081917 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7245 is 0.08599262602909007 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7246 is 0.08599152287581505 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7247 is 0.08599042005078344 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7248 is 0.08598931755378485 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7249 is 0.08598821538460887 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7250 is 0.08598711354304545 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7251 is 0.0859860120288847 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7252 is 0.08598491084191692 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7253 is 0.0859838099819326 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7254 is 0.08598270944872242 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7255 is 0.0859816092420773 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7256 is 0.08598050936178826 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7257 is 0.08597940980764662 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7258 is 0.08597831057944379 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7259 is 0.08597721167697144 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7260 is 0.08597611310002141 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7261 is 0.08597501484838581 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7262 is 0.08597391692185673 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7263 is 0.08597281932022671 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7264 is 0.08597172204328832 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7265 is 0.08597062509083435 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7266 is 0.08596952846265783 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7267 is 0.0859684321585519 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7268 is 0.08596733617831 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7269 is 0.08596624052172569 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7270 is 0.08596514518859265 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7271 is 0.08596405017870493 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7272 is 0.08596295549185659 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7273 is 0.08596186112784197 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7274 is 0.08596076708645566 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7275 is 0.08595967336749226 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7276 is 0.08595857997074671 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7277 is 0.08595748689601414 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7278 is 0.08595639414308974 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7279 is 0.08595530171176904 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7280 is 0.08595420960184762 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7281 is 0.08595311781312132 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7282 is 0.08595202634538625 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7283 is 0.08595093519843852 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7284 is 0.08594984437207459 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7285 is 0.08594875386609097 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7286 is 0.08594766368028452 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7287 is 0.08594657381445213 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7288 is 0.08594548426839095 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7289 is 0.08594439504189837 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7290 is 0.08594330613477179 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7291 is 0.08594221754680899 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7292 is 0.08594112927780781 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7293 is 0.08594004132756634 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7294 is 0.08593895369588286 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7295 is 0.08593786638255578 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7296 is 0.08593677938738367 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7297 is 0.0859356927101654 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7298 is 0.08593460635069994 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7299 is 0.08593352030878647 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7300 is 0.08593243458422434 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7301 is 0.08593134917681307 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7302 is 0.08593026408635239 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7303 is 0.0859291793126422 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7304 is 0.08592809485548261 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7305 is 0.08592701071467385 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7306 is 0.08592592689001642 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7307 is 0.08592484338131091 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7308 is 0.08592376018835814 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7309 is 0.08592267731095911 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7310 is 0.08592159474891496 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7311 is 0.0859205125020271 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7312 is 0.08591943057009707 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7313 is 0.08591834895292653 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7314 is 0.08591726765031743 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7315 is 0.08591618666207179 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7316 is 0.08591510598799193 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7317 is 0.08591402562788023 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7318 is 0.08591294558153936 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7319 is 0.08591186584877206 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7320 is 0.08591078642938133 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7321 is 0.08590970732317031 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7322 is 0.08590862852994233 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7323 is 0.08590755004950094 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7324 is 0.08590647188164977 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7325 is 0.0859053940261927 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7326 is 0.0859043164829338 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7327 is 0.08590323925167724 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7328 is 0.08590216233222746 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7329 is 0.08590108572438897 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7330 is 0.08590000942796656 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7331 is 0.08589893344276517 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7332 is 0.08589785776858987 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7333 is 0.08589678240524598 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7334 is 0.08589570735253893 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7335 is 0.08589463261027429 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7336 is 0.08589355817825792 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7337 is 0.08589248405629585 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7338 is 0.08589141024419412 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7339 is 0.08589033674175915 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7340 is 0.08588926354879742 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7341 is 0.08588819066511556 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7342 is 0.08588711809052048 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7343 is 0.08588604582481918 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7344 is 0.08588497386781886 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7345 is 0.08588390221932687 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7346 is 0.08588283087915084 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7347 is 0.08588175984709838 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7348 is 0.08588068912297742 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7349 is 0.08587961870659602 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7350 is 0.08587854859776246 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7351 is 0.0858774787962851 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7352 is 0.08587640930197254 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7353 is 0.08587534011463353 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7354 is 0.08587427123407698 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7355 is 0.08587320266011197 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7356 is 0.08587213439254786 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7357 is 0.08587106643119398 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7358 is 0.08586999877585998 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7359 is 0.08586893142635563 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7360 is 0.08586786438249085 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7361 is 0.08586679764407582 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7362 is 0.0858657312109208 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7363 is 0.08586466508283623 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7364 is 0.08586359925963273 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7365 is 0.08586253374112118 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7366 is 0.08586146852711242 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7367 is 0.08586040361741766 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7368 is 0.08585933901184821 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7369 is 0.08585827471021555 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7370 is 0.08585721071233123 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7371 is 0.08585614701800716 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7372 is 0.08585508362705528 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7373 is 0.08585402053928769 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7374 is 0.08585295775451672 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7375 is 0.0858518952725549 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7376 is 0.08585083309321485 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7377 is 0.08584977121630935 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7378 is 0.08584870964165144 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7379 is 0.08584764836905422 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7380 is 0.08584658739833097 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7381 is 0.08584552672929524 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7382 is 0.08584446636176063 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7383 is 0.08584340629554094 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7384 is 0.08584234653045014 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7385 is 0.08584128706630244 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7386 is 0.08584022790291206 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7387 is 0.0858391690400935 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7388 is 0.08583811047766138 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7389 is 0.08583705221543056 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7390 is 0.08583599425321593 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7391 is 0.08583493659083263 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7392 is 0.08583387922809596 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7393 is 0.08583282216482142 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7394 is 0.08583176540082453 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7395 is 0.08583070893592114 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7396 is 0.08582965276992717 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7397 is 0.08582859690265873 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7398 is 0.08582754133393213 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7399 is 0.08582648606356372 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7400 is 0.08582543109137013 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7401 is 0.08582437641716814 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7402 is 0.08582332204077468 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7403 is 0.08582226796200679 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7404 is 0.08582121418068167 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7405 is 0.08582016069661683 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7406 is 0.08581910750962976 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7407 is 0.0858180546195382 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7408 is 0.08581700202616002 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7409 is 0.08581594972931328 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7410 is 0.08581489772881622 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7411 is 0.08581384602448713 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7412 is 0.08581279461614463 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7413 is 0.08581174350360732 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7414 is 0.08581069268669413 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7415 is 0.08580964216522396 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7416 is 0.08580859193901606 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7417 is 0.08580754200788972 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7418 is 0.08580649237166445 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7419 is 0.08580544303015981 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7420 is 0.08580439398319571 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7421 is 0.08580334523059203 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7422 is 0.0858022967721689 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7423 is 0.0858012486077466 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7424 is 0.08580020073714556 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7425 is 0.08579915316018641 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7426 is 0.08579810587668985 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7427 is 0.08579705888647673 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7428 is 0.08579601218936822 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7429 is 0.08579496578518549 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7430 is 0.08579391967374989 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7431 is 0.08579287385488298 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7432 is 0.08579182832840641 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7433 is 0.08579078309414206 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7434 is 0.08578973815191192 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7435 is 0.08578869350153816 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7436 is 0.08578764914284305 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7437 is 0.08578660507564904 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7438 is 0.08578556129977884 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7439 is 0.08578451781505511 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7440 is 0.08578347462130084 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7441 is 0.08578243171833917 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7442 is 0.0857813891059932 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7443 is 0.08578034678408646 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7444 is 0.08577930475244237 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7445 is 0.08577826301088474 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7446 is 0.08577722155923732 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7447 is 0.08577618039732424 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7448 is 0.08577513952496957 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7449 is 0.08577409894199765 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7450 is 0.08577305864823292 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7451 is 0.08577201864350005 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7452 is 0.08577097892762377 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7453 is 0.08576993950042902 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7454 is 0.08576890036174085 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7455 is 0.08576786151138456 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7456 is 0.08576682294918546 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7457 is 0.0857657846749691 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7458 is 0.08576474668856118 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7459 is 0.0857637089897875 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7460 is 0.08576267157847406 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7461 is 0.08576163445444702 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7462 is 0.08576059761753266 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7463 is 0.0857595610675574 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7464 is 0.08575852480434784 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7465 is 0.0857574888277307 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7466 is 0.08575645313753293 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7467 is 0.08575541773358147 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7468 is 0.08575438261570356 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7469 is 0.08575334778372659 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7470 is 0.08575231323747798 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7471 is 0.08575127897678536 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7472 is 0.08575024500147653 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7473 is 0.08574921131137946 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7474 is 0.08574817790632219 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7475 is 0.085747144786133 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7476 is 0.08574611195064018 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7477 is 0.08574507939967237 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7478 is 0.08574404713305814 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7479 is 0.08574301515062635 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7480 is 0.08574198345220604 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7481 is 0.08574095203762624 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7482 is 0.08573992090671627 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7483 is 0.08573889005930552 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7484 is 0.08573785949522353 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7485 is 0.08573682921430004 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7486 is 0.08573579921636491 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7487 is 0.08573476950124807 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7488 is 0.08573374006877976 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7489 is 0.08573271091879023 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7490 is 0.08573168205110988 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7491 is 0.08573065346556938 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7492 is 0.0857296251619994 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7493 is 0.08572859714023083 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7494 is 0.08572756940009467 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7495 is 0.0857265419414221 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7496 is 0.08572551476404444 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7497 is 0.08572448786779309 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7498 is 0.08572346125249976 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7499 is 0.08572243491799608 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7500 is 0.08572140886411404 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7501 is 0.08572038309068555 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7502 is 0.0857193575975429 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7503 is 0.08571833238451834 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7504 is 0.08571730745144436 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7505 is 0.08571628279815359 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7506 is 0.08571525842447869 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7507 is 0.08571423433025269 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7508 is 0.08571321051530847 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7509 is 0.08571218697947933 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7510 is 0.08571116372259856 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7511 is 0.08571014074449959 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7512 is 0.08570911804501603 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7513 is 0.0857080956239817 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7514 is 0.08570707348123038 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7515 is 0.08570605161659618 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7516 is 0.08570503002991325 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7517 is 0.08570400872101591 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7518 is 0.0857029876897386 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7519 is 0.08570196693591589 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7520 is 0.0857009464593826 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7521 is 0.08569992625997351 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7522 is 0.08569890633752374 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7523 is 0.08569788669186838 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7524 is 0.08569686732284269 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7525 is 0.08569584823028224 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7526 is 0.0856948294140225 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7527 is 0.08569381087389924 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7528 is 0.08569279260974827 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7529 is 0.08569177462140565 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7530 is 0.08569075690870745 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7531 is 0.08568973947149004 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7532 is 0.08568872230958975 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7533 is 0.08568770542284315 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7534 is 0.08568668881108697 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7535 is 0.08568567247415801 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7536 is 0.0856846564118933 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7537 is 0.08568364062412984 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7538 is 0.08568262511070493 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7539 is 0.08568160987145594 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7540 is 0.08568059490622046 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7541 is 0.08567958021483606 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7542 is 0.08567856579714062 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7543 is 0.085677551652972 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7544 is 0.08567653778216829 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7545 is 0.08567552418456775 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7546 is 0.0856745108600086 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7547 is 0.08567349780832945 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7548 is 0.08567248502936886 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7549 is 0.08567147252296561 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7550 is 0.08567046028895858 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7551 is 0.08566944832718677 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7552 is 0.08566843663748934 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7553 is 0.08566742521970565 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7554 is 0.08566641407367506 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7555 is 0.0856654031992372 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7556 is 0.08566439259623176 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7557 is 0.08566338226449852 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7558 is 0.0856623722038775 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7559 is 0.08566136241420881 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7560 is 0.08566035289533266 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7561 is 0.08565934364708949 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7562 is 0.08565833466931976 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7563 is 0.08565732596186414 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7564 is 0.0856563175245634 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7565 is 0.08565530935725843 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7566 is 0.08565430145979033 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7567 is 0.08565329383200021 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7568 is 0.08565228647372944 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7569 is 0.08565127938481946 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7570 is 0.08565027256511183 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7571 is 0.08564926601444828 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7572 is 0.08564825973267069 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7573 is 0.08564725371962091 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7574 is 0.08564624797514118 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7575 is 0.0856452424990737 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7576 is 0.08564423729126086 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7577 is 0.08564323235154515 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7578 is 0.0856422276797692 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7579 is 0.08564122327577581 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7580 is 0.08564021913940781 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7581 is 0.08563921527050834 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7582 is 0.08563821166892048 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7583 is 0.08563720833448757 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7584 is 0.08563620526705304 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7585 is 0.08563520246646042 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7586 is 0.08563419993255343 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7587 is 0.08563319766517585 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7588 is 0.08563219566417166 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7589 is 0.0856311939293849 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7590 is 0.08563019246065985 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7591 is 0.08562919125784076 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7592 is 0.08562819032077217 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7593 is 0.08562718964929865 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7594 is 0.08562618924326497 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7595 is 0.0856251891025159 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7596 is 0.08562418922689649 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7597 is 0.08562318961625184 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7598 is 0.08562219027042722 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7599 is 0.08562119118926792 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7600 is 0.08562019237261953 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7601 is 0.08561919382032768 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7602 is 0.08561819553223807 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7603 is 0.08561719750819664 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7604 is 0.08561619974804936 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7605 is 0.08561520225164237 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7606 is 0.08561420501882204 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7607 is 0.08561320804943463 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7608 is 0.08561221134332678 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7609 is 0.08561121490034505 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7610 is 0.08561021872033625 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7611 is 0.08560922280314733 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7612 is 0.08560822714862523 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7613 is 0.08560723175661722 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7614 is 0.0856062366269705 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7615 is 0.08560524175953259 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7616 is 0.08560424715415091 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7617 is 0.08560325281067319 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7618 is 0.08560225872894718 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7619 is 0.08560126490882088 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7620 is 0.0856002713501422 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7621 is 0.08559927805275944 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7622 is 0.08559828501652082 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7623 is 0.0855972922412748 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7624 is 0.08559629972686987 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7625 is 0.08559530747315476 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7626 is 0.08559431547997824 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7627 is 0.08559332374718921 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7628 is 0.08559233227463674 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7629 is 0.08559134106217003 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7630 is 0.08559035010963828 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7631 is 0.08558935941689103 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7632 is 0.0855883689837777 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7633 is 0.08558737881014797 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7634 is 0.08558638889585173 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7635 is 0.08558539924073881 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7636 is 0.08558440984465925 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7637 is 0.08558342070746322 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7638 is 0.08558243182900101 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7639 is 0.08558144320912302 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7640 is 0.08558045484767975 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7641 is 0.08557946674452194 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7642 is 0.08557847889950027 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7643 is 0.08557749131246566 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7644 is 0.08557650398326914 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7645 is 0.08557551691176185 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7646 is 0.08557453009779503 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7647 is 0.08557354354122011 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7648 is 0.08557255724188857 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7649 is 0.08557157119965204 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7650 is 0.08557058541436226 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7651 is 0.08556959988587115 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7652 is 0.0855686146140306 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7653 is 0.08556762959869282 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7654 is 0.08556664483971001 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7655 is 0.08556566033693454 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7656 is 0.08556467609021887 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7657 is 0.08556369209941558 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7658 is 0.08556270836437742 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7659 is 0.08556172488495725 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7660 is 0.08556074166100795 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7661 is 0.0855597586923827 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7662 is 0.08555877597893459 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7663 is 0.08555779352051701 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7664 is 0.08555681131698337 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7665 is 0.08555582936818726 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7666 is 0.08555484767398226 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7667 is 0.0855538662342223 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7668 is 0.08555288504876123 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7669 is 0.08555190411745306 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7670 is 0.085550923440152 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7671 is 0.08554994301671226 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7672 is 0.08554896284698828 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7673 is 0.08554798293083454 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7674 is 0.0855470032681057 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7675 is 0.08554602385865645 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7676 is 0.0855450447023417 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7677 is 0.08554406579901642 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7678 is 0.08554308714853569 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7679 is 0.08554210875075477 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7680 is 0.08554113060552895 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7681 is 0.08554015271271372 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7682 is 0.0855391750721646 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7683 is 0.08553819768373731 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7684 is 0.08553722054728764 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7685 is 0.08553624366267157 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7686 is 0.08553526702974504 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7687 is 0.08553429064836425 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7688 is 0.08553331451838549 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7689 is 0.08553233863966511 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7690 is 0.08553136301205967 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7691 is 0.08553038763542573 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7692 is 0.08552941250962004 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7693 is 0.08552843763449944 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7694 is 0.08552746300992094 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7695 is 0.0855264886357416 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7696 is 0.08552551451181858 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7697 is 0.08552454063800925 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7698 is 0.08552356701417103 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7699 is 0.08552259364016143 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7700 is 0.08552162051583814 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7701 is 0.08552064764105895 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7702 is 0.08551967501568167 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7703 is 0.08551870263956438 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7704 is 0.0855177305125652 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7705 is 0.08551675863454229 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7706 is 0.08551578700535405 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7707 is 0.08551481562485896 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7708 is 0.08551384449291553 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7709 is 0.08551287360938252 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7710 is 0.08551190297411868 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7711 is 0.08551093258698296 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7712 is 0.08550996244783432 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7713 is 0.085508992556532 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7714 is 0.08550802291293519 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7715 is 0.08550705351690328 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7716 is 0.08550608436829575 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7717 is 0.08550511546697222 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7718 is 0.08550414681279231 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7719 is 0.08550317840561594 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7720 is 0.08550221024530304 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7721 is 0.08550124233171358 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7722 is 0.08550027466470776 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7723 is 0.08549930724414588 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7724 is 0.08549834006988827 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7725 is 0.08549737314179541 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7726 is 0.08549640645972797 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7727 is 0.08549544002354664 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7728 is 0.08549447383311223 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7729 is 0.08549350788828566 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7730 is 0.08549254218892806 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7731 is 0.08549157673490054 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7732 is 0.08549061152606438 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7733 is 0.08548964656228093 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7734 is 0.08548868184341175 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7735 is 0.08548771736931839 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7736 is 0.0854867531398626 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7737 is 0.08548578915490619 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7738 is 0.08548482541431113 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7739 is 0.0854838619179394 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7740 is 0.08548289866565323 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7741 is 0.08548193565731481 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7742 is 0.08548097289278661 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7743 is 0.08548001037193101 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7744 is 0.08547904809461074 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7745 is 0.08547808606068838 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7746 is 0.08547712427002678 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7747 is 0.08547616272248891 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7748 is 0.08547520141793778 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7749 is 0.08547424035623649 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7750 is 0.08547327953724833 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7751 is 0.08547231896083668 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7752 is 0.08547135862686496 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7753 is 0.08547039853519678 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7754 is 0.0854694386856958 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7755 is 0.08546847907822587 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7756 is 0.08546751971265083 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7757 is 0.08546656058883473 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7758 is 0.08546560170664166 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7759 is 0.08546464306593587 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7760 is 0.08546368466658166 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7761 is 0.0854627265084435 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7762 is 0.08546176859138593 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7763 is 0.08546081091527362 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7764 is 0.08545985347997129 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7765 is 0.08545889628534385 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7766 is 0.0854579393312563 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7767 is 0.08545698261757369 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7768 is 0.08545602614416119 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7769 is 0.08545506991088413 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7770 is 0.08545411391760789 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7771 is 0.08545315816419802 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7772 is 0.08545220265052011 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7773 is 0.08545124737643989 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7774 is 0.08545029234182318 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7775 is 0.08544933754653593 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7776 is 0.08544838299044416 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7777 is 0.08544742867341408 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7778 is 0.08544647459531181 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7779 is 0.08544552075600384 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7780 is 0.08544456715535659 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7781 is 0.0854436137932366 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7782 is 0.08544266066951058 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7783 is 0.0854417077840453 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7784 is 0.08544075513670765 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7785 is 0.0854398027273646 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7786 is 0.08543885055588325 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7787 is 0.08543789862213078 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7788 is 0.08543694692597457 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7789 is 0.08543599546728192 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7790 is 0.08543504424592042 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7791 is 0.08543409326175765 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7792 is 0.08543314251466132 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7793 is 0.08543219200449931 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7794 is 0.08543124173113947 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7795 is 0.08543029169444989 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7796 is 0.08542934189429867 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7797 is 0.08542839233055408 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7798 is 0.08542744300308441 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7799 is 0.08542649391175819 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7800 is 0.08542554505644388 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7801 is 0.08542459643701016 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7802 is 0.08542364805332583 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7803 is 0.08542269990525969 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7804 is 0.0854217519926807 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7805 is 0.08542080431545795 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7806 is 0.08541985687346063 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7807 is 0.08541890966655795 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7808 is 0.08541796269461928 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7809 is 0.08541701595751414 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7810 is 0.08541606945511206 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7811 is 0.08541512318728271 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7812 is 0.08541417715389593 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7813 is 0.08541323135482154 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7814 is 0.08541228578992954 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7815 is 0.08541134045909 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7816 is 0.08541039536217312 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7817 is 0.08540945049904919 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7818 is 0.08540850586958859 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7819 is 0.08540756147366178 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7820 is 0.08540661731113938 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7821 is 0.08540567338189207 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7822 is 0.08540472968579066 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7823 is 0.08540378622270602 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7824 is 0.08540284299250907 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7825 is 0.08540189999507106 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7826 is 0.08540095723026304 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7827 is 0.08540001469795636 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7828 is 0.08539907239802243 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7829 is 0.08539813033033271 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7830 is 0.08539718849475883 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7831 is 0.08539624689117244 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7832 is 0.08539530551944531 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7833 is 0.08539436437944942 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7834 is 0.08539342347105668 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7835 is 0.08539248279413918 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7836 is 0.08539154234856917 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7837 is 0.08539060213421892 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7838 is 0.08538966215096079 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7839 is 0.08538872239866728 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7840 is 0.085387782877211 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7841 is 0.08538684358646456 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7842 is 0.08538590452630081 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7843 is 0.08538496569659262 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7844 is 0.08538402709721295 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7845 is 0.08538308872803488 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7846 is 0.08538215058893163 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7847 is 0.08538121267977643 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7848 is 0.08538027500044268 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7849 is 0.0853793375508038 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7850 is 0.08537840033073345 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7851 is 0.08537746334010521 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7852 is 0.08537652657879284 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7853 is 0.08537559004667021 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7854 is 0.08537465374361139 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7855 is 0.0853737176694903 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7856 is 0.08537278182418112 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7857 is 0.08537184620755812 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7858 is 0.08537091081949573 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7859 is 0.08536997565986822 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7860 is 0.08536904072855027 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7861 is 0.08536810602541645 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7862 is 0.08536717155034147 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7863 is 0.08536623730320024 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7864 is 0.08536530328386766 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7865 is 0.08536436949221872 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7866 is 0.08536343592812856 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7867 is 0.08536250259147245 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7868 is 0.08536156948212559 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7869 is 0.08536063659996343 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7870 is 0.08535970394486152 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7871 is 0.08535877151669542 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7872 is 0.08535783931534084 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7873 is 0.08535690734067354 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7874 is 0.08535597559256941 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7875 is 0.0853550440709045 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7876 is 0.0853541127755548 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7877 is 0.08535318170639647 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7878 is 0.08535225086330589 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7879 is 0.08535132024615925 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7880 is 0.08535038985483315 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7881 is 0.08534945968920411 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7882 is 0.08534852974914872 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7883 is 0.08534760003454378 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7884 is 0.0853466705452661 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7885 is 0.0853457412811926 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7886 is 0.08534481224220028 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7887 is 0.08534388342816628 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7888 is 0.08534295483896778 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7889 is 0.08534202647448218 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7890 is 0.08534109833458677 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7891 is 0.0853401704191591 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7892 is 0.08533924272807673 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7893 is 0.08533831526121734 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7894 is 0.08533738801845872 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7895 is 0.08533646099967869 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7896 is 0.08533553420475526 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7897 is 0.08533460763356646 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7898 is 0.0853336812859904 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7899 is 0.08533275516190535 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7900 is 0.08533182926118967 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7901 is 0.08533090358372175 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7902 is 0.08532997812938005 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7903 is 0.08532905289804331 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7904 is 0.0853281278895901 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7905 is 0.08532720310389928 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7906 is 0.08532627854084973 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7907 is 0.08532535420032039 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7908 is 0.08532443008219034 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7909 is 0.08532350618633883 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7910 is 0.08532258251264498 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7911 is 0.08532165906098818 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7912 is 0.08532073583124787 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7913 is 0.0853198128233036 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7914 is 0.08531889003703498 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7915 is 0.08531796747232175 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7916 is 0.0853170451290436 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7917 is 0.08531612300708054 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7918 is 0.08531520110631248 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7919 is 0.08531427942661954 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7920 is 0.08531335796788189 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7921 is 0.08531243672997975 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7922 is 0.08531151571279345 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7923 is 0.08531059491620349 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7924 is 0.08530967434009037 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7925 is 0.08530875398433473 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7926 is 0.08530783384881721 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7927 is 0.08530691393341869 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7928 is 0.08530599423801997 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7929 is 0.08530507476250213 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7930 is 0.08530415550674617 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7931 is 0.0853032364706333 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7932 is 0.08530231765404472 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7933 is 0.08530139905686179 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7934 is 0.08530048067896594 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7935 is 0.08529956252023867 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7936 is 0.08529864458056159 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7937 is 0.08529772685981644 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7938 is 0.08529680935788496 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7939 is 0.08529589207464904 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7940 is 0.08529497500999061 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7941 is 0.08529405816379182 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7942 is 0.08529314153593469 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7943 is 0.08529222512630151 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7944 is 0.08529130893477459 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7945 is 0.08529039296123635 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7946 is 0.08528947720556929 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7947 is 0.08528856166765596 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7948 is 0.08528764634737908 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7949 is 0.08528673124462134 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7950 is 0.08528581635926567 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7951 is 0.08528490169119494 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7952 is 0.08528398724029222 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7953 is 0.0852830730064406 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7954 is 0.08528215898952331 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7955 is 0.08528124518942358 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7956 is 0.08528033160602486 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7957 is 0.08527941823921054 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7958 is 0.08527850508886423 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7959 is 0.08527759215486952 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7960 is 0.08527667943711018 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7961 is 0.08527576693546997 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7962 is 0.08527485464983282 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7963 is 0.0852739425800827 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7964 is 0.08527303072610372 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7965 is 0.08527211908778004 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7966 is 0.08527120766499585 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7967 is 0.08527029645763552 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7968 is 0.08526938546558348 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7969 is 0.0852684746887242 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7970 is 0.08526756412694228 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7971 is 0.08526665378012246 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7972 is 0.0852657436481494 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7973 is 0.08526483373090804 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7974 is 0.08526392402828326 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7975 is 0.08526301454016012 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7976 is 0.08526210526642373 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7977 is 0.08526119620695924 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7978 is 0.08526028736165198 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7979 is 0.08525937873038726 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7980 is 0.08525847031305059 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7981 is 0.08525756210952745 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7982 is 0.0852566541197035 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7983 is 0.08525574634346443 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7984 is 0.08525483878069606 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7985 is 0.08525393143128424 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7986 is 0.08525302429511489 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7987 is 0.08525211737207412 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7988 is 0.08525121066204806 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7989 is 0.08525030416492292 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7990 is 0.08524939788058493 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7991 is 0.08524849180892059 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7992 is 0.0852475859498163 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7993 is 0.08524668030315859 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7994 is 0.08524577486883414 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7995 is 0.08524486964672967 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7996 is 0.08524396463673198 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7997 is 0.08524305983872796 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7998 is 0.08524215525260456 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7999 is 0.08524125087824888 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8000 is 0.08524034671554802 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8001 is 0.08523944276438922 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8002 is 0.08523853902465982 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8003 is 0.08523763549624716 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8004 is 0.08523673217903877 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8005 is 0.08523582907292215 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8006 is 0.08523492617778498 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8007 is 0.08523402349351497 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8008 is 0.08523312101999993 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8009 is 0.08523221875712773 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8010 is 0.0852313167047864 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8011 is 0.08523041486286395 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8012 is 0.08522951323124851 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8013 is 0.08522861180982834 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8014 is 0.08522771059849175 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8015 is 0.0852268095971271 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8016 is 0.08522590880562278 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8017 is 0.08522500822386751 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8018 is 0.08522410785174982 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8019 is 0.08522320768915842 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8020 is 0.08522230773598216 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8021 is 0.08522140799210985 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8022 is 0.08522050845743054 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8023 is 0.08521960913183317 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8024 is 0.08521871001520696 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8025 is 0.08521781110744106 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8026 is 0.08521691240842474 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8027 is 0.08521601391804746 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8028 is 0.0852151156361986 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8029 is 0.0852142175627677 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8030 is 0.08521331969764435 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8031 is 0.08521242204071834 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8032 is 0.08521152459187932 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8033 is 0.08521062735101725 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8034 is 0.08520973031802201 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8035 is 0.0852088334927836 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8036 is 0.08520793687519217 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8037 is 0.0852070404651379 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8038 is 0.08520614426251098 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8039 is 0.08520524826720187 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8040 is 0.0852043524791009 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8041 is 0.08520345689809855 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8042 is 0.08520256152408547 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8043 is 0.08520166635695232 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8044 is 0.08520077139658977 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8045 is 0.08519987664288872 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8046 is 0.08519898209574008 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8047 is 0.08519808775503471 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8048 is 0.08519719362066383 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8049 is 0.08519629969251848 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8050 is 0.08519540597048988 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8051 is 0.08519451245446939 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8052 is 0.0851936191443483 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8053 is 0.08519272604001818 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8054 is 0.08519183314137052 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8055 is 0.0851909404482969 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8056 is 0.08519004796068903 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8057 is 0.08518915567843875 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8058 is 0.08518826360143783 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8059 is 0.08518737172957824 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8060 is 0.08518648006275199 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8061 is 0.08518558860085121 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8062 is 0.085184697343768 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8063 is 0.08518380629139466 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8064 is 0.08518291544362343 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8065 is 0.08518202480034685 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8066 is 0.08518113436145731 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8067 is 0.08518024412684738 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8068 is 0.08517935409640974 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8069 is 0.08517846427003707 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8070 is 0.08517757464762217 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8071 is 0.08517668522905794 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8072 is 0.08517579601423732 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8073 is 0.08517490700305332 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8074 is 0.08517401819539906 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8075 is 0.08517312959116771 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8076 is 0.08517224119025257 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8077 is 0.08517135299254695 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8078 is 0.08517046499794426 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8079 is 0.085169577206338 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8080 is 0.08516868961762175 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8081 is 0.08516780223168921 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8082 is 0.085166915048434 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8083 is 0.08516602806774998 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8084 is 0.08516514128953104 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8085 is 0.0851642547136711 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8086 is 0.08516336834006424 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8087 is 0.08516248216860452 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8088 is 0.08516159619918616 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8089 is 0.08516071043170345 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8090 is 0.08515982486605067 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8091 is 0.08515893950212226 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8092 is 0.08515805433981274 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8093 is 0.08515716937901661 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8094 is 0.08515628461962858 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8095 is 0.08515540006154333 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8096 is 0.08515451570465571 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8097 is 0.08515363154886056 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8098 is 0.0851527475940528 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8099 is 0.08515186384012748 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8100 is 0.08515098028697968 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8101 is 0.08515009693450465 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8102 is 0.08514921378259759 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8103 is 0.0851483308311538 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8104 is 0.08514744808006873 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8105 is 0.08514656552923783 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8106 is 0.08514568317855663 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8107 is 0.08514480102792082 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8108 is 0.0851439190772261 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8109 is 0.08514303732636819 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8110 is 0.08514215577524294 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8111 is 0.08514127442374636 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8112 is 0.08514039327177443 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8113 is 0.08513951231922312 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8114 is 0.08513863156598873 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8115 is 0.08513775101196741 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8116 is 0.08513687065705546 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8117 is 0.08513599050114928 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8118 is 0.08513511054414531 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8119 is 0.08513423078594008 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8120 is 0.0851333512264302 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8121 is 0.08513247186551234 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8122 is 0.0851315927030832 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8123 is 0.08513071373903967 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8124 is 0.0851298349732786 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8125 is 0.08512895640569695 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8126 is 0.08512807803619184 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8127 is 0.08512719986466027 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8128 is 0.08512632189099952 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8129 is 0.08512544411510684 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8130 is 0.08512456653687953 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8131 is 0.08512368915621503 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8132 is 0.08512281197301085 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8133 is 0.08512193498716451 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8134 is 0.08512105819857364 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8135 is 0.08512018160713594 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8136 is 0.08511930521274923 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8137 is 0.0851184290153113 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8138 is 0.08511755301472008 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8139 is 0.08511667721087365 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8140 is 0.08511580160367001 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8141 is 0.08511492619300728 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8142 is 0.08511405097878373 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8143 is 0.0851131759608976 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8144 is 0.08511230113924727 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8145 is 0.08511142651373119 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8146 is 0.08511055208424782 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8147 is 0.0851096778506958 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8148 is 0.08510880381297373 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8149 is 0.08510792997098025 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8150 is 0.08510705632461434 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8151 is 0.08510618287377474 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8152 is 0.08510530961836042 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8153 is 0.08510443655827038 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8154 is 0.08510356369340374 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8155 is 0.08510269102365957 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8156 is 0.08510181854893713 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8157 is 0.08510094626913577 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8158 is 0.0851000741841548 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8159 is 0.08509920229389366 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8160 is 0.08509833059825186 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8161 is 0.08509745909712901 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8162 is 0.08509658779042474 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8163 is 0.08509571667803878 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8164 is 0.0850948457598709 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8165 is 0.08509397503582103 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8166 is 0.08509310450578905 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8167 is 0.08509223416967494 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8168 is 0.08509136402737887 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8169 is 0.08509049407880094 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8170 is 0.08508962432384136 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8171 is 0.08508875476240042 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8172 is 0.08508788539437849 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8173 is 0.08508701621967601 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8174 is 0.0850861472381935 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8175 is 0.08508527844983146 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8176 is 0.08508440985449062 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8177 is 0.08508354145207161 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8178 is 0.0850826732424753 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8179 is 0.08508180522560245 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8180 is 0.08508093740135406 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8181 is 0.08508006976963113 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8182 is 0.08507920233033466 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8183 is 0.08507833508336578 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8184 is 0.08507746802862579 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8185 is 0.08507660116601581 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8186 is 0.08507573449543732 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8187 is 0.08507486801679168 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8188 is 0.08507400172998034 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8189 is 0.0850731356349049 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8190 is 0.08507226973146693 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8191 is 0.08507140401956821 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8192 is 0.08507053849911037 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8193 is 0.08506967316999534 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8194 is 0.08506880803212495 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8195 is 0.0850679430854012 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8196 is 0.08506707832972611 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8197 is 0.08506621376500183 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8198 is 0.08506534939113047 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8199 is 0.08506448520801431 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8200 is 0.08506362121555562 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8201 is 0.08506275741365679 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8202 is 0.08506189380222029 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8203 is 0.0850610303811486 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8204 is 0.08506016715034437 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8205 is 0.08505930410971019 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8206 is 0.08505844125914878 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8207 is 0.08505757859856294 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8208 is 0.08505671612785559 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8209 is 0.08505585384692953 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8210 is 0.08505499175568781 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8211 is 0.08505412985403356 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8212 is 0.08505326814186978 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8213 is 0.08505240661909975 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8214 is 0.08505154528562675 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8215 is 0.08505068414135404 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8216 is 0.08504982318618504 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8217 is 0.0850489624200233 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8218 is 0.08504810184277223 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8219 is 0.08504724145433551 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8220 is 0.08504638125461678 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8221 is 0.08504552124351979 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8222 is 0.08504466142094834 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8223 is 0.08504380178680626 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8224 is 0.08504294234099755 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8225 is 0.08504208308342619 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8226 is 0.08504122401399627 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8227 is 0.08504036513261187 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8228 is 0.08503950643917728 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8229 is 0.08503864793359671 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8230 is 0.0850377896157745 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8231 is 0.08503693148561507 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8232 is 0.08503607354302292 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8233 is 0.08503521578790255 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8234 is 0.08503435822015859 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8235 is 0.08503350083969569 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8236 is 0.08503264364641859 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8237 is 0.0850317866402321 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8238 is 0.08503092982104112 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8239 is 0.08503007318875055 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8240 is 0.08502921674326537 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8241 is 0.08502836048449072 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8242 is 0.08502750441233169 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8243 is 0.08502664852669349 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8244 is 0.08502579282748136 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8245 is 0.0850249373146007 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8246 is 0.08502408198795684 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8247 is 0.08502322684745524 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8248 is 0.0850223718930015 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8249 is 0.08502151712450112 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8250 is 0.08502066254185989 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8251 is 0.0850198081449834 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8252 is 0.08501895393377751 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8253 is 0.08501809990814807 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8254 is 0.08501724606800098 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8255 is 0.08501639241324224 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8256 is 0.08501553894377795 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8257 is 0.08501468565951416 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8258 is 0.08501383256035708 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8259 is 0.08501297964621292 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8260 is 0.08501212691698802 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8261 is 0.08501127437258876 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8262 is 0.08501042201292161 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8263 is 0.08500956983789304 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8264 is 0.08500871784740961 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8265 is 0.08500786604137792 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8266 is 0.08500701441970478 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8267 is 0.08500616298229687 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8268 is 0.08500531172906106 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8269 is 0.0850044606599042 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8270 is 0.0850036097747333 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8271 is 0.08500275907345531 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8272 is 0.08500190855597736 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8273 is 0.08500105822220659 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8274 is 0.08500020807205026 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8275 is 0.08499935810541558 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8276 is 0.08499850832220991 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8277 is 0.08499765872234065 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8278 is 0.08499680930571529 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8279 is 0.08499596007224132 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8280 is 0.08499511102182643 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8281 is 0.08499426215437811 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8282 is 0.08499341346980425 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8283 is 0.08499256496801258 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8284 is 0.08499171664891092 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8285 is 0.08499086851240722 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8286 is 0.08499002055840942 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8287 is 0.08498917278682559 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8288 is 0.08498832519756382 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8289 is 0.08498747779053227 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8290 is 0.08498663056563921 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8291 is 0.08498578352279286 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8292 is 0.08498493666190161 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8293 is 0.08498408998287393 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8294 is 0.08498324348561823 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8295 is 0.08498239717004304 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8296 is 0.08498155103605703 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8297 is 0.08498070508356884 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8298 is 0.08497985931248717 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8299 is 0.08497901372272083 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8300 is 0.08497816831417873 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8301 is 0.08497732308676971 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8302 is 0.0849764780404028 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8303 is 0.08497563317498702 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8304 is 0.0849747884904315 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8305 is 0.08497394398664541 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8306 is 0.0849730996635379 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8307 is 0.08497225552101834 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8308 is 0.08497141155899605 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8309 is 0.0849705677773805 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8310 is 0.08496972417608109 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8311 is 0.08496888075500743 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8312 is 0.08496803751406908 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8313 is 0.0849671944531757 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8314 is 0.08496635157223699 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8315 is 0.08496550887116279 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8316 is 0.08496466634986291 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8317 is 0.08496382400824726 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8318 is 0.08496298184622586 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8319 is 0.0849621398637087 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8320 is 0.08496129806060584 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8321 is 0.08496045643682748 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8322 is 0.08495961499228383 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8323 is 0.08495877372688518 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8324 is 0.08495793264054183 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8325 is 0.08495709173316415 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8326 is 0.08495625100466268 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8327 is 0.08495541045494792 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8328 is 0.08495457008393043 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8329 is 0.08495372989152083 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8330 is 0.0849528898776299 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8331 is 0.0849520500421683 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8332 is 0.08495121038504692 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8333 is 0.08495037090617663 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8334 is 0.08494953160546838 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8335 is 0.08494869248283314 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8336 is 0.08494785353818202 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8337 is 0.08494701477142613 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8338 is 0.08494617618247666 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8339 is 0.08494533777124487 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8340 is 0.08494449953764202 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8341 is 0.08494366148157947 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8342 is 0.08494282360296875 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8343 is 0.08494198590172121 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8344 is 0.0849411483777485 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8345 is 0.08494031103096218 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8346 is 0.08493947386127394 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8347 is 0.08493863686859549 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8348 is 0.0849378000528386 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8349 is 0.08493696341391514 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8350 is 0.08493612695173701 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8351 is 0.08493529066621616 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8352 is 0.08493445455726464 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8353 is 0.08493361862479452 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8354 is 0.08493278286871793 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8355 is 0.08493194728894711 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8356 is 0.08493111188539422 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8357 is 0.08493027665797172 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8358 is 0.08492944160659192 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8359 is 0.08492860673116728 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8360 is 0.08492777203161025 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8361 is 0.08492693750783341 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8362 is 0.08492610315974941 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8363 is 0.08492526898727092 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8364 is 0.08492443499031058 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8365 is 0.08492360116878135 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8366 is 0.08492276752259592 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8367 is 0.08492193405166729 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8368 is 0.08492110075590839 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8369 is 0.08492026763523229 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8370 is 0.08491943468955204 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8371 is 0.08491860191878077 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8372 is 0.08491776932283171 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8373 is 0.08491693690161817 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8374 is 0.08491610465505335 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8375 is 0.0849152725830507 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8376 is 0.08491444068552365 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8377 is 0.08491360896238569 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8378 is 0.08491277741355036 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8379 is 0.0849119460389313 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8380 is 0.08491111483844217 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8381 is 0.08491028381199665 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8382 is 0.08490945295950862 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8383 is 0.08490862228089181 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8384 is 0.08490779177606018 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8385 is 0.08490696144492768 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8386 is 0.08490613128740832 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8387 is 0.08490530130341616 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8388 is 0.08490447149286537 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8389 is 0.08490364185567008 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8390 is 0.0849028123917446 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8391 is 0.08490198310100319 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8392 is 0.08490115398336018 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8393 is 0.08490032503873006 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8394 is 0.08489949626702722 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8395 is 0.08489866766816628 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8396 is 0.08489783924206179 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8397 is 0.08489701098862838 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8398 is 0.08489618290778077 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8399 is 0.08489535499943372 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8400 is 0.08489452726350202 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8401 is 0.08489369969990056 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8402 is 0.08489287230854427 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8403 is 0.08489204508934815 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8404 is 0.08489121804222724 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8405 is 0.08489039116709664 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8406 is 0.0848895644638715 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8407 is 0.08488873793246701 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8408 is 0.08488791157279849 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8409 is 0.08488708538478122 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8410 is 0.08488625936833058 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8411 is 0.08488543352336209 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8412 is 0.08488460784979121 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8413 is 0.0848837823475334 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8414 is 0.08488295701650432 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8415 is 0.08488213185661972 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8416 is 0.0848813068677952 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8417 is 0.08488048204994662 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8418 is 0.08487965740298978 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8419 is 0.08487883292684055 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8420 is 0.0848780086214149 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8421 is 0.08487718448662883 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8422 is 0.0848763605223984 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8423 is 0.08487553672863969 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8424 is 0.08487471310526892 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8425 is 0.08487388965220224 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8426 is 0.08487306636935597 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8427 is 0.08487224325664645 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8428 is 0.08487142031399007 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8429 is 0.08487059754130327 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8430 is 0.08486977493850253 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8431 is 0.08486895250550448 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8432 is 0.08486813024222563 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8433 is 0.08486730814858269 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8434 is 0.0848664862244924 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8435 is 0.08486566446987151 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8436 is 0.08486484288463686 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8437 is 0.08486402146870534 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8438 is 0.08486320022199388 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8439 is 0.08486237914441952 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8440 is 0.08486155823589926 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8441 is 0.08486073749635024 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8442 is 0.0848599169256896 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8443 is 0.08485909652383457 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8444 is 0.08485827629070242 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8445 is 0.08485745622621042 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8446 is 0.08485663633027606 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8447 is 0.0848558166028167 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8448 is 0.0848549970437498 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8449 is 0.08485417765299301 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8450 is 0.08485335843046382 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8451 is 0.08485253937607999 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8452 is 0.08485172048975907 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8453 is 0.084850901771419 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8454 is 0.08485008322097745 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8455 is 0.08484926483835241 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8456 is 0.0848484466234617 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8457 is 0.08484762857622338 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8458 is 0.08484681069655545 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8459 is 0.08484599298437594 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8460 is 0.08484517543960308 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8461 is 0.08484435806215501 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8462 is 0.08484354085194996 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8463 is 0.08484272380890628 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8464 is 0.08484190693294234 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8465 is 0.08484109022397651 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8466 is 0.08484027368192724 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8467 is 0.08483945730671305 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8468 is 0.08483864109825254 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8469 is 0.0848378250564643 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8470 is 0.08483700918126702 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8471 is 0.08483619347257944 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8472 is 0.08483537793032034 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8473 is 0.08483456255440855 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8474 is 0.08483374734476293 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8475 is 0.0848329323013025 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8476 is 0.08483211742394615 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8477 is 0.08483130271261304 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8478 is 0.08483048816722219 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8479 is 0.0848296737876928 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8480 is 0.08482885957394404 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8481 is 0.08482804552589521 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8482 is 0.08482723164346559 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8483 is 0.08482641792657461 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8484 is 0.08482560437514157 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8485 is 0.08482479098908606 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8486 is 0.08482397776832755 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8487 is 0.08482316471278563 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8488 is 0.08482235182237995 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8489 is 0.08482153909703012 -------- Training accuracy = 97.0\n",
            "Cost after iteration 8490 is 0.08482072653665598 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8491 is 0.08481991414117725 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8492 is 0.08481910191051374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8493 is 0.08481828984458542 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8494 is 0.08481747794331222 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8495 is 0.0848166662066141 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8496 is 0.08481585463441114 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8497 is 0.08481504322662342 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8498 is 0.08481423198317109 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8499 is 0.08481342090397437 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8500 is 0.08481260998895351 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8501 is 0.08481179923802885 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8502 is 0.08481098865112074 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8503 is 0.08481017822814951 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8504 is 0.08480936796903578 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8505 is 0.08480855787369997 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8506 is 0.08480774794206261 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8507 is 0.0848069381740444 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8508 is 0.08480612856956599 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8509 is 0.0848053191285481 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8510 is 0.08480450985091151 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8511 is 0.08480370073657702 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8512 is 0.08480289178546555 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8513 is 0.084802082997498 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8514 is 0.08480127437259537 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8515 is 0.08480046591067868 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8516 is 0.08479965761166906 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8517 is 0.08479884947548756 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8518 is 0.0847980415020554 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8519 is 0.08479723369129388 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8520 is 0.08479642604312422 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8521 is 0.08479561855746774 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8522 is 0.08479481123424591 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8523 is 0.08479400407338011 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8524 is 0.08479319707479185 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8525 is 0.08479239023840271 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8526 is 0.08479158356413423 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8527 is 0.08479077705190809 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8528 is 0.08478997070164597 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8529 is 0.08478916451326964 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8530 is 0.08478835848670084 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8531 is 0.08478755262186148 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8532 is 0.08478674691867345 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8533 is 0.08478594137705867 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8534 is 0.08478513599693917 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8535 is 0.08478433077823698 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8536 is 0.08478352572087422 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8537 is 0.08478272082477303 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8538 is 0.08478191608985558 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8539 is 0.08478111151604417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8540 is 0.0847803071032611 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8541 is 0.08477950285142871 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8542 is 0.08477869876046935 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8543 is 0.08477789483030557 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8544 is 0.08477709106085986 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8545 is 0.08477628745205469 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8546 is 0.08477548400381271 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8547 is 0.08477468071605657 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8548 is 0.084773877588709 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8549 is 0.08477307462169273 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8550 is 0.08477227181493055 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8551 is 0.08477146916834534 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8552 is 0.08477066668185994 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8553 is 0.08476986435539736 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8554 is 0.0847690621888806 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8555 is 0.08476826018223271 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8556 is 0.08476745833537677 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8557 is 0.08476665664823593 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8558 is 0.08476585512073342 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8559 is 0.08476505375279243 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8560 is 0.0847642525443363 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8561 is 0.08476345149528836 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8562 is 0.08476265060557206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8563 is 0.08476184987511078 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8564 is 0.08476104930382801 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8565 is 0.08476024889164735 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8566 is 0.08475944863849239 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8567 is 0.08475864854428669 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8568 is 0.08475784860895404 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8569 is 0.08475704883241811 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8570 is 0.0847562492146027 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8571 is 0.08475544975543169 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8572 is 0.08475465045482894 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8573 is 0.08475385131271838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8574 is 0.08475305232902401 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8575 is 0.08475225350366987 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8576 is 0.08475145483658003 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8577 is 0.08475065632767861 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8578 is 0.08474985797688979 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8579 is 0.08474905978413781 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8580 is 0.08474826174934691 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8581 is 0.0847474638724415 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8582 is 0.08474666615334588 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8583 is 0.08474586859198444 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8584 is 0.08474507118828177 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8585 is 0.0847442739421623 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8586 is 0.0847434768535506 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8587 is 0.08474267992237132 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8588 is 0.08474188314854911 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8589 is 0.08474108653200868 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8590 is 0.08474029007267476 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8591 is 0.08473949377047217 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8592 is 0.08473869762532579 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8593 is 0.08473790163716052 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8594 is 0.08473710580590131 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8595 is 0.08473631013147312 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8596 is 0.08473551461380106 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8597 is 0.08473471925281018 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8598 is 0.08473392404842564 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8599 is 0.08473312900057264 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8600 is 0.08473233410917635 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8601 is 0.08473153937416215 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8602 is 0.08473074479545535 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8603 is 0.08472995037298128 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8604 is 0.08472915610666541 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8605 is 0.0847283619964332 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8606 is 0.08472756804221021 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8607 is 0.08472677424392193 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8608 is 0.08472598060149412 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8609 is 0.08472518711485226 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8610 is 0.08472439378392223 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8611 is 0.08472360060862964 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8612 is 0.08472280758890044 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8613 is 0.08472201472466041 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8614 is 0.08472122201583546 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8615 is 0.08472042946235156 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8616 is 0.08471963706413463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8617 is 0.08471884482111079 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8618 is 0.08471805273320614 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8619 is 0.08471726080034678 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8620 is 0.08471646902245886 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8621 is 0.08471567739946864 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8622 is 0.08471488593130243 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8623 is 0.08471409461788654 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8624 is 0.08471330345914732 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8625 is 0.08471251245501119 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8626 is 0.08471172160540462 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8627 is 0.08471093091025413 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8628 is 0.08471014036948625 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8629 is 0.08470934998302762 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8630 is 0.08470855975080485 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8631 is 0.08470776967274468 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8632 is 0.08470697974877384 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8633 is 0.08470618997881905 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8634 is 0.08470540036280727 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8635 is 0.08470461090066528 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8636 is 0.0847038215923201 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8637 is 0.08470303243769861 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8638 is 0.08470224343672784 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8639 is 0.08470145458933494 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8640 is 0.08470066589544697 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8641 is 0.084699877354991 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8642 is 0.08469908896789442 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8643 is 0.08469830073408434 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8644 is 0.08469751265348811 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8645 is 0.08469672472603305 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8646 is 0.08469593695164662 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8647 is 0.0846951493302561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8648 is 0.08469436186178918 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8649 is 0.08469357454617321 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8650 is 0.08469278738333581 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8651 is 0.08469200037320462 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8652 is 0.0846912135157073 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8653 is 0.08469042681077152 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8654 is 0.08468964025832511 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8655 is 0.08468885385829579 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8656 is 0.08468806761061147 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8657 is 0.0846872815152 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8658 is 0.0846864955719893 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8659 is 0.08468570978090742 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8660 is 0.0846849241418823 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8661 is 0.0846841386548421 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8662 is 0.08468335331971484 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8663 is 0.08468256813642874 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8664 is 0.08468178310491205 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8665 is 0.08468099822509294 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8666 is 0.08468021349689976 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8667 is 0.08467942892026081 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8668 is 0.08467864449510452 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8669 is 0.08467786022135929 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8670 is 0.08467707609895361 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8671 is 0.08467629212781601 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8672 is 0.08467550830787504 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8673 is 0.08467472463905933 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8674 is 0.08467394112129754 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8675 is 0.08467315775451834 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8676 is 0.08467237453865051 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8677 is 0.08467159147362284 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8678 is 0.08467080855936412 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8679 is 0.08467002579580331 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8680 is 0.08466924318286928 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8681 is 0.08466846072049096 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8682 is 0.08466767840859746 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8683 is 0.08466689624711775 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8684 is 0.08466611423598099 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8685 is 0.08466533237511632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8686 is 0.08466455066445296 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8687 is 0.08466376910392005 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8688 is 0.08466298769344696 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8689 is 0.08466220643296295 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8690 is 0.08466142532239741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8691 is 0.08466064436167979 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8692 is 0.08465986355073953 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8693 is 0.0846590828895061 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8694 is 0.08465830237790906 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8695 is 0.08465752201587803 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8696 is 0.08465674180334257 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8697 is 0.08465596174023246 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8698 is 0.08465518182647733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8699 is 0.08465440206200697 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8700 is 0.08465362244675119 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8701 is 0.08465284298063985 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8702 is 0.08465206366360288 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8703 is 0.08465128449557013 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8704 is 0.08465050547647167 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8705 is 0.08464972660623747 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8706 is 0.08464894788479767 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8707 is 0.0846481693120823 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8708 is 0.08464739088802156 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8709 is 0.08464661261254562 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8710 is 0.0846458344855848 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8711 is 0.0846450565070693 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8712 is 0.08464427867692949 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8713 is 0.08464350099509577 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8714 is 0.08464272346149852 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8715 is 0.08464194607606822 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8716 is 0.08464116883873535 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8717 is 0.08464039174943047 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8718 is 0.08463961480808418 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8719 is 0.08463883801462713 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8720 is 0.08463806136898998 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8721 is 0.08463728487110343 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8722 is 0.08463650852089825 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8723 is 0.08463573231830526 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8724 is 0.08463495626325533 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8725 is 0.0846341803556793 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8726 is 0.08463340459550817 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8727 is 0.08463262898267282 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8728 is 0.08463185351710441 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8729 is 0.08463107819873385 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8730 is 0.08463030302749235 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8731 is 0.08462952800331103 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8732 is 0.0846287531261211 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8733 is 0.08462797839585375 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8734 is 0.0846272038124403 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8735 is 0.08462642937581202 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8736 is 0.08462565508590031 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8737 is 0.08462488094263658 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8738 is 0.08462410694595225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8739 is 0.08462333309577888 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8740 is 0.08462255939204788 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8741 is 0.0846217858346909 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8742 is 0.08462101242363955 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8743 is 0.08462023915882548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8744 is 0.08461946604018045 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8745 is 0.08461869306763607 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8746 is 0.08461792024112427 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8747 is 0.08461714756057677 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8748 is 0.08461637502592549 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8749 is 0.08461560263710231 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8750 is 0.08461483039403923 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8751 is 0.08461405829666821 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8752 is 0.08461328634492132 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8753 is 0.08461251453873063 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8754 is 0.08461174287802821 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8755 is 0.0846109713627463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8756 is 0.08461019999281703 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8757 is 0.08460942876817269 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8758 is 0.08460865768874558 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8759 is 0.08460788675446802 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8760 is 0.08460711596527237 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8761 is 0.08460634532109103 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8762 is 0.0846055748218565 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8763 is 0.08460480446750125 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8764 is 0.08460403425795786 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8765 is 0.08460326419315883 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8766 is 0.08460249427303684 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8767 is 0.08460172449752454 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8768 is 0.08460095486655463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8769 is 0.08460018538005988 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8770 is 0.08459941603797302 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8771 is 0.08459864684022692 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8772 is 0.08459787778675448 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8773 is 0.08459710887748856 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8774 is 0.08459634011236213 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8775 is 0.08459557149130814 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8776 is 0.08459480301425973 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8777 is 0.08459403468114989 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8778 is 0.08459326649191176 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8779 is 0.08459249844647851 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8780 is 0.08459173054478333 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8781 is 0.08459096278675941 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8782 is 0.08459019517234014 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8783 is 0.08458942770145875 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8784 is 0.08458866037404865 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8785 is 0.08458789319004323 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8786 is 0.08458712614937594 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8787 is 0.08458635925198026 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8788 is 0.08458559249778971 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8789 is 0.08458482588673785 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8790 is 0.08458405941875832 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8791 is 0.08458329309378475 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8792 is 0.08458252691175082 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8793 is 0.08458176087259027 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8794 is 0.08458099497623686 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8795 is 0.08458022922262444 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8796 is 0.08457946361168679 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8797 is 0.08457869814335787 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8798 is 0.08457793281757159 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8799 is 0.08457716763426193 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8800 is 0.08457640259336284 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8801 is 0.08457563769480844 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8802 is 0.08457487293853283 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8803 is 0.08457410832447007 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8804 is 0.08457334385255441 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8805 is 0.0845725795227201 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8806 is 0.08457181533490124 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8807 is 0.08457105128903224 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8808 is 0.08457028738504746 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8809 is 0.08456952362288121 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8810 is 0.0845687600024679 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8811 is 0.084567996523742 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8812 is 0.08456723318663803 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8813 is 0.0845664699910905 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8814 is 0.08456570693703401 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8815 is 0.08456494402440314 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8816 is 0.08456418125313257 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8817 is 0.08456341862315696 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8818 is 0.08456265613441108 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8819 is 0.08456189378682973 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8820 is 0.08456113158034763 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8821 is 0.0845603695148997 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8822 is 0.08455960759042083 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8823 is 0.08455884580684593 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8824 is 0.08455808416411006 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8825 is 0.08455732266214808 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8826 is 0.08455656130089513 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8827 is 0.08455580008028632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8828 is 0.08455503900025671 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8829 is 0.08455427806074155 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8830 is 0.084553517261676 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8831 is 0.08455275660299531 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8832 is 0.08455199608463478 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8833 is 0.08455123570652974 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8834 is 0.08455047546861554 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8835 is 0.08454971537082757 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8836 is 0.08454895541310134 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8837 is 0.08454819559537227 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8838 is 0.0845474359175759 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8839 is 0.08454667637964781 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8840 is 0.08454591698152356 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8841 is 0.08454515772313888 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8842 is 0.08454439860442936 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8843 is 0.08454363962533074 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8844 is 0.08454288078577883 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8845 is 0.08454212208570931 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8846 is 0.08454136352505814 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8847 is 0.08454060510376113 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8848 is 0.08453984682175421 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8849 is 0.08453908867897329 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8850 is 0.08453833067535442 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8851 is 0.08453757281083363 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8852 is 0.08453681508534695 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8853 is 0.08453605749883049 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8854 is 0.08453530005122042 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8855 is 0.0845345427424529 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8856 is 0.08453378557246416 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8857 is 0.08453302854119048 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8858 is 0.08453227164856814 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8859 is 0.08453151489453348 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8860 is 0.0845307582790229 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8861 is 0.08453000180197277 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8862 is 0.08452924546331957 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8863 is 0.0845284892629998 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8864 is 0.08452773320094997 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8865 is 0.08452697727710672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8866 is 0.08452622149140651 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8867 is 0.08452546584378613 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8868 is 0.08452471033418218 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8869 is 0.08452395496253141 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8870 is 0.08452319972877056 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8871 is 0.08452244463283648 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8872 is 0.08452168967466599 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8873 is 0.0845209348541959 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8874 is 0.08452018017136316 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8875 is 0.08451942562610477 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8876 is 0.08451867121835767 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8877 is 0.08451791694805885 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8878 is 0.08451716281514547 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8879 is 0.08451640881955454 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8880 is 0.08451565496122326 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8881 is 0.0845149012400888 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8882 is 0.08451414765608835 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8883 is 0.08451339420915914 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8884 is 0.08451264089923854 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8885 is 0.08451188772626383 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8886 is 0.08451113469017241 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8887 is 0.08451038179090159 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8888 is 0.08450962902838892 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8889 is 0.08450887640257185 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8890 is 0.0845081239133879 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8891 is 0.08450737156077458 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8892 is 0.0845066193446695 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8893 is 0.08450586726501033 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8894 is 0.08450511532173471 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8895 is 0.08450436351478033 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8896 is 0.08450361184408495 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8897 is 0.08450286030958634 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8898 is 0.08450210891122234 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8899 is 0.08450135764893078 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8900 is 0.08450060652264954 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8901 is 0.08449985553231658 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8902 is 0.08449910467786982 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8903 is 0.08449835395924737 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8904 is 0.08449760337638712 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8905 is 0.08449685292922725 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8906 is 0.08449610261770586 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8907 is 0.08449535244176107 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8908 is 0.08449460240133107 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8909 is 0.08449385249635413 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8910 is 0.0844931027267685 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8911 is 0.08449235309251245 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8912 is 0.08449160359352431 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8913 is 0.08449085422974248 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8914 is 0.0844901050011054 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8915 is 0.08448935590755144 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8916 is 0.08448860694901913 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8917 is 0.08448785812544701 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8918 is 0.0844871094367736 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8919 is 0.08448636088293748 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8920 is 0.08448561246387733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8921 is 0.08448486417953181 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8922 is 0.0844841160298396 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8923 is 0.08448336801473946 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8924 is 0.08448262013417011 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8925 is 0.08448187238807046 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8926 is 0.08448112477637933 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8927 is 0.08448037729903554 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8928 is 0.08447962995597808 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8929 is 0.08447888274714589 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8930 is 0.084478135672478 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8931 is 0.08447738873191339 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8932 is 0.08447664192539117 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8933 is 0.08447589525285037 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8934 is 0.08447514871423026 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8935 is 0.08447440230946993 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8936 is 0.0844736560385086 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8937 is 0.0844729099012855 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8938 is 0.08447216389774001 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8939 is 0.08447141802781136 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8940 is 0.08447067229143891 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8941 is 0.08446992668856212 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8942 is 0.08446918121912039 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8943 is 0.0844684358830532 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8944 is 0.08446769068030004 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8945 is 0.08446694561080041 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8946 is 0.08446620067449394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8947 is 0.08446545587132022 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8948 is 0.08446471120121891 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8949 is 0.08446396666412968 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8950 is 0.08446322225999227 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8951 is 0.0844624779887464 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8952 is 0.08446173385033191 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8953 is 0.08446098984468856 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8954 is 0.08446024597175625 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8955 is 0.08445950223147489 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8956 is 0.08445875862378437 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8957 is 0.08445801514862476 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8958 is 0.08445727180593592 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8959 is 0.08445652859565797 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8960 is 0.08445578551773104 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8961 is 0.08445504257209514 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8962 is 0.08445429975869047 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8963 is 0.08445355707745718 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8964 is 0.08445281452833552 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8965 is 0.08445207211126574 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8966 is 0.08445132982618812 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8967 is 0.08445058767304302 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8968 is 0.08444984565177072 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8969 is 0.0844491037623117 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8970 is 0.08444836200460634 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8971 is 0.08444762037859511 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8972 is 0.08444687888421853 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8973 is 0.08444613752141712 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8974 is 0.08444539629013147 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8975 is 0.08444465519030217 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8976 is 0.08444391422186988 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8977 is 0.08444317338477524 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8978 is 0.08444243267895903 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8979 is 0.08444169210436189 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8980 is 0.08444095166092472 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8981 is 0.08444021134858824 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8982 is 0.08443947116729336 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8983 is 0.08443873111698097 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8984 is 0.08443799119759197 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8985 is 0.08443725140906733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8986 is 0.084436511751348 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8987 is 0.08443577222437508 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8988 is 0.08443503282808952 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8989 is 0.08443429356243257 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8990 is 0.08443355442734526 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8991 is 0.08443281542276879 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8992 is 0.08443207654864435 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8993 is 0.08443133780491316 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8994 is 0.08443059919151649 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8995 is 0.08442986070839567 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8996 is 0.08442912235549203 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8997 is 0.08442838413274692 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8998 is 0.08442764604010179 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8999 is 0.08442690807749806 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9000 is 0.08442617024487721 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9001 is 0.08442543254218075 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9002 is 0.08442469496935025 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9003 is 0.08442395752632728 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9004 is 0.08442322021305343 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9005 is 0.08442248302947032 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9006 is 0.08442174597551971 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9007 is 0.08442100905114333 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9008 is 0.08442027225628287 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9009 is 0.08441953559088013 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9010 is 0.08441879905487695 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9011 is 0.0844180626482152 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9012 is 0.08441732637083668 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9013 is 0.08441659022268345 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9014 is 0.0844158542036974 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9015 is 0.0844151183138205 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9016 is 0.08441438255299481 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9017 is 0.08441364692116234 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9018 is 0.08441291141826525 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9019 is 0.08441217604424565 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9020 is 0.08441144079904572 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9021 is 0.0844107056826076 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9022 is 0.08440997069487353 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9023 is 0.08440923583578583 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9024 is 0.08440850110528676 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9025 is 0.08440776650331869 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9026 is 0.08440703202982394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9027 is 0.0844062976847449 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9028 is 0.08440556346802405 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9029 is 0.08440482937960382 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9030 is 0.08440409541942674 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9031 is 0.0844033615874353 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9032 is 0.08440262788357215 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9033 is 0.0844018943077798 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9034 is 0.08440116086000096 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9035 is 0.08440042754017829 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9036 is 0.08439969434825445 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9037 is 0.08439896128417218 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9038 is 0.08439822834787429 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9039 is 0.08439749553930356 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9040 is 0.08439676285840285 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9041 is 0.084396030305115 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9042 is 0.08439529787938292 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9043 is 0.08439456558114955 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9044 is 0.08439383341035786 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9045 is 0.08439310136695093 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9046 is 0.08439236945087168 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9047 is 0.0843916376620632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9048 is 0.08439090600046865 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9049 is 0.08439017446603118 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9050 is 0.08438944305869389 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9051 is 0.08438871177840003 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9052 is 0.08438798062509281 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9053 is 0.08438724959871555 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9054 is 0.08438651869921149 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9055 is 0.08438578792652401 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9056 is 0.08438505728059645 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9057 is 0.08438432676137225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9058 is 0.0843835963687948 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9059 is 0.08438286610280762 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9060 is 0.08438213596335417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9061 is 0.08438140595037803 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9062 is 0.08438067606382273 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9063 is 0.08437994630363191 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9064 is 0.08437921666974915 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9065 is 0.0843784871621181 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9066 is 0.08437775778068257 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9067 is 0.08437702852538621 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9068 is 0.08437629939617279 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9069 is 0.0843755703929861 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9070 is 0.08437484151577006 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9071 is 0.0843741127644684 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9072 is 0.0843733841390251 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9073 is 0.08437265563938408 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9074 is 0.08437192726548927 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9075 is 0.08437119901728471 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9076 is 0.08437047089471439 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9077 is 0.0843697428977224 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9078 is 0.08436901502625278 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9079 is 0.08436828728024973 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9080 is 0.08436755965965734 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9081 is 0.08436683216441979 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9082 is 0.08436610479448138 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9083 is 0.08436537754978635 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9084 is 0.08436465043027892 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9085 is 0.08436392343590347 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9086 is 0.08436319656660432 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9087 is 0.08436246982232587 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9088 is 0.08436174320301253 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9089 is 0.08436101670860877 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9090 is 0.08436029033905901 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9091 is 0.08435956409430784 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9092 is 0.08435883797429976 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9093 is 0.08435811197897936 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9094 is 0.08435738610829123 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9095 is 0.08435666036218005 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9096 is 0.08435593474059046 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9097 is 0.0843552092434672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9098 is 0.08435448387075498 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9099 is 0.08435375862239858 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9100 is 0.08435303349834282 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9101 is 0.08435230849853247 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9102 is 0.08435158362291247 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9103 is 0.0843508588714277 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9104 is 0.08435013424402307 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9105 is 0.08434940974064356 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9106 is 0.08434868536123417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9107 is 0.08434796110573992 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9108 is 0.08434723697410582 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9109 is 0.08434651296627706 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9110 is 0.08434578908219868 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9111 is 0.08434506532181583 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9112 is 0.08434434168507376 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9113 is 0.08434361817191763 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9114 is 0.08434289478229275 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9115 is 0.08434217151614433 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9116 is 0.0843414483734177 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9117 is 0.08434072535405825 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9118 is 0.08434000245801132 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9119 is 0.08433927968522227 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9120 is 0.08433855703563659 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9121 is 0.08433783450919978 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9122 is 0.08433711210585729 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9123 is 0.0843363898255547 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9124 is 0.08433566766823752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9125 is 0.08433494563385137 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9126 is 0.08433422372234192 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9127 is 0.08433350193365473 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9128 is 0.08433278026773558 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9129 is 0.08433205872453015 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9130 is 0.08433133730398425 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9131 is 0.08433061600604355 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9132 is 0.08432989483065395 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9133 is 0.08432917377776131 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9134 is 0.08432845284731146 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9135 is 0.08432773203925031 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9136 is 0.08432701135352387 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9137 is 0.08432629079007799 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9138 is 0.08432557034885879 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9139 is 0.08432485002981227 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9140 is 0.08432412983288445 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9141 is 0.08432340975802148 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9142 is 0.08432268980516945 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9143 is 0.08432196997427455 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9144 is 0.08432125026528293 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9145 is 0.0843205306781409 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9146 is 0.08431981121279457 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9147 is 0.08431909186919032 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9148 is 0.08431837264727449 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9149 is 0.08431765354699333 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9150 is 0.08431693456829328 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9151 is 0.08431621571112073 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9152 is 0.0843154969754221 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9153 is 0.08431477836114389 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9154 is 0.08431405986823258 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9155 is 0.08431334149663469 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9156 is 0.0843126232462968 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9157 is 0.0843119051171655 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9158 is 0.08431118710918738 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9159 is 0.08431046922230918 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9160 is 0.08430975145647748 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9161 is 0.08430903381163901 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9162 is 0.08430831628774055 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9163 is 0.08430759888472888 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9164 is 0.08430688160255081 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9165 is 0.08430616444115309 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9166 is 0.08430544740048272 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9167 is 0.0843047304804865 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9168 is 0.08430401368111137 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9169 is 0.08430329700230431 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9170 is 0.08430258044401231 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9171 is 0.08430186400618238 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9172 is 0.0843011476887616 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9173 is 0.084300431491697 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9174 is 0.08429971541493572 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9175 is 0.08429899945842488 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9176 is 0.08429828362211167 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9177 is 0.08429756790594328 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9178 is 0.08429685230986696 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9179 is 0.08429613683382996 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9180 is 0.08429542147777955 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9181 is 0.08429470624166306 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9182 is 0.08429399112542789 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9183 is 0.08429327612902136 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9184 is 0.08429256125239092 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9185 is 0.08429184649548402 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9186 is 0.08429113185824806 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9187 is 0.08429041734063066 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9188 is 0.08428970294257929 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9189 is 0.08428898866404147 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9190 is 0.08428827450496487 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9191 is 0.0842875604652971 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9192 is 0.08428684654498576 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9193 is 0.08428613274397859 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9194 is 0.08428541906222325 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9195 is 0.08428470549966756 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9196 is 0.08428399205625921 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9197 is 0.08428327873194608 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9198 is 0.08428256552667594 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9199 is 0.0842818524403967 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9200 is 0.08428113947305617 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9201 is 0.08428042662460236 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9202 is 0.0842797138949832 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9203 is 0.08427900128414663 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9204 is 0.08427828879204075 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9205 is 0.0842775764186135 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9206 is 0.08427686416381303 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9207 is 0.08427615202758741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9208 is 0.08427544000988471 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9209 is 0.08427472811065319 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9210 is 0.08427401632984101 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9211 is 0.08427330466739635 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9212 is 0.08427259312326747 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9213 is 0.08427188169740271 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9214 is 0.08427117038975031 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9215 is 0.08427045920025864 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9216 is 0.084269748128876 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9217 is 0.0842690371755509 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9218 is 0.08426832634023168 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9219 is 0.08426761562286682 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9220 is 0.08426690502340475 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9221 is 0.0842661945417941 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9222 is 0.08426548417798334 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9223 is 0.08426477393192104 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9224 is 0.08426406380355582 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9225 is 0.0842633537928363 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9226 is 0.08426264389971114 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9227 is 0.08426193412412906 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9228 is 0.0842612244660387 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9229 is 0.08426051492538894 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9230 is 0.08425980550212842 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9231 is 0.084259096196206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9232 is 0.08425838700757053 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9233 is 0.08425767793617087 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9234 is 0.08425696898195588 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9235 is 0.08425626014487456 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9236 is 0.08425555142487579 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9237 is 0.08425484282190855 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9238 is 0.0842541343359219 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9239 is 0.08425342596686483 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9240 is 0.08425271771468643 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9241 is 0.0842520095793358 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9242 is 0.08425130156076206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9243 is 0.08425059365891437 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9244 is 0.0842498858737419 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9245 is 0.0842491782051939 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9246 is 0.08424847065321954 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9247 is 0.08424776321776815 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9248 is 0.084247055898789 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9249 is 0.08424634869623145 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9250 is 0.08424564161004482 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9251 is 0.08424493464017853 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9252 is 0.084244227786582 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9253 is 0.08424352104920454 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9254 is 0.08424281442799585 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9255 is 0.08424210792290523 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9256 is 0.08424140153388232 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9257 is 0.08424069526087667 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9258 is 0.08423998910383779 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9259 is 0.08423928306271537 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9260 is 0.08423857713745903 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9261 is 0.08423787132801844 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9262 is 0.0842371656343433 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9263 is 0.08423646005638334 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9264 is 0.08423575459408833 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9265 is 0.08423504924740802 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9266 is 0.08423434401629225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9267 is 0.0842336389006909 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9268 is 0.08423293390055375 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9269 is 0.0842322290158308 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9270 is 0.08423152424647189 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9271 is 0.08423081959242706 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9272 is 0.0842301150536462 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9273 is 0.0842294106300794 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9274 is 0.08422870632167664 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9275 is 0.08422800212838809 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9276 is 0.08422729805016375 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9277 is 0.08422659408695378 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9278 is 0.08422589023870829 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9279 is 0.08422518650537755 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9280 is 0.08422448288691173 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9281 is 0.08422377938326105 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9282 is 0.08422307599437578 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9283 is 0.08422237272020623 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9284 is 0.08422166956070276 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9285 is 0.08422096651581562 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9286 is 0.08422026358549535 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9287 is 0.08421956076969217 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9288 is 0.08421885806835662 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9289 is 0.08421815548143917 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9290 is 0.08421745300889028 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9291 is 0.08421675065066048 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9292 is 0.08421604840670033 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9293 is 0.08421534627696035 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9294 is 0.08421464426139123 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9295 is 0.08421394235994355 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9296 is 0.08421324057256793 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9297 is 0.08421253889921515 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9298 is 0.08421183733983585 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9299 is 0.08421113589438088 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9300 is 0.08421043456280083 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9301 is 0.08420973334504661 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9302 is 0.08420903224106907 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9303 is 0.08420833125081903 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9304 is 0.08420763037424737 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9305 is 0.08420692961130495 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9306 is 0.08420622896194284 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9307 is 0.08420552842611187 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9308 is 0.08420482800376308 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9309 is 0.08420412769484752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9310 is 0.08420342749931621 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9311 is 0.08420272741712016 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9312 is 0.08420202744821062 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9313 is 0.0842013275925386 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9314 is 0.0842006278500553 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9315 is 0.08419992822071191 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9316 is 0.08419922870445964 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9317 is 0.08419852930124973 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9318 is 0.08419783001103343 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9319 is 0.08419713083376204 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9320 is 0.08419643176938689 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9321 is 0.08419573281785933 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9322 is 0.08419503397913074 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9323 is 0.08419433525315255 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9324 is 0.08419363663987611 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9325 is 0.08419293813925295 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9326 is 0.08419223975123455 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9327 is 0.0841915414757724 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9328 is 0.08419084331281809 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9329 is 0.08419014526232316 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9330 is 0.08418944732423912 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9331 is 0.08418874949851775 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9332 is 0.08418805178511062 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9333 is 0.08418735418396936 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9334 is 0.08418665669504573 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9335 is 0.08418595931829147 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9336 is 0.08418526205365837 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9337 is 0.08418456490109814 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9338 is 0.08418386786056259 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9339 is 0.08418317093200364 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9340 is 0.08418247411537308 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9341 is 0.08418177741062288 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9342 is 0.08418108081770487 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9343 is 0.08418038433657107 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9344 is 0.08417968796717341 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9345 is 0.08417899170946394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9346 is 0.08417829556339465 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9347 is 0.08417759952891758 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9348 is 0.08417690360598488 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9349 is 0.08417620779454858 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9350 is 0.0841755120945609 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9351 is 0.08417481650597393 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9352 is 0.08417412102873995 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9353 is 0.08417342566281104 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9354 is 0.08417273040813956 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9355 is 0.08417203526467774 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9356 is 0.08417134023237786 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9357 is 0.0841706453111923 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9358 is 0.08416995050107336 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9359 is 0.08416925580197342 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9360 is 0.0841685612138449 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9361 is 0.08416786673664024 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9362 is 0.08416717237031189 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9363 is 0.0841664781148123 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9364 is 0.08416578397009405 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9365 is 0.08416508993610962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9366 is 0.08416439601281163 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9367 is 0.08416370220015261 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9368 is 0.08416300849808518 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9369 is 0.08416231490656202 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9370 is 0.08416162142553582 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9371 is 0.0841609280549592 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9372 is 0.08416023479478493 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9373 is 0.08415954164496577 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9374 is 0.0841588486054545 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9375 is 0.08415815567620387 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9376 is 0.08415746285716674 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9377 is 0.08415677014829599 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9378 is 0.08415607754954446 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9379 is 0.0841553850608651 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9380 is 0.08415469268221083 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9381 is 0.08415400041353462 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9382 is 0.08415330825478937 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9383 is 0.08415261620592822 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9384 is 0.08415192426690417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9385 is 0.08415123243767024 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9386 is 0.08415054071817957 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9387 is 0.08414984910838523 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9388 is 0.08414915760824043 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9389 is 0.08414846621769831 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9390 is 0.08414777493671204 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9391 is 0.08414708376523486 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9392 is 0.08414639270322004 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9393 is 0.08414570175062083 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9394 is 0.08414501090739056 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9395 is 0.08414432017348253 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9396 is 0.0841436295488501 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9397 is 0.08414293903344666 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9398 is 0.0841422486272256 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9399 is 0.08414155833014039 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9400 is 0.0841408681421444 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9401 is 0.08414017806319118 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9402 is 0.08413948809323427 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9403 is 0.08413879823222711 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9404 is 0.08413810848012339 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9405 is 0.08413741883687657 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9406 is 0.08413672930244034 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9407 is 0.08413603987676832 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9408 is 0.08413535055981412 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9409 is 0.08413466135153154 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9410 is 0.08413397225187423 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9411 is 0.0841332832607959 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9412 is 0.08413259437825038 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9413 is 0.08413190560419144 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9414 is 0.08413121693857291 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9415 is 0.0841305283813486 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9416 is 0.08412983993247247 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9417 is 0.08412915159189828 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9418 is 0.08412846335958006 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9419 is 0.08412777523547174 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9420 is 0.08412708721952723 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9421 is 0.08412639931170063 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9422 is 0.0841257115119459 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9423 is 0.08412502382021705 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9424 is 0.08412433623646826 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9425 is 0.0841236487606536 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9426 is 0.08412296139272712 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9427 is 0.08412227413264305 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9428 is 0.08412158698035556 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9429 is 0.08412089993581885 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9430 is 0.0841202129989871 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9431 is 0.08411952616981463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9432 is 0.08411883944825571 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9433 is 0.0841181528342646 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9434 is 0.08411746632779565 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9435 is 0.08411677992880329 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9436 is 0.0841160936372418 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9437 is 0.08411540745306563 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9438 is 0.08411472137622916 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9439 is 0.08411403540668698 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9440 is 0.08411334954439345 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9441 is 0.0841126637893031 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9442 is 0.08411197814137049 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9443 is 0.08411129260055017 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9444 is 0.08411060716679675 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9445 is 0.08410992184006477 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9446 is 0.08410923662030895 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9447 is 0.08410855150748386 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9448 is 0.08410786650154431 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9449 is 0.08410718160244483 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9450 is 0.08410649681014032 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9451 is 0.08410581212458548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9452 is 0.08410512754573504 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9453 is 0.08410444307354391 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9454 is 0.08410375870796688 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9455 is 0.08410307444895877 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9456 is 0.08410239029647454 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9457 is 0.08410170625046905 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9458 is 0.08410102231089725 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9459 is 0.08410033847771411 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9460 is 0.08409965475087461 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9461 is 0.08409897113033372 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9462 is 0.08409828761604653 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9463 is 0.08409760420796814 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9464 is 0.0840969209060535 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9465 is 0.08409623771025782 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9466 is 0.08409555462053624 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9467 is 0.08409487163684387 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9468 is 0.08409418875913591 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9469 is 0.0840935059873676 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9470 is 0.08409282332149415 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9471 is 0.08409214076147083 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9472 is 0.08409145830725288 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9473 is 0.08409077595879569 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9474 is 0.08409009371605453 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9475 is 0.08408941157898478 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9476 is 0.08408872954754179 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9477 is 0.08408804762168105 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9478 is 0.0840873658013579 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9479 is 0.08408668408652785 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9480 is 0.08408600247714637 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9481 is 0.08408532097316895 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9482 is 0.08408463957455115 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9483 is 0.08408395828124851 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9484 is 0.08408327709321661 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9485 is 0.08408259601041104 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9486 is 0.08408191503278749 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9487 is 0.08408123416030157 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9488 is 0.08408055339290892 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9489 is 0.08407987273056533 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9490 is 0.0840791921732264 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9491 is 0.08407851172084801 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9492 is 0.0840778313733859 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9493 is 0.08407715113079584 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9494 is 0.08407647099303364 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9495 is 0.08407579096005525 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9496 is 0.08407511103181643 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9497 is 0.08407443120827314 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9498 is 0.08407375148938129 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9499 is 0.08407307187509681 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9500 is 0.0840723923653757 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9501 is 0.08407171296017392 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9502 is 0.08407103365944756 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9503 is 0.08407035446315257 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9504 is 0.0840696753712451 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9505 is 0.0840689963836812 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9506 is 0.084068317500417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9507 is 0.08406763872140863 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9508 is 0.08406696004661221 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9509 is 0.08406628147598408 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9510 is 0.08406560300948034 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9511 is 0.0840649246470572 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9512 is 0.08406424638867094 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9513 is 0.08406356823427795 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9514 is 0.08406289018383441 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9515 is 0.08406221223729675 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9516 is 0.08406153439462123 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9517 is 0.08406085665576433 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9518 is 0.08406017902068243 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9519 is 0.0840595014893319 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9520 is 0.08405882406166927 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9521 is 0.08405814673765101 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9522 is 0.0840574695172336 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9523 is 0.08405679240037356 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9524 is 0.08405611538702747 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9525 is 0.08405543847715184 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9526 is 0.08405476167070333 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9527 is 0.08405408496763861 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9528 is 0.08405340836791425 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9529 is 0.08405273187148683 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9530 is 0.08405205547831328 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9531 is 0.08405137918835012 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9532 is 0.08405070300155415 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9533 is 0.08405002691788219 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9534 is 0.08404935093729095 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9535 is 0.08404867505973733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9536 is 0.08404799928517807 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9537 is 0.08404732361357013 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9538 is 0.08404664804487032 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9539 is 0.08404597257903552 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9540 is 0.0840452972160228 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9541 is 0.08404462195578895 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9542 is 0.08404394679829104 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9543 is 0.08404327174348611 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9544 is 0.08404259679133111 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9545 is 0.08404192194178314 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9546 is 0.08404124719479926 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9547 is 0.08404057255033649 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9548 is 0.08403989800835206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9549 is 0.08403922356880313 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9550 is 0.08403854923164678 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9551 is 0.08403787499684022 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9552 is 0.08403720086434073 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9553 is 0.08403652683410541 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9554 is 0.08403585290609171 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9555 is 0.0840351790802568 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9556 is 0.08403450535655801 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9557 is 0.0840338317349527 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9558 is 0.08403315821539817 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9559 is 0.08403248479785183 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9560 is 0.08403181148227111 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9561 is 0.0840311382686134 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9562 is 0.08403046515683614 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9563 is 0.08402979214689688 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9564 is 0.08402911923875302 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9565 is 0.08402844643236212 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9566 is 0.08402777372768176 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9567 is 0.08402710112466948 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9568 is 0.0840264286232828 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9569 is 0.08402575622347945 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9570 is 0.08402508392521703 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9571 is 0.08402441172845317 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9572 is 0.08402373963314558 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9573 is 0.08402306763925194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9574 is 0.08402239574672998 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9575 is 0.08402172395553748 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9576 is 0.08402105226563222 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9577 is 0.08402038067697194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9578 is 0.08401970918951457 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9579 is 0.08401903780321786 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9580 is 0.0840183665180397 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9581 is 0.084017695333938 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9582 is 0.08401702425087068 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9583 is 0.08401635326879563 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9584 is 0.0840156823876709 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9585 is 0.08401501160745438 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9586 is 0.08401434092810414 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9587 is 0.08401367034957814 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9588 is 0.08401299987183455 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9589 is 0.08401232949483137 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9590 is 0.08401165921852667 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9591 is 0.08401098904287864 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9592 is 0.08401031896784535 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9593 is 0.08400964899338509 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9594 is 0.08400897911945589 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9595 is 0.08400830934601607 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9596 is 0.08400763967302387 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9597 is 0.08400697010043752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9598 is 0.08400630062821528 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9599 is 0.08400563125631551 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9600 is 0.08400496198469651 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9601 is 0.08400429281331659 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9602 is 0.0840036237421342 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9603 is 0.0840029547711077 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9604 is 0.08400228590019548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9605 is 0.08400161712935604 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9606 is 0.08400094845854782 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9607 is 0.0840002798877293 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9608 is 0.083999611416859 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9609 is 0.08399894304589547 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9610 is 0.0839982747747972 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9611 is 0.08399760660352283 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9612 is 0.08399693853203095 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9613 is 0.08399627056028015 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9614 is 0.08399560268822913 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9615 is 0.08399493491583654 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9616 is 0.08399426724306105 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9617 is 0.08399359966986142 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9618 is 0.08399293219619632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9619 is 0.08399226482202454 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9620 is 0.08399159754730488 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9621 is 0.08399093037199616 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9622 is 0.08399026329605715 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9623 is 0.08398959631944675 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9624 is 0.08398892944212377 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9625 is 0.08398826266404717 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9626 is 0.08398759598517586 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9627 is 0.08398692940546873 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9628 is 0.08398626292488479 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9629 is 0.08398559654338303 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9630 is 0.08398493026092237 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9631 is 0.08398426407746196 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9632 is 0.08398359799296075 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9633 is 0.08398293200737789 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9634 is 0.08398226612067244 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9635 is 0.08398160033280352 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9636 is 0.08398093464373027 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9637 is 0.08398026905341187 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9638 is 0.08397960356180752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9639 is 0.0839789381688763 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9640 is 0.08397827287457765 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9641 is 0.08397760767887065 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9642 is 0.08397694258171466 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9643 is 0.08397627758306894 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9644 is 0.08397561268289286 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9645 is 0.08397494788114566 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9646 is 0.08397428317778677 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9647 is 0.08397361857277565 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9648 is 0.0839729540660716 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9649 is 0.08397228965763406 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9650 is 0.0839716253474225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9651 is 0.08397096113539643 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9652 is 0.08397029702151527 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9653 is 0.0839696330057386 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9654 is 0.08396896908802595 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9655 is 0.08396830526833687 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9656 is 0.08396764154663092 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9657 is 0.08396697792286778 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9658 is 0.08396631439700701 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9659 is 0.08396565096900828 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9660 is 0.08396498763883127 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9661 is 0.08396432440643568 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9662 is 0.08396366127178123 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9663 is 0.08396299823482763 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9664 is 0.08396233529553464 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9665 is 0.08396167245386207 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9666 is 0.08396100970976976 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9667 is 0.08396034706321742 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9668 is 0.083959684514165 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9669 is 0.08395902206257234 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9670 is 0.08395835970839932 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9671 is 0.08395769745160589 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9672 is 0.08395703529215193 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9673 is 0.08395637322999745 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9674 is 0.08395571126510239 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9675 is 0.08395504939742675 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9676 is 0.0839543876269306 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9677 is 0.08395372595357395 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9678 is 0.08395306437731682 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9679 is 0.08395240289811941 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9680 is 0.08395174151594174 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9681 is 0.08395108023074396 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9682 is 0.08395041904248626 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9683 is 0.08394975795112879 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9684 is 0.0839490969566317 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9685 is 0.08394843605895527 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9686 is 0.08394777525805974 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9687 is 0.08394711455390536 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9688 is 0.08394645394645238 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9689 is 0.08394579343566114 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9690 is 0.08394513302149192 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9691 is 0.08394447270390516 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9692 is 0.08394381248286113 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9693 is 0.0839431523583203 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9694 is 0.08394249233024305 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9695 is 0.08394183239858977 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9696 is 0.08394117256332104 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9697 is 0.08394051282439718 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9698 is 0.0839398531817788 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9699 is 0.08393919363542635 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9700 is 0.08393853418530044 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9701 is 0.08393787483136157 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9702 is 0.08393721557357033 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9703 is 0.0839365564118874 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9704 is 0.08393589734627331 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9705 is 0.08393523837668877 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9706 is 0.08393457950309446 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9707 is 0.083933920725451 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9708 is 0.08393326204371916 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9709 is 0.08393260345785968 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9710 is 0.08393194496783332 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9711 is 0.08393128657360079 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9712 is 0.08393062827512296 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9713 is 0.08392997007236058 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9714 is 0.08392931196527458 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9715 is 0.08392865395382575 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9716 is 0.08392799603797499 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9717 is 0.08392733821768322 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9718 is 0.08392668049291135 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9719 is 0.08392602286362034 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9720 is 0.08392536532977117 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9721 is 0.08392470789132479 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9722 is 0.08392405054824222 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9723 is 0.08392339330048453 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9724 is 0.08392273614801272 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9725 is 0.08392207909078792 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9726 is 0.08392142212877118 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9727 is 0.08392076526192366 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9728 is 0.08392010849020641 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9729 is 0.08391945181358067 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9730 is 0.0839187952320076 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9731 is 0.0839181387454484 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9732 is 0.08391748235386429 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9733 is 0.08391682605721651 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9734 is 0.08391616985546632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9735 is 0.08391551374857499 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9736 is 0.08391485773650388 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9737 is 0.08391420181921423 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9738 is 0.08391354599666746 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9739 is 0.08391289026882495 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9740 is 0.08391223463564804 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9741 is 0.08391157909709814 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9742 is 0.0839109236531367 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9743 is 0.0839102683037252 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9744 is 0.08390961304882505 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9745 is 0.08390895788839778 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9746 is 0.0839083028224049 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9747 is 0.08390764785080797 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9748 is 0.08390699297356848 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9749 is 0.08390633819064808 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9750 is 0.08390568350200829 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9751 is 0.08390502890761085 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9752 is 0.08390437440741731 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9753 is 0.08390372000138936 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9754 is 0.0839030656894886 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9755 is 0.08390241147167689 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9756 is 0.08390175734791584 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9757 is 0.0839011033181672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9758 is 0.08390044938239277 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9759 is 0.0838997955405543 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9760 is 0.08389914179261361 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9761 is 0.08389848813853255 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9762 is 0.08389783457827292 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9763 is 0.08389718111179666 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9764 is 0.08389652773906556 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9765 is 0.08389587446004165 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9766 is 0.08389522127468672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9767 is 0.08389456818296286 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9768 is 0.08389391518483193 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9769 is 0.08389326228025593 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9770 is 0.08389260946919697 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9771 is 0.083891956751617 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9772 is 0.08389130412747808 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9773 is 0.08389065159674235 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9774 is 0.08388999915937177 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9775 is 0.0838893468153286 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9776 is 0.08388869456457489 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9777 is 0.08388804240707277 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9778 is 0.0838873903427845 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9779 is 0.08388673837167226 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9780 is 0.0838860864936982 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9781 is 0.08388543470882462 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9782 is 0.0838847830170138 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9783 is 0.08388413141822793 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9784 is 0.08388347991242937 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9785 is 0.08388282849958043 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9786 is 0.08388217717964344 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9787 is 0.08388152595258076 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9788 is 0.0838808748183548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9789 is 0.08388022377692794 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9790 is 0.08387957282826256 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9791 is 0.08387892197232116 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9792 is 0.08387827120906617 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9793 is 0.08387762053846011 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9794 is 0.08387696996046543 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9795 is 0.08387631947504469 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9796 is 0.08387566908216043 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9797 is 0.08387501878177515 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9798 is 0.08387436857385154 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9799 is 0.08387371845835212 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9800 is 0.08387306843523955 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9801 is 0.08387241850447648 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9802 is 0.08387176866602554 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9803 is 0.08387111891984944 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9804 is 0.08387046926591088 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9805 is 0.08386981970417254 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9806 is 0.08386917023459724 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9807 is 0.08386852085714774 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9808 is 0.08386787157178677 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9809 is 0.08386722237847714 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9810 is 0.08386657327718174 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9811 is 0.0838659242678633 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9812 is 0.08386527535048477 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9813 is 0.08386462652500908 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9814 is 0.08386397779139905 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9815 is 0.0838633291496176 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9816 is 0.08386268059962772 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9817 is 0.08386203214139236 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9818 is 0.08386138377487451 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9819 is 0.08386073550003718 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9820 is 0.08386008731684336 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9821 is 0.08385943922525613 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9822 is 0.08385879122523858 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9823 is 0.08385814331675369 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9824 is 0.08385749549976469 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9825 is 0.08385684777423463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9826 is 0.08385620014012667 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9827 is 0.08385555259740399 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9828 is 0.08385490514602975 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9829 is 0.08385425778596717 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9830 is 0.08385361051717946 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9831 is 0.08385296333962987 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9832 is 0.08385231625328168 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9833 is 0.08385166925809816 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9834 is 0.08385102235404263 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9835 is 0.08385037554107838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9836 is 0.08384972881916879 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9837 is 0.08384908218827718 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9838 is 0.083848435648367 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9839 is 0.08384778919940156 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9840 is 0.08384714284134434 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9841 is 0.08384649657415875 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9842 is 0.08384585039780827 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9843 is 0.08384520431225645 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9844 is 0.0838445583174667 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9845 is 0.08384391241340255 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9846 is 0.08384326660002753 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9847 is 0.08384262087730526 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9848 is 0.08384197524519929 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9849 is 0.08384132970367321 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9850 is 0.0838406842526906 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9851 is 0.08384003889221515 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9852 is 0.08383939362221053 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9853 is 0.08383874844264037 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9854 is 0.08383810335346839 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9855 is 0.08383745835465835 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9856 is 0.08383681344617391 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9857 is 0.0838361686279789 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9858 is 0.083835523900037 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9859 is 0.08383487926231205 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9860 is 0.0838342347147679 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9861 is 0.08383359025736835 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9862 is 0.08383294589007728 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9863 is 0.08383230161285851 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9864 is 0.08383165742567596 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9865 is 0.08383101332849356 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9866 is 0.08383036932127523 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9867 is 0.0838297254039849 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9868 is 0.08382908157658654 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9869 is 0.08382843783904417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9870 is 0.08382779419132179 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9871 is 0.08382715063338343 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9872 is 0.0838265071651931 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9873 is 0.0838258637867149 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9874 is 0.08382522049791293 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9875 is 0.08382457729875126 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9876 is 0.08382393418919401 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9877 is 0.08382329116920532 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9878 is 0.08382264823874945 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9879 is 0.08382200539779044 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9880 is 0.08382136264629257 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9881 is 0.08382071998422008 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9882 is 0.08382007741153716 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9883 is 0.0838194349282081 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9884 is 0.08381879253419715 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9885 is 0.08381815022946863 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9886 is 0.08381750801398684 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9887 is 0.08381686588771617 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9888 is 0.08381622385062089 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9889 is 0.08381558190266543 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9890 is 0.08381494004381415 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9891 is 0.08381429827403153 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9892 is 0.08381365659328191 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9893 is 0.08381301500152981 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9894 is 0.0838123734987397 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9895 is 0.08381173208487598 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9896 is 0.08381109075990331 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9897 is 0.08381044952378605 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9898 is 0.08380980837648887 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9899 is 0.08380916731797627 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9900 is 0.08380852634821287 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9901 is 0.08380788546716328 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9902 is 0.08380724467479211 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9903 is 0.08380660397106394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9904 is 0.08380596335594352 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9905 is 0.08380532282939551 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9906 is 0.08380468239138458 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9907 is 0.08380404204187547 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9908 is 0.0838034017808329 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9909 is 0.08380276160822163 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9910 is 0.0838021215240064 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9911 is 0.08380148152815213 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9912 is 0.08380084162062348 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9913 is 0.0838002018013854 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9914 is 0.08379956207040261 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9915 is 0.08379892242764009 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9916 is 0.08379828287306271 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9917 is 0.08379764340663533 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9918 is 0.08379700402832291 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9919 is 0.08379636473809038 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9920 is 0.08379572553590271 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9921 is 0.0837950864217249 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9922 is 0.08379444739552194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9923 is 0.08379380845725884 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9924 is 0.08379316960690061 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9925 is 0.08379253084441236 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9926 is 0.08379189216975912 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9927 is 0.08379125358290607 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9928 is 0.08379061508381819 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9929 is 0.0837899766724607 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9930 is 0.08378933834879877 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9931 is 0.08378870011279752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9932 is 0.08378806196442212 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9933 is 0.08378742390363784 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9934 is 0.08378678593040986 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9935 is 0.08378614804470344 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9936 is 0.08378551024648385 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9937 is 0.08378487253571633 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9938 is 0.08378423491236624 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9939 is 0.08378359737639886 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9940 is 0.08378295992777955 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9941 is 0.08378232256647367 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9942 is 0.08378168529244653 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9943 is 0.08378104810566359 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9944 is 0.0837804110060903 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9945 is 0.08377977399369195 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9946 is 0.08377913706843411 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9947 is 0.08377850023028219 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9948 is 0.0837778634792017 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9949 is 0.08377722681515816 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9950 is 0.08377659023811704 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9951 is 0.08377595374804392 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9952 is 0.08377531734490434 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9953 is 0.08377468102866394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9954 is 0.08377404479928821 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9955 is 0.08377340865674286 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9956 is 0.08377277260099346 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9957 is 0.08377213663200571 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9958 is 0.08377150074974521 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9959 is 0.08377086495417772 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9960 is 0.08377022924526895 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9961 is 0.08376959362298457 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9962 is 0.08376895808729039 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9963 is 0.08376832263815207 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9964 is 0.08376768727553548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9965 is 0.0837670519994064 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9966 is 0.08376641680973061 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9967 is 0.08376578170647403 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9968 is 0.08376514668960242 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9969 is 0.08376451175908169 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9970 is 0.08376387691487773 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9971 is 0.08376324215695646 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9972 is 0.08376260748528379 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9973 is 0.0837619728998257 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9974 is 0.08376133840054811 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9975 is 0.08376070398741702 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9976 is 0.0837600696603984 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9977 is 0.08375943541945834 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9978 is 0.0837588012645628 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9979 is 0.08375816719567786 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9980 is 0.08375753321276962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9981 is 0.08375689931580414 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9982 is 0.08375626550474752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9983 is 0.08375563177956591 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9984 is 0.08375499814022545 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9985 is 0.08375436458669232 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9986 is 0.08375373111893268 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9987 is 0.08375309773691272 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9988 is 0.0837524644405987 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9989 is 0.08375183122995679 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9990 is 0.08375119810495328 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9991 is 0.08375056506555449 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9992 is 0.08374993211172661 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9993 is 0.08374929924343602 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9994 is 0.08374866646064902 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9995 is 0.08374803376333198 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9996 is 0.08374740115145127 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9997 is 0.08374676862497317 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9998 is 0.08374613618386417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9999 is 0.08374550382809072 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 10000 is 0.08374487155761913 -------- Training accuracy = 96.88888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGMrrC5urNrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e452642d-7a35-4f71-96b6-926a4fab6d39"
      },
      "source": [
        "#cross_val(X_cv,y_cv,parameters,print_values=True)\n",
        "test(X_te,y_te,parameters,print_values=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST RESULTS: \n",
            "Testing accuracy = 99.0\n",
            "Precision: 0.9787234042553191\n",
            "Recall: 1.0\n",
            "F1 score: 0.989247311827957\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99.0, 0.9787234042553191, 1.0, 0.989247311827957)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFrS1HpMpjdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "db77fe01-bca2-4292-a94d-fd206be97826"
      },
      "source": [
        "#Plotting Cost vs Number of Iterations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "itera = np.arange(1,len(costs)+1,1)\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Cost Function variation')\n",
        "plt.plot(itera,costs)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8b2d9865f8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2jSaEHdpnxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Decision Boundary Visualisation helper functions\n",
        "#Remember to set the path to which the graphs should be stored in \"OUTPUT_DIR\"\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "GRID_X_START = -1.5\n",
        "GRID_X_END = 2.5\n",
        "GRID_Y_START = -1.0\n",
        "GRID_Y_END = 2\n",
        "OUTPUT_DIR = \"/content/drive/My Drive/Colab Notebooks/fun_vis\"\n",
        "grid = np.mgrid[GRID_X_START:GRID_X_END:100j,GRID_X_START:GRID_Y_END:100j]\n",
        "grid_2d = grid.reshape(2,-1)\n",
        "XX, YY = grid\n",
        "def make_plot(X, y, plot_name, file_name=None, XX=None, YY=None, preds=None, dark=False):\n",
        "    if (dark):\n",
        "        plt.style.use('dark_background')\n",
        "    else:\n",
        "        sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(16,12))\n",
        "    axes = plt.gca()\n",
        "    axes.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
        "    plt.title(plot_name, fontsize=30)\n",
        "    plt.subplots_adjust(left=0.20)\n",
        "    plt.subplots_adjust(right=0.80)\n",
        "    if(XX is not None and YY is not None and preds is not None):\n",
        "        plt.contourf(XX, YY, preds.reshape(XX.shape), 25, alpha = 1, cmap=cm.Spectral)\n",
        "        plt.contour(XX, YY, preds.reshape(XX.shape), levels=[.5], cmap=\"Greys\", vmin=0, vmax=.6)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y.ravel(), s=40, cmap=plt.cm.Spectral, edgecolors='black')\n",
        "    if(file_name):\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "import os\n",
        "def callback_numpy_plot(index, params):\n",
        "    plot_title = \"Iteration {:05}\".format(index)\n",
        "    file_name = \"numpy_model_{:05}.png\".format(index//50)\n",
        "    file_path = os.path.join(OUTPUT_DIR, file_name)\n",
        "    out,act = forw_prop(np.transpose(grid_2d),params,act_fn)\n",
        "    prediction_probs = act[\"A\" + str(len(layer_dims)-1)]\n",
        "    prediction_probs = prediction_probs.reshape(prediction_probs.shape[1], 1)\n",
        "    make_plot(X_te, y_te, plot_title, file_name=file_path, XX=XX, YY=YY, preds=prediction_probs, dark=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaBatc_6p62v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Decision Boundary Visualisation\n",
        "\n",
        "layer_dims_vis = layer_dims\n",
        "layer_dims_vis[0] = 2\n",
        "parameters_dat = initialize_parameters(layer_dims_vis,act_fn)\n",
        "_,params_values = fit(X_tr, y_tr, m_tr, 10000, 0.015, parameters_dat,activation_fn = act_fn,print_cost=False,callback = callback_numpy_plot)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZW1bV68p_Gx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "outputId": "54ca207a-8085-4a49-e2cd-15f0a8f2f8c3"
      },
      "source": [
        "#Get the final Decision Boundary at the end of training evaluated on the test set \n",
        "\n",
        "out,act = forw_prop(np.transpose(grid_2d),params_values,act_fn)\n",
        "prediction_probs_np = act[\"A\" + str(len(layer_dims)-1)]\n",
        "prediction_probs_np = prediction_probs_np.reshape(prediction_probs_np.shape[1], 1)\n",
        "make_plot(X_te, y_te, \"Final Iteration\", file_name=None, XX=XX, YY=YY, preds=prediction_probs_np, dark=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8u6EGVL90sJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
