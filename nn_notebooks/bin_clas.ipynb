{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bin_clas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWIr65IilAMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R7vIDz5moGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "74a3b819-7fe2-42e5-e071-235da47da164"
      },
      "source": [
        "N_SAMPLES = 1000\n",
        "TEST_SIZE = 0.1\n",
        "X, y = make_moons(n_samples = N_SAMPLES, noise=0.2, random_state=100)\n",
        "X_tr, X_te, y_tr_t, y_te_t = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
        "y_tr_t = y_tr_t.reshape(y_tr_t.shape[0],1)\n",
        "y_te_t = y_te_t.reshape(y_te_t.shape[0],1)\n",
        "m_tr = y_tr_t.shape[0]\n",
        "m_te = y_te_t.shape[0]\n",
        "y_tr = y_tr_t.T\n",
        "y_te = y_te_t.T\n",
        "from matplotlib import pyplot\n",
        "from pandas import DataFrame\n",
        "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
        "colors = {0:'red', 1:'blue'}\n",
        "fig, ax = pyplot.subplots()\n",
        "grouped = df.groupby('label')\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9e7hdVXnv/9n3XAwQWBUIYBaeB0NAjyCbi7/299gechqockINp0lPkVgMWOVq6ykESC0StZ5WTwDzeBTU0CoC9ucROEoIYFvbp4rhmMhFAonNSgMRQzSBzc6+7/H7Y8yx11hjvmNe1n3vjO/zjGfvtdacY75zzDHfd4z32gEoAgICAgICPOhsNQEBAQEBAe2NICgCAgICAhIRBEVAQEBAQCKCoAgICAgISEQQFAEBAQEBiehuNQH1xr59+9i9e7f428KFC72/tQMCfbUh0FcbAn21o91pTKJv4cKFvPnNb/aeq2ZS27JlS1W/tUML9AX6An3Tl77pQGO1/DGongICAgICEhEERUBAQEBAIoKgCAgICAhIxIwzZgcEBAS0ErfeeivFYpGOjo5WkxLDwYMHufXWW1m/fj0HDhzIfF5LBcVXvvIV3ve+97Fv3z7e8Y53xH5/z3vew4MPPsiuXbsA+Pa3v81tt93WbDIDAgICMmFgYICnnnqKT37yk0xMTLSanBje/va389a3vpXrr7+eT3ziE5nPa6nqaePGjVxwwQWJx/zzP/8zZ555JmeeeWYQEjMUBaA/+hsQMJ0xMTHB9773vbYUEqDp++53v0uxWMx1XksFxT//8z/z61//upUkBLQYK4HdwGPR3xWtJScgoGa0q5AwmJiYyK0Wa3sbxbvf/W62bdvG3r17+fjHP87PfvazxOMXLlzIli1bxN8WL17s/a0dcLjR133gAO+46CK6RkaYE333jb4+bnz4Ycbnz285ffVGoK82tDt9AIODgyxevLjVZHgxa9YsFi9ezPHHH597LFsaALJw4UL1zDPPiL/NmzdPzZ07VwHqwgsvVC+++GLDAkraoR1u9PWDOgBKWe1g9H070Nfu4xfoa7/22GOPtZyGpUuXqu3bt6sdO3aoG264oeK3xYsXK0D97d/+ba7xbWv32IGBAQYHBwF45JFH6Onp4ZhjjmkxVQH1Qgnodb7rib4PCAjIj87OTjZs2MCFF17Iaaedxh/+4R/WZYfT1oLi2GOPnfr/7LPPprOzk1/96lctpCigWkgG6/3A5cAh4LXo7+XR9wEBhwvq6cxxzjnnsHPnTnbt2sXY2Bj33Xcfy5Ytq7nfltoo7r33Xn77t3+bQqHAnj17+MQnPkFPTw8AX/rSl7jkkkv4yEc+wvj4OENDQ6xcubKV5AZUiZXAV4BR9A7icuD+6Lf7gSeAInonEYREwOGEpHejGpxwwgns2bNn6vNLL73EueeeWxON0GJB8d/+239L/H3Dhg1s2LChSdQENAIF9IswJ2oAX0ULByMU9hMERMDhhyzvRrugrVVPAdMfRfRqycZY9H1AwOGMIvV/N15++WVOOumkqc8nnngiL7/8cg09agRBEdBQlDj8DNYhgDAgC0rU/93YsmULp5xyCsVikZ6eHlauXMlDDz1UQ48aQVAENBSHm8E6BBAGZEUj3o2JiQmuvvpqHn30UZ5//nkeeOCB1NizLGj7gLuA6Y/DxWA9nXTOAe2BRrwbjzzyCI888kgdeiojCIqApiCvwbrA9BMsRbTOeY71ndE5T5d7CGg+poMzR1A9zRDMJL34dFXflDj87DEBhweCoJgBmK6MFWARcFn0FyrVN0dFf7/K9BCAh5s9JuDwQRAU0xyLgK9RX8barN3J7cDzwMbo73qmvzvt/cBCYEn0t5bgqYCAdkEQFNMYK4FtQJ/zfS2MtVm7k0XANUCH1a5FG82qUd8UgDnPPdcWO4/9wFOEnUTAzEEQFNMURkUzC81kbVSrF2+m2seXVOBt5FffGOH2tquuyiXcZpJdJyCgkQiCYpqiSFxFo4BhqteLS31m3Z3kZbpPJnyfR31jC7fuwcHMwm0623UCApLwla98hV/+8pc888wzdeszCIppihJxFc0IcAbV68WlPs3uJEm1k4XpuoLkBeAOKpPe3xF9D7L6RhJGRfILt+lsMA8ISEOWEtN5EQTFNIXkYfNByoy2Xn1ejl7Z+1Q7Pqa7iDJT9wmS64HFEd2Lo88++Pookd+mUUQWLmcQVFEBrUB9laCNKDEdAu6mMRoR1en2CZoxzwEYHKSbymjjIvEgM9BG9mE0E+9CG9ylaOUXSBduaRHPl0efe+fOZXRwkHUp/ZWIC5dZwIPUL91zQEA21DvReGMQdhTTHI3wsLH7LJKs2ikRZ7qz0YzX7DDc3/N6ZaXRYGwar3zgAwD8Ocl2B2nnBEEVFdBsTB8laBAUAYkokazacZnuMGXG60Ner6w0GgyO/9rXUl85s8l/grLBfBkw5Bw3nWI3AqYrikyXqKEgKAISYQuC8blzRXdV20vpDOLuuqNRM0brLuD8KmnwucwWAdVdqUl17Q6uneN89M5pGyH1RkArUGK6zLwgKAJSYQTBixs2eN1VjbrqBeJM/WpgnHJgXR/5N9hpLrMloHN8vOI7Y3cwgmEj8ia/mak3zI7GNvb7jlsStfZTRATUB42Zeffeey8//OEPWbRoEXv27OHyyy+vmdJgzD7MkTVL637g0OmnZ5rCrkG8SH2yqkpZNg39ZwKMj6Oi782G3jaAKyph09AIxwB3bOdv2sTuiI45aLbQQdx8uRIt1MxacxRYRTuaOANqR/1nXlqJ6WoQBMVhjEb6W7hMvZ4bbFs4rEfvVuYBHRMTU8coYDKlH5eGeqZ7dsf2OqC4bh1d1jFzo7+2B5cxb9ppWfoIdS1mNto/0XhQPR2myONvYdQl3QcOVHWtem6wjZ3hceBLaLqPIG4XGUd7X7lolnrJHds7Abq6xONt82URmBCOmaQdTZwBhwvCjuIwRZFs6iB7ZTzvootYQXW7jnpssG0GnIa5wndDaA+ngzXQkAVF4mPbB6iREfH4HmAALYwHAEmcdNKOJs4ACV1dXUxMSOK+PdDV1YVSriI2GWFHUSWme0K5EunqIHdl3DUyUpOXtx2fkWX83GOKxJ0JfTCGcxfbaHxm1xLxse0A6OjgEHo3o6K/h4C7gJ+gje4/iT6PUPYSG6G23c90n6vTCV1dXbz3ve+ly7N7bDUMfaVSKdd5YUdRBaZHLGUy7IjmMbSQkFxOG1HaM8v4Scc8QZwBK2SB4B4DmgG7uaOKlHcX1ZRflc7ZD6wDPuXQNtnXx7LxcQ6idw7zor8/odLofgXwTuCk6PO2HPS4mAlzdTph3rx5nHXWWSxfvpyOjrSZ2Xwcf/zx/Ou//ivr16/Pfa6aSW3Lli1V/Za1FUANglJWG4y+byTtjWoFUP0O/ea7RQ241yzjl3TMiuj/g9HfL4EaAvU6qEnnHLfZ11kZfT4Q/b09+vt69HdFhntx+7DPke5hvK8vNnb90fn2cQdBLRGeS6PnaivmX7u/HzONxmr5Y1A95USR6RJLmQ1uChA7KM2oQYwBeKK3NzWPkoFP3VEkffySjnHjKT6MXnm/H/jFqlUVqh3l6UMyNl8T/Z0X/b3Hod29nzRnAMmAX1q7NrYzKOHPO5UnG6+EIjNrrga0DkFQ5ESJ6RJLmR8S87sCeBfwP4COjo7UPEqQnHa8RHIq8360PnSW5xiIC7claMb65r//e0Crff4ftG5f6uMMZM8iG73AeyJ6rhDup0g6E3aF2oGlS2PXqSbvVNZaGiVm7lwNaC6CoMiJZkbxGtTbGJl3tf92YC3QOTKSyZXWt9I2+vzr8Kcy/0fgX6O+FGWDr2+M7ZrhpnDRLcBOdPpy6ToPAm8S+nLxDSrdcO37GSCbM0CRdJuHLVDS8k7lcWtuxVwNmJkIxuwqkOTqWY1BNAn1NkYm9VdCVoN8nXhdbpCN2kXiKh+AK4GbqQxA24aQyty6LuiVzBmUU5Hb47sELSRc2majdwGfISFlegb0CX2DZtzzSHYGkMY5CSbkqkCyACqSz8GgERHnAYcfwo6iSkjpvetdXrPeSYir0auDXJd7NnpV7e5OBogz4tloIWFf93bKjKuI3+11BM2UIT6+93ho6wA+QTmPU1LKdIMhdOZbI+SS/FUM4/bln7J3OfY4ZwlYTNsFlIgHEs4iWZ3UiFT0AYcXWioostR2vf3229mxYwc//elPOfPMM5tIXT40IrN8kdqMkVniEJL06pIaxGAIWE5cMM5DTjPuMje3poUURQ2V9gt3fHs854BelZ8R/W/GQVIX2bgUeMPzm4rOdxm35AywjfhOZAzo3bs34epl5KkZHhDQDLRUUKTVdr3wwgs55ZRTOOWUU7jyyiv54he/2ETq8qFI/T1MSlRvjJR2N1n7M8xPSr9tw90lGN29tMJ3v0u7D2OfMEy5iB5Pt980+Ly43KC3y4F/Qo7TUJSr9d2Cn3EbYSbtcnqA0QULMlCs4dsFFIkL72GCJ1NAY9FSQZFW23XZsmX87d/+LQBPPvkkRx11FMcdd1yzyMuFEvX3MKnWGOnb3ZCzP/v6LmNdhywYje7eVuMYKPSK3b1ukTjzG0TvaAxTPhOd00mC5Ao7CuzB78X1HnSd7veQvmrvQO94+oDPAas9xxWJj4kRMpcD4/PnJ1wlG0oET6aA5qOtjdknnHACe/bsmfr80ksvccIJJ/DKK694z1m4cCFbtmwRf1u8eLH3t3rgF48+SvG221Dd3XSMj/OLtWt5RHCJ9MFH34sHDjD7hRdAKW489VQ+nsJw5jz3HL1XXQWDg1Pf9c6dyz9t2MCh00/nxQMH6N27l9EFC/j4/Pl8PIUuc/zCt7+d3c8+y+iCBfwBOvcTVv6iN/X1cdfDDzM+fz47du3itD/6I7rGyvsA1dfHy3/914wedxx/cegQNy5YwPj8+XQfOBDra3ZfH5//u7+j69AhJubM4bQPfIAOT66kyZ4eXvroR3nLl77EZEcHHZOTvLR2Ld8+8URxHL4djYM0bl3O8S46gP/V3c1V3/tejPFL9zHZ08OOb3yDj598cqb51209G59gqXWe+dDo96NWtDt90P401kJfSyMFFy5cqJ555hnxt4cfflj95m/+5tTnxx9/XJ111lkNiTysV5MinbM2H31JEcDSNRsVPe7Stx4dDW3a/+dcw42iXg3qJs+9uMeut44bAvWGcz/mmsNWH1s3b64Yh0XRuVnHQRo3Kdp7EtQaTx/ufdjPKm3+pT3nes2zVr4fM5m+6UDjjIzMfvnllznppJOmPp944om8/PLLLaQoHfX2MEkzkku2iDSVVd64DCnNeAGtxumw2u8DL1H29rKNstejPZ3Wee7FPvZdUd/muFnEPanMNSfQ7p+gVTtm7FeibRIT6JmeFo8BleNmVGR3Ree7174FefyqNUT7nrOvwl3eeRYSAwbUgrYWFA899BCXXXYZAOeeey6vvfZaotppJqKI30ieJER8DMuu57AHv77dwBZE74jSjBu6JOOyVOb0KHSBoTnEjby2wd8wv+XEvaCGKGdU9Z1vYI/LXMo2hi+hDfQSwzSM1NhBzHWGo2tkvW5/9H/exUKR+HOeDfxvZFdrKaWI+ez+Vi+37SBsDm+0bBt07733qr1796rR0VG1Z88edfnll6sPf/jD6sMf/vDUMV/4whfUzp071dNPP52qdqKGrVU7NIm+JDWSL6Fcv6d/n2pldY7jzbULxNU6pg1ENBhVSlLCPikh4LDnuPOEa9rnm/G7yXM9o656g0rVjqHzoHBeVrqzqI2S5p801r7rudey1XTDUTO/rU54hnnoy6MWa+b70W6t3WmsgT+2nvg2GYiWNx99Pr23xFyG0Lp5qZ/+qA8lnCMxjiVoJm8fawRRAdQ6ZEbqY+p2m0RmOEuEPieja/nGwgjNrZs3pzJcl04pQ657bffzEOmZYiVmnDb/zL1JY/qaNe5Z7Cj2s3WfuW8x4VuoLMl4f618t9ultTuNM9JGEaDhUyPtB+6m8ol2oHXzknqhhJySYpS4GmUlck6kHrSr6m7garQKZty6/ig65cc/eK5lMIa2RdxPNpXGz4HL0Kojeyw6qFSNXUH24kazgWtzHA9a/XUG2i5iaJaSDOaNoSmg7/Fqz++96OdXJB+9o8SfQ95YnG+THDDZOgRlWLPQ1u6xAWVI5dcLaBuDrfc3TOGraGZmn7MfnU77y8453fgr2xmo6O/XKdsb7N++B5yPZkzGyJ2EUXR68DOpzIl0HXHmNhEdY3AH2jhuUmVMGbtHRrhFuJYRoC460MbrSeH4IXRJ0k7KL8koOtGgTbNhoEkZcYskM2aTF2pC6MfQ8znKz1KsnudBN/qZ346/QJUEaQ7YaH3sRijJ1EyEHUWL4VsTZVkrFfGvLn0rvrvRCfqGgdeRPYGkFbLxMroMOfL699AM+wjhd0Ucc9E7lo3Ec0BdTaXnUReV3lXXor2OfoqcKmNddN7r+IWEQR+azdg0dqBfjAk0Q7Q9rLZR6UBgEgeaayjiGXGNEXn+o4/Grl+wxmCecD+gn7GpR+Z6Zrlja3Z1trfb3eT3xCriDx5sfRbaRiTMCUhC2FG0EO6a6BcRI3G/X0e8jCfIUboGSSu+u4HvIGcUNdf25V4aI1uKbhu+1fwc4oxujLJ6qQicA3xBOP+Tnn570GN1F1p43QEcaf3uCo4O5JdgXPhuDDiXePZWG4NoN+FtlDPVmmOLt902lajQ4AzkZzgc0dBJnCmbjLBnoIWtTcsQWqU3j3h51jyMvSTQZcbtXZSz+bYGRRpTpDfAh7CjaBGkNVHxtttYJHz/KWS3xqQUG2krPskP36bJXiHb6EEzMRdpuwijzpF2F27/JYu+n3iOk6432ds7lc67CDxJPHGg775c9KJ3PS5tgyTnv+pEC4kiwoq8uzuzXv9S4Hfw7wD2R9cxuyezg7iOuJCoBqbutztOdjbf1qFESGTSXARB0QIU0KtdNw5BdXdPrVhtmNW3vbk2qqkn0Cu8j6Crui2L2hPkR1G49kj0nTFWd5I8aYx6wu1nCPhrzznDxAMDC8BN6Psw8ROmSYk8RoHnvv71CuO2SQIo5Z1KUkcp4RiFVoHdHf0diWgesf636S8hrMjHx2OsbBtynExaWKkxNP959PmzlIMa65Xm3oydjfZgx6EkUyvQcpeterZ2d49N8tkf7+tLdNc0bo22T7vtN+/60OdNAeFz8zzkfDeMPz7CuOe6bqy3I7t+TqJdaW1aVnqOHQZ1gUCjiQXZunmzSH+aq67b1+eQU4a4/S6hHFMipdNwU5z84r/+14qxX4R2+x11jhtCjvdIek5DnmeXx4XVfT9WRmMupUtpj3e7oKA/+tt63tMuPKZa+oJ7bJvAVu0ciV6xKspG5dLatbxAea2knPN70Gm8JWOq+79bgjRLpK6UwmId8RX8MHrX8p/QhnF7XfdBtP7aTcmxGjkyewRt8zBqMEn9ZV/XpvH16Ls/Ra/MZ2/fLq7OxymXRTUGbh8G0KVY06rgjQEHKev+JTWem+LkNx56aKr+9j8Cz6N3TT3OcSZN+VxkM22R+C6kj2wurFkdSs1zMIZ6N11KeyCUZGoWgqBoIorEX/ABtPviQmDgnHOm1EkL0fUe3M31POIqKx9mA3dSKRRWk+wv4urwX0XWBm9Dv6JJHjXmNZ4n3LdBH9oga6cG8R3rVpY7H+0B9ano/k757/89xiylc4xwk4RxN5XV/XxIU8GI99HVxR1UphbJUlPDZfglZENzWs0PaYHgExwS/e0ROxHQKrR8O1TP1s6qp6QI3pVo1ZOrNnLVGleQHInrNkk15IvU9dFn0kCMzZ1bVfoGKYurpFYqeGjwRXFLxxq1mBTFbo+jj6bVCTT4VDBZ1XgTvb1iZHxak1RIKyirqFw6B6znZuhKGisz53auW5dprrbju90urd1pDCk8ah+IprTV6Bf8NSpTUGR5KX3MbRjNGEdIz1U0IPSRJXdUAdRzGzfmZhTG3vAGZYbvY3BLonNs+8YhUBsopyWxmXI/cVuCsR1INg9bCEv3OiDQ8JpAq50mJSkHkmuj+OWyZZnTi5ixyivszP1f4dC1RrhfyUZmP9+klOnt9m63S2t3GoOgqH0gGt5sQ/YQ5WR8SQzaPldisK9RZoySIVxiyMbonTd3VN7xkxjZEKg/9tC1xDq3QLx2xXrn8/WefhY5/UhC2DdW7nhcRnwHZgzOSQn3pOuO9/VNnSM9S7u9Hl07SdhBpUAzNPnuOW1ujM2dG8sB5TPUt9u73S6t3WkMxuw2h2vInoV2ZSyg7RSznONt/bI5V6rF3E3ZXvAC5foJpj1CpS7epAKfAC4hnjvKjcuYwJ87KgkrI7rcSOMRdHpzV/89Gh1vw63Jfa3z+TPES6gOUennXxSuZZdsdcfGttnsR6cmkWIxZqHtP669yOjxpeuq7u6pYMJLSUZXdG3XwO/alZ4A/ifaZjGCnlNSvis7Yt3YYGJu2IL7bjAXB0AwZtcdeY2DV5JeYKdImZkZKMq1mO2CRK6nzfnID9n22rFxf3SOSZthe97YhYuSkCTYjCF8FZXeVascWoqkJ78bJX5vs9ERywYl/KFZ96O9t95wfndrZPhqgEsJ9/qIHBOE6xpGvB9tTHYN5raAtyPxi/jnzm6059Qs9AJkDvAXAl096OR+yygvEMwzMIKjtHZtEAgBIoKgqCOSCsSUkBmWWTUbL5guNKO2vYcGkN01f8c6zhfE14ufYZeQXWf/QaB1HDjiX/4lUzadIv48QUawGS8kX/RxSaDBhUlvYjPwDso7NUgPzdqGHnMbfegxN7gfLXxcN2GTcM/egfUB30LnoboLPyMuIefMMu0K6x5KJM8dt58+KoMCTaW+n0S0PUh5ji2k7LF2oA51twNmLlquN6tna5WNIotB2jUO+gyMbr0Dn9HW6JPzFN6x+3dtJtcL92CfNzZnTiajZpqtI2vz1dE2wXhvIAeaSfUWknTtK4R+pfv0GXclW4x5Rous67rzz/Q3IDwn9x6yzB3p+kuQ7THV1MtodWt3+qYDjcFG0WIUSfc7d1dwdyH7w8+iMrahhOxvfxRU5IaSgviklBymnoJrM/m8595U1G/3oUOZ8nTuR+ccsjPUfpD8ieTc8boeHbzXSVktNot4oJkU45Cka79f6Fe6T0PPJVSmSfHFtkxGvyVddyE6iaBra3HvIcvcUc5no16U4lhCTERAHgRBUQNstU2JbGnKbIaVpP+W9ORGjTGCVi18C606cc+1g/hWUWkL+CCaYReRa177ssb6aJOwEq3+GaFcY6LaSgEug59HXAVk56JSyJl20zCPeF4j6T6XoFU336KsXiwRV1+BfrlKKdfdj65fniVzkTR3zDlDxJ+nmX9JzhJpkdpZI7kDZjaCoKgSrj3ifKpLU+bTf/tWlJegDd8mVcdU0R4L3ZQ9ZnzZUkvItQ/GhGNduB5ZNiNJ8u7yIQ8zOhNd88JGL379flaUSC4+1A9iZt+vRsdeTmXywhHypanzVTE0kMbIPuctwFXE64wswe8skVYvI8nmJqEQ9bmEIFhmIlquN6tna4aNIskeUa3f+Qq0n71bC3oJ5eRzIMdcGL/8LHERtt78HuK68UPCdwrZRpE1kM1Xo9nXR55xnxS+S7peUt9riNsgbDvOcMq1pOeVff5VJriz51GWMZJidJJsRb44D0N3ms3NnefNSCDY7vr/6UBjCLirfSAyt7zMMGvbunlzBXOQXrw05m8zqH7iwWK2UJEM3bcI3yu0wfXnf/EXqYwkq+E0qQ+fkJXG/XX8keZZx91lxGtITidS7bX882+lgkEFBxQMqgtZoYYpR+8Pp1zTN45LhPEy81RykBjv65uaw0lz3B0vKfCwmudQy7vdLq3daQzG7CaiRGPKpozPn89T0f9u5s4+ymqOu6l8ineh7Q6u0VRS08ym7HMvGcj/o4e2HuD13/qtVN9+O5AtTQVXjOiXvpdQIj7uXZRdVMfnzs1dmUAKZvswBcbo5wQKoh1HUVbvXBfRm6ZqKQBznntOOC5OwT/yVV6nwBHRt+49G9uJUUedQXwcO9HPWJqnA2iVlauy7BwZoTvq96iEc93xupN43XGi74rC9wHTD0FQVAEp1fV11C96tUi8ZjXoF+8M4MNU6uT/BLnm9nrixXdc7xobHcB7he8VcCNakBmUSA5kexc6kvpd+A3ZUnzIbCpjGGz4YiJMBtsXN2zIXBPaoEilwPsmK1nMbgZ4jJ+ymwcFzfwbaOGUtVCQ0fW/7aqrhONcCqCHMUoJLLYHvQgw9gO3HCrohcU3omPNgmKEcjzF1zx9/xPwEtpY78ZimOzFUlS9VE42izE/YPqg5duherZmxlFcgWwbqJV2SZWgou+Wk54nCbKraaS+/oXKZHZf8oyfL64gq90hLT7E13x2oGqerz3W+yio2QxWDHsXg+qXFHKr2AyN6aq4gsK55mwG1T7rmqNUJpKUVD1ZMgoPEi9CleUc2+biU3OtJtgopgONQfXUZJgVu506IS2+ICvMylnyonktYx8lZDXNTVS640rRwWeio7xvRZdX/bDnGpKnjqTK8Y1LSbj+qxTYkeIDpd1EC+yvg+OmvUvZTpFeZ708wRhXUox5EyXFJtjeQpL7cqXbbZmCTl5jNof4CpfzG9H+1H7+xtVYKp+aBZ3E3WRN/z64qV6SdnUnAr8btROp3iV65mFmOBm3XMrVszVrR9EIg7ZLn+RFI9WjsGs52CttX2SzFAlsN2PwdncEWcYvfVwqvXtsGr/GStVtGXVhhdO/OfcKhXBcLc93Eah/F3YUuv9CbGzzGPOTDOCm36Oje1tHoWI3N5bxGsPIaeaT6FDRc04qE5vkiFCNd1+j3m15njSiRGpy33EaKx0V4nO6uS14PdU+ELlaXo+dPLT7XkKfF85q/OqeJBWIr/kYW5bxSx4X+aUpgLougUlTce5BBZPicbU8XyPg7mWFms2gOoKDajaD6uSEF1tSvSW5L7uFn3zPbBE6xfhyoS8jdFdQqeoZIe4dZQSNcZl11XyTaA8vty+pFkY7tGzPt5GM2e17tXKFRiWNcbVi5Zxur4/ie3EAACAASURBVDEMgiLbQORu9S7ssmXLlkT9vsSETD2KNKElnWs3UxlNYiiGOWUdP3lc/C9NAdQP6FfzOOj8flCVX0T33PhxeeIU3ObaKn5MvypFtCXdawHUOymoI6O+fYLyPLR78SLher5nlnRMFtddFT1PX76npJiKanJztfLdLj/jejJme85IfU9Gc29QwRoFBbV581brnH6lhYo0p9tvDIONokFIi6a1kUVL2X3gQKJ+v0Tc7tCLtpG4Outx0uss2xhG5xw6g/Tay2mQx6UoUKm19UXgKc5kwHHm7Zi6snRuHgrTY4xt3Xsv+zmdp7iB/exPeXL7WclP2c1rUd/7WRHT4d+Fzgv1ls99bqq2h3RHs9FR5RJNrneddL6EUbSN4QWrL7fWiFS/YoTKuh7TA0Xql9XKnTPSKHVQtlB+CniJ9773P1rnnEF+R/r2tWe0fKVQz9aOFe6yegE9t3Gjt541VEYPD1KZ6VRSO6y2+jbn+sqQftM61lVFGA+W2sbPv9o7WlQ7Taq5rE44d1LBayrdRpFvlVmp9ktTYyTf02L61X+gkNmWYX5zdzGSd13WHYXrteQrn1pvNWqz3+1qnnX+fpJ2tVIz6imjMk1ThTXenhFUT7UPRENamorBZky7brxRtA9INZBHnOMkQ6a5ji2oDgnnSjRJNG/dvLnG8Vih5JemX/U4W/RuXlOVW3T33DT9MFN9V7f9z8J0fH3fpMwL38GgupsVMYa+Jmpp6cWT5o+t4vPZIEaIp1iRFiNriKeQafW7XN3765tjeZrvua6J+nxNxe1kUhtQsERlM643x54xLQXF0qVL1fbt29WOHTvUDTfcEPt91apVat++fWrr1q1q69at6kMf+lAjB6LmJhmhk7yA3J3GRGen+KJnqTMxEDX3OpL9QhIqNoPyxTc8t3FjVWMQfyHclybrS5LX46SWFzCLgMm28nTjIsx4Zkl3kuZFluSsIC0cPub5vkBlCpnqnm1jW/O8npLmjOl7tYJDKllgTKrswqo59oxpJyg6OzvVzp071cknn6x6enrUtm3b1OLFiyuOWbVqlbrzzjubNRA1tSSvo2rdKPO4OvrUB1K+n9dIzo+0yEPL0w88UNUYZGu1rwT9z7eavrMKGLfvNcp94fs4qJ6kX2T2SQ4Rxj06q1rI7ktaDLxOsopyy5YtXmFQ27OtT2uuRiDLnFmitLBwhYPslVef+da4MWxLY/Y555zDzp072bVrF2NjY9x3330sW7asVeTUhKQgM1+AkhSw5ULKxWQwKvQpXWcbcXOaXcJTysfkq/nQdcit8lxGeqCda6RzP+dxDciLeN/pJsO0Iqq+vuMlhUbo4VjHgGmnO5Hu2phSfak0kgohXYJ2ZnDnz5tilOl0Kdui/+dv2iSa/NOf7UxElsTvoPmoC6mMVVH4rkA5MTtUV6igOTA5zpqO5cuXc8EFF3DFFdrP49JLL+Xcc8/lmmuumTpm1apVfOYzn+HVV1/lxRdf5GMf+xgvvfRSYr/79u1j9+7d4m+LFy/m+eefr99NRJjz3HO87aqr6B4cnPpufO5cXtywgUOnnw5oj6bevXsZXbCA8fnz6du1i9P+6I/oGitPKkWycFDAxJw5dExMUFq7loFzzqno077OxJw5dB06xOiCBcz78Y8p3nYbqrubjvFxSmvXcmDp0hhNBn27dvH2P/iDWJ6oQ089xfNKni5JY/DtPb/FunVFursV4+Md/Jf/8ioPPfQbU5/Xri2xdOmBrMPtRdLzPXCgm717e1mwYJS3Pvl/KK5bFxuPtPPmzx/PRMejj87nttuKFfe3kvt466c+xURnZ+o1uw8c4B0XXUTXSFlcT/b1seOv/5qhU0+teFb2OeZZ9u7dG3sWvrk12dXF0488QtfBg7z9Ax+gw7rmRF8fzzz8sNifO7+bgUa9v3mxaZN+vh0ditHRTpQyWdcM3NFWPPDAs5x88khFH3/5lyczMaGP6+lRfOITuzjnnIHc8y0P0sbw7LPP9v7WxO1cuS1fvlzdddddU58vvfTSmJrp6KOPVr29vQpQV155pXriiScatrWqpeUNvjPb+DeoDG765bJlosrHzrmUpiMugLqJuJogj365GhuFbwyO9nosVbPFTtY9V/qw2+eUjcswqDY6xuVkDx/Xlz6r7jt+rG0DSHoeaXYJ33xKSvvtU2MOU/aq8tmt8s7vRrXmqZ6SnnNBwbAzjO58luZ3mm2rMaqmPGPYljaK8847T23atGnq84033qhuvPFG7/GdnZ3q4MGDjRyIqlueoi1JwU1btmxRq6PPr5O/9oFhGLXUTPDRmMXrSda3S0Y690XKYrRLcx1cqfr6xp3fzTmV13ONyzITdgXMcNSqd1008y9N35+VMSfZMNwkfT5BIdmrpGvmDS5thOG7OYIibZ4tic2n9CZ5y70uHDegshmvqzfWTztB0dXVpX7+85+rYrE4Zcw+7bTTKo457rjjpv6/+OKL1Q9/+MNGDkRVrUDcQGhyL0nHJ60W7RQelxF3YzRulT46fCk6BsmfkVViDFlTeFQyiLSo6iwrKdnQ986pyOl8fu9HcFD92DIux5mwLGDy0RwfC2MsziIEfIzZ9GncpaUFhc/bTRIYJj7DPW4IWYBlYf6NMnw3XlD45pFxcUUlCwrp+0mlHRzSrpN1R1FbrMW0ExSAuvDCC9ULL7ygdu7cqW666SYFqFtvvVVddNFFClCf/vSn1bPPPqu2bdumvv/976tFixY1ciCqakvIlvbbtCRGYdPnY/y+3cFNAh02PUnpGNLyRNmMrrpxWqFgRPlfpNUp58d3JUdwUD1Bf+TZJe1aBpS8atOpw0sUPKvjRQqGxPMqW/IuSBrTLVu25FIrueNvlztNS+ro83b7ApUCSFJT1ZK+o5FqqsYLCt/u93VVZsoFpedyVkHhY/4rlN6hGi+pYZXO9Gv3jJqWgqIRrV0ExUfxvxy+1aJLnxSQJe0qpF2N3ZJ2FHle7OrHr6DiboSmva6qCX6z1Uclrx1E0iXrF15eHa9UWkhkUS0kR3f7VHdJ7tJpMQy+HaOZFwPRMWtIjtFw7/12KlVU66t6xrrlta/U692uT0vb/Q4qvZBYo+SFz6jq7p5Qlcx/jXee6O+XqModS1KrPdZi2rnHzhT4agN8Gn/VM5/jXfeBAxUum3cRr0jXAdxiHQNyRhkXJc/3ReqXHcePInGHW4Mu0jNJxSt0jNPF45wPwFHs5y1cF/1mYLxODqFr0h0CbsaMuK5pYTsfGifQWcT9g1R07bKT6pu4nP4oE5R0t9KY9u7dW+F0a6gyVeeSKuVJfdoYQlfbA7gBeJrK6najlPNE2fdeAFZTWTHxCqp3fS3RmDLBjcUi4DLgGMpPx67aYmMb8OdoB+T/jZ4T5kl+gO9972l0RY5Po7Np/Tn+p7ofeDxqWdxgS7RydBsspZvbWmHMNjsEqc5D1m33SnQKBddT6QtCn+4KzberGUJSrVS25u0opBV/Hh2rf1cxCOpI+lVPz7hzjWGldwivZ7iWT+0wpMqrQm1EvDi6Zl5jtHEGMCqk19EpVdzdoM9wLdkcTNW7dcLv7rESrT4Pt1p2APXOqtzY9/d2Vd4BTCpYr/zqR8mbabmydwSaxkYGz9UWmBpUT7UPRE3NZ4DOsu2WErUNUy5/mSZ8Csj5m7LqmrO+2NmSsvm8MdwX8pue43wtzsjncVD9gP6I3kUqm5tikhrAfbmHon4rx7paY7TPmJ22EHD7NCqm1ZRdoSWjttRcWn1R+LWmGJ8eXk++ObM8Ntf091IUduUiRNPY6HQczfd6CqqnOmE/8D30RtBGlgTY24A+5/tetBLkCMpRkaZ9ncqN6n7gL6PfbIwAJ5GetPh+4F3AtdHf6mKik1J5SwqO/yL0UUigtoS77X6DHi6mFNE7j76+yRQak5RqUiT2B9EJussokk1V51MvSue78M0ZoxCzn/PN6EjpeSQHaxq46efnoe/Uhpk3tSCu2mtHnOv5/ljiKh5JFdWBHsEsBQF60HHt1Sr1bJjRhWalJA+Coo7ImvTBIEkrLn22dcirnd8le8Zs4EGSdd+gWfxP0DrunyQc54e5E1+ShyLp7DWtZkR8dBWX8+up0S1loDNJbBeAn6NFpT+NSInsWmKJWUrnu+lYrkOPjP362yNsWNOdxJNFuKzMRa9Da4n4XOtDz5u0eWDE+iLatYJCGp70fP8E8Tf5WmAdZeuSO9L2fHbn6gjaFvctkt/EPEivsVJv1Hk719pWD9VTrdvmrOdLHiJJwVF2GxL6N6qJQU8/WXXfkmqrn6SAO/9Wu4CuAJfsn54ne6zkJaK34mvW/Juq1N+uV9n0ufl806vVwZv5J53vxke49g9prkjBciP4AzalGiX9lF1kffNFms9udoE3co5Fvd/t6tt6FbdRVM6reI32dd75Gi+FusR7bH5aDT2Lqu4z2ChqHwgFzc2SKTHpIbSB0/5OEhwDyHpsKY20aZLuO82d0R6P8b4+z3jIjN42+m5kheqaYtpulHM842pcp+tj5uXvdWS2W6ciTZ9bneExeTEgX9ONk1lCZVGhJKHt+80weUnomN+MQLGFhB2TMQTq86DGZ8+OzbtvEn8fklx1G5nao3E2xkUKLlOuPSp5fsgFieI01steYc//IQVvVNVnEBS1D0RLctrYq0vDiFeTvqvw7Q586RiSzsnLnOTxqPTGeBMrYueWKKh53hVWErP2vaxZV1ZJ/ur1Njz6dyf2/JMWJGlCOy1aW3ou0m8+g7pbD8V87z5/KZhPoreZ73bjWtL8iC8I4jTWwwOqfvnSgjG7DjgD7flso14xBZKZ1tWKP/Pww9yPNm6/7pxvP7URZNtHETlaQVFZb9lGkl2lSJ4Yi0rz7ancX3HuqxT4N4ocB55ejf7XULHOuTPpnHM9359BebRXAi8Bm6P2EpX63BLpVockIzvOcekJuX1HDaRQ4jOQJxmOpd+KxG0bkqFcwmzgtwU6JXpnBkrkiV04cKCbyrmS13IpoUh8ng+h3+rmpSRvgZRuXKtWYtYroZ7UpJrH0nd2ridpJb+cSlWF23wqgUm0zjpJlZZ15Zl1POxz72Wlms2gOmJqle1GTNvVwyozvZbTJmTdUQw757vXklZfSb7peewXybsT83yTdg557B+LQF0VzQufLcH3bKSd5/js2bHvfXW4jVrLvDPm/+lno8jSpOJUrt1CJ6GMJ6Y0fVTv0po8//P1GVRPNQyEbytej4l/BfGXbVj4zg7IguoNplLaD/c6eQSfpBrLypBWoNVNs73M3GXMSbEM0staqPi+t3dcpaeAVkrO0im9yHnVBsnJC6WFwD4K6sf0q9JUgsP08S2gbQd22o3xaF5lta1J6s2Jvr6pwD0z774pHGenH+8nPf1IM97tbK1WZm0WMQeFeeVTn2ZNz5HW6lELPAiKmgZCWuEN4E/sl7X5Vm4SI3+NeL2HaryvkgyN5tq+DLRJfRqvp7zG/iPpV53iKnuJir+0Nyk5AGpIlXcWvh1Hv7rzzu0qPaV5dn1udfaL8gvdha59YcZq57p1U8etAPU1a6fVleHlL1AOsKvGhuX2tY5yUOcwqImurila15DdTlWrl2A93u30lnVn6BMmaXmgpCSU8YC82lotgi59DIOgSPmtViO270XpJx6prZBf8iHKO4paXzyzC5CiuvPem922bt5cxTjlcX3NkpDN35cuXJRm9MuSrTYv7ZVz4Z0U1FuiXYJ98nhfnzVW+fr2qUZ9TTIqL0JnD/gYlcJeSv9hP9ek3W2WhUO9BEl9U8hIYy0JE8Ocl6i4p1HajqKaxUljWzBm14BazE1JYS8l4pHaCh0d6353DTA+f35dwmiM0fN8dGoy5fxerYG+d+/eKhIIZh3dIskxy0nGa02BLh1pp9wbJh53bFeJTkO+mWGe3T+ynxd4ioJznOrutsaqmHgvNmzjd5boayibW40Z/svA88BG4HNUGtI/TnxO2pT4jOhZTPfNDwuTUCR9rKW7uYcy9Q9G39mweeldwOX09U0gR3FL18viINEeSBUUV199NUcddVQzaGkp0kqpS0h7UWw28zp6qo5FfxXlHJVXAnejs8f6+ss7rYy3y3riEdvVeqaMLlhQZe7KLIXqjyI5B24fOro1jQLbf2cS6HaO785EcRnZZsbRFPgo/QxS4Ch0tL3LVjrGx60rl8jqTVPEL0INm5rAzm2rPdyuRLO57xNPoGKjFx3tnU6JhpmLZwh02ewwmw9YM1AifayLxO+ml0rqXbj5Ep7g7/7uZ9ZvNvrQixQoi8/HgT3E8yy0H1IFxbHHHsuWLVu4//77WeopBj9TkDc/TZH0F8W4vy5Hr9p6gbnoadSJftnujo73rdjNC1/NqqweznkG4/Pn19CXb3TNS/MttCAYQYvVcSpXbH1ottNDJUssU6BdE91EF+Sg2CeO02bGSg6wm/fxGAvZzTejJ+Q6MJbWrrV6yP5kSsTZnBmVcfRi4HTgfcAlwPXodCzryJYHyrA6hR55lxJ7V/BS1Mwae7bTVw+aHfoEiZtrqjlYgp5b9nzqgihNvUaJ9GT9SdBv/hNPzCeeuc1c8ydooWDm6JHoJcWXySYsWrsLyaTb+t3f/V31zW9+U+3YsUN96lOfUm9961tbrm+TWjOzxybZNlzd7RrkFAy2HtlnA6hHEGA99MS21065r3q7/Zmo7bQypHFvko0bn1Oy8VkynLut2hKTyenPbY8gef5lG78ku9OwM9eSilgltfE5c9RlxA3VSc4R5trGfrE+hZZJtE2kmnlY3fubZPtKc5N2PeiMt95rSvZ6WhR53iUNs6/S41DKHKitBGqWMayLjeKVV17hlVdeYXx8nPnz5/P3f//3fPazn816+oyEb00I8S33LcTXK/OA36K8RpBW7Ouoz6qsntk8y33VqoEuIm/3+0heA08CB3HvZsGCUWQVwzaS774WJUkR9x66GWM7RS5H554tRUd1HzggXHk//YI9w4VRgF1DPBjTVZD41sX2my9iYoLvEQ/O8x6P3jEtQ6/Z34VWwNi0dAD7KLCFfl6lQAdwE820VxTxK+5cu4EZ5UvQd3U1lW/jKsrWvyuJv/nz6OlxR8v93IM8t0fxv9XtocRLlEDXXnuteuqpp9SmTZvUJZdcorq7uxWgOjo61M6dO6uSao1srahH4a7WfQFV65ATtZnVmHGftPvzxXisTqGhXvfiH79mpSbI7kGi6avG37yWNB7xe+hgUB0d0ZeUK6uavGK++ZD2+RCozZ7fzK7Vdt81TapXYTd7dyvN+69GLsBHckDNZlDdy4qqd8bJ7281bq1ZPJ+Scoe51yxEAXdJ89k3v5PenfqlmWmYe+xf/uVfqre85S3ib6eeempuQhvdWlW4yG4+ldQSZHdZ02z3SZthS8FR9ktWr0SGaf1Ujl+9Jm/adn/Saf4i9GX68qrDsgi9pD5l4ZSkmqzFJdt1V3XVO646yCT28yWXNOom9/0oRL/5YoGGnDni3tM+IdjSrnWeNy+U//1NU8uY5zOoypUVpePS5kG6+mfdup3OXHAzGPvruNc2P2sdwxBHkXUgcrek1bcvlXSSvnds7lzVj2zfcAWMCQisNQbEvpe0fuq/o7D7MkzYZbrfjP4OKK3H9cdAZHu+PobvXtdeSWbRD8f79e0s+1N+yzv3ktKWL0qZc3a6eilp4UH8cT9SFTyblh/Qr3qcxcQRHFQ/pr+OO4o8cTr9Cs5T/kyxSYufbNfRsTxuAsqk+b0m1ofcQmR2XVuzBEWWVbwJcFpE+cW9Hn+9gPG+PvHFlgzaRmUgGcmryeCZhXHFx68+k7eyFVT5RcuTd78QGbNrMQiaF9rN4+PLTZV8L43aUfiuJS1apOdqzyFbhZmUa8xOFzJMeh32fojUb/Edxc7I0J935yu/v3l2tr7nb5570nyTrvOa0kKnvOPw53ryzfG8qtoQmV2X1gxBkeUltwXJMOWCMobBD4H6EpUrwZ3r1nkZ9hr8SQtbs6Oo3+QtN/dF/qaSdbxrxPPmzh1TfgHgS2/uJlbLYjfJrmKTcmVJvzUqoZ6P6bv1KeznK83B10B9lHj9jHS7WDz9fLW2tNp3FNJx7qLAV+zKNy/sHWjWRU19PJiqaUFQ1D4QmVva6jtNxWSacZ80BWy2bt6cyLCXoHci7nWNEDEMZzXVGbbTGFdjbTx5DNvmBUwSAK5e+XWhv0Gl1VkHVVmtJa0cq8v9b5phqFKFwHo5IeR5rmuQmX1a9mLfQihdyNVnMeGff1l2ttJzfT167mmLB/c6knusmUdpi5okwVbrOKWfHwRF7QNR0ZJe4LQXKWm7bze3gphZcZoXe4DKlzBNldGPv5RmPe67sYIiC4M2bUCVkwNKAiBJr5zU/6SCz2c4J2uuqGaOX/7n6jJ7N2mhb9FQb7VZfcYvjUn6FiLud2m7xYLS6iaJ2btCR1pU+FRl9nyuZpeRbZcSBEXtAzHVsqyW8r5Iviapkgyzl2pI1PsF9gkG6fv22lFIL6X7cvareCK3SVU2jB8SzjWeVcPRcS4Nr6lqq9+1UlBIz92dK5VJC+U5YDyhXOeKRla2yzd+SQJjtfA8q9ktLvL083nhe1fw+HYUI853wxnoSOszfn5IClgnFMgW2uJmAHqCcuDcfuBm9AjnxThwB5VJKOzrJ2UeKpKnIp0/YVtrErlJ4Yt3oO/AnrPj6HxN8TQJs2dPUJmAYgA5R88H0WFfs4TfOqK+J6Lj3ExZ3eiZ4c6IdMSrn7UGBeD3iFe5q0xaqEewhJ4/Bcrz4g7gCOfc9qhslzZzpdqRUJ5bo8h1IF3MI55scgjYSW+v+9a7IyPN8/9JPH1oLzoJShYUyffmV4eGrgKa3WrdUVTjtijtQC5DDm5KC44yVe/yXN+0PDsK37E+ryvJz74xzQ1oyr7L0PUo3G2+u6MYVLBcJe9I7J2Drf82O41qjJBZPWLq29xdQZLbq7ujcOe1lI7jNeIuuY1SQaWrnrLEwqSpFZNdsP39aMN2T89ENEfSPAHteb5EyTuUJRnHJuwomo4SeSrk+ncgCxOuodDrCLNmNmuLib4+riG+tsi6WsuTALBIvirUxQzXrw/sZCNFgRoXCp1I4nLOO2+AyrstEU+X0AV8HTlxm4156BWdndZhIjovbxoFPUtGRrqqOLd6uDlKr6cyHZ2bCPAXf/zHDsXJqUEG0ClFFkZ9tTadeJH0mbsfnYLT5oE2OsiWpM/NC62ic49kbKwTPU8uIa5rcPsw83ybQPsojUqHXy0aIv1b1epho8jjtuhzJRzBu2yZ2jmYgCXXK6ZWt8k0Q7wvEKs9dhR2y7KjMKVSffSlRX6bJiVrs1dlefz13VbLudU9a59brPvda6A2RN+PzZ07Nd+kee3LDtAs43bjdxTuvEqzERjDtuvtZJ5tHjdYM0/TA0uT6WmM11NLdxRLly5l+/bt7NixgxtuuCH2e29vL/fddx87duzgRz/6EQsXLmwKXXlqU5SIr7R6ie8KXIxTrgFg1hbj8+fnvr6EtITej6ETHt9FfA3yAs1Ym2SFz25hf74GPZK+1bk9msuI2xwUOm35XxPXX9vpF0vk22vaqOVcP5I08kXiNogO4mnBu9GWmDlA9+Dg1F5nQKB4lPIaepiyNr9Iq3ehkG1VXSR9h2owhrbkJO369gPfQ9YBDJAvkd/96D1fN3re3U7+fVk9U3/GUVepn7V1dnaqnTt3qpNPPln19PSobdu2qcWLF1cc85GPfER98YtfVIBasWKFuu+++1L7bUWuJ3cHICX/c5u04mrkij3JJtF4r6d6+4fLEdQ6z07S+VLkrV3XWMrDY6/saolEXxHZKOoTxZ62ii8g52gywZ52TIXPJiftbK+IzrddtyVaShTUkXULxMwz/xYpf4qOPDsK4x1nnlXSHC7PC/2MVyj/LtKX8r6g5LTm9YivyDaGbekee95556lNmzZNfb7xxhvVjTfeWHHMpk2b1HnnnacA1dXVpV599dVGDkRNzWasBWTDX1oKhEbSV42Rvj70VZcnKb3FX3r9krp92NcfVjCqKpMMui9mmrtktS9tQd1xx3blzwGU/3m+4TzPQed5+pJJ2ouDLAInaV4PU843NRxd7xtRxtieOhvu0+dflrnmJgiUjMjud6MZ+tXPUud6kuennl8mMM/tx2fQXpfh2vUZw6TfjD2r6Vi+fDkXXHABV1xxBQCXXnop5557Ltdcc83UMc888wwXXHABL7/8MgA7d+7k3HPP5Ve/+pW333379rF7927xt8WLF/P8889XTXP3gQO6Ct2CBVNqIh/mP/ooxU9+EtXZScfkJP/+Z3/G6IIFoBRDp54qnl8rfWm0v+Oii+gaGZn6bqKvj2cefjj1XrLQd+BAN3v39rJgwWhUu1p/d9FF74iMuBp9fRM8/PAzU8ds2jSfdeuKdHcrxsc7WLu2xNKl8boNLp57bg5XXfU2BgfLpU6POEJxxx3Pc/rph7zXr4TCNnb39EzQ1QXDw+Xj584dZ8OGFyv6fOGF2SgFp546NHUfSWNh7rGvr5ORkUnWri2hFFXdt0Hfrl28/Q/+oMJUr4BnH3iAkZNPnvqu8O1v85bPfQ7V3Q0TE5TWruWAU6ly/qOPUrztNjr7+pgcGRGPAZj3wx/ytmuvnbrmqxTYRZGJT13J7LOLHP++P+ano4tZxoMMW27J7jOvFmnzL22u2cfu3dvL+Dh85COLGBsrn9PRMYlSbsHYynmSdD82jd/+9jH8zd+8he5uGBnpYHKyw9vPj340j2uueVvsuj09KjKQp187C9J4zNlnn+39rS7SPm9bvny5uuuuu6Y+X3rpperOO++sOOaZZ55RJ5xwwtTnnTt3qmOOOaYhEjOtVVs7II+7YDX05blGrUby/Gme04y42d36ys2vRorvKKTruys297MbhOemAzG7Dl/Kc6megXSPee+7smXZvcWvegAAIABJREFUUeSZIwVQz23c6FVFgk4hY3Yo91p1JjoZVL/BejWbQTU3MVK+unfPP/+Ma6lp1TgMuOpEN/BNmif+fss0mnkwpORdilKVwZuS6mlE+Q3l9RrDbL+1zJj98ssvc9JJJ019PvHEE6d2DtIxXV1dHHnkkYm7iUYhaxCei8aalvIHxtVqJJeRNDolko24RaoPEYyb49euLaFHu4B2SexGDqrzYQi4Ddkgau7TVN8zgXn2TJDG4k7iZuVJtAuljXzm3xJynbSS8F2Webgf6Nuzh5+QHK42it5JfIivMMQcXuMoJpnDq1zLEHMYFCt0NyIcbyW6evfmqH2X5Arevrf1CbSTwyXIzg4S0u6nAGxEP/9ZlOeLi16rn/3oCnqHgDeiv1dRvbN8/VGzpK+mdXV1qZ///OeqWCxOGbNPO+20imM++tGPVhiz77///oZJzKRWD/1+lpY3F1Wz8+1Ul+Y5yQCcZ0fhO7acwE3TZ1Zyb6jyqj+LHtq+tmQQ7Vfa6O2eM2DdqzQWryk58Zx7L0NKNsD6Wz2zzxbQAXc2UdJ8WoGuM3FEal6uSdVVYQyu5/zzGaVHVOVcM5lgffr9K1SlzUDa/U0quMfp161659Io2RukXYrkAuvareqbyn/aGbMBdeGFF6oXXnhB7dy5U910000KULfeequ66KKLFKD6+vrUAw88oHbs2KGefPJJdfLJJzdyILytPfzEK1uzhFc6fVn919M9RpJfhPRYBG1IzOLVYvzV3Rd3jUquWSD1befk8Y2FZkCVadBdo+obKffvn5v1iIbuR8dR2MT75tPRFFRHanzLoMpfbyH5nvT8M7EL7vMzQtt4FZ2nZAFt6LnCQ7MRFkZlNKgqhYOblrzSIypdUGSN/nbfscPU66lRrVE2imbUDpieOwpU7ase2+7geyHSBZIuXOTqdH2CQuorjblISeVsF8Z1qhy459owpMJKtwj95bNVVI5fXq+x8jlZdxT+Z+7WcfCvupNaki3wttvsMqNJO8KVqszopYVFQXjOZvdnsrhKz0Vyrx5WcRdtyd5ghE7WinbNfoeDoMg6EKmttbls4q0Zwis7fbWuevK4NsoCSe8ofDmc7HiJFUJf61UycyH6KxkXb1JZXGs1fWaMpBWtYVZ+Y2V8DpbHrQNdGKjasd65bl3O+ZQtviWrS3Ty4qcQOSu4z9QVykmxEoPWdaUFxVDCuQeV3skkq9zKDhV2pHU9BER9dhVBUNQ+EC1vjfZ6agV92Voe9ZV/16Hp86WSfkPFt/x+DyqZDh+dvnNtpu8mBZS8awyzkpmBu9peJtAzm8Ho+/xjvWXLFmE+5WVQWZ6lLKhcdeo+Cur79Kt3RjRo1Z07vh9VlSouSUVpq3t8z9vELPh2pL4dReVc0zTankxJY5d1bCVPuuqERhAUtQ9ES5r9YrYjfc0ZvzT7Q56iLEYFNKTkehKSasfHXEaFa7k7kTVKNnLbTF9intJuwl8USVpt/4B+1enQfQQH1Q/oT1g4+Mc6/nyrKdmZ9iylsdCGfPsejfvtERZzjO8opGfp6/9jzr0YVZlxNlit/Copu1LdelW5kxmtOLa3d0Jlc0rIOra+uVOdmjcIitoHouktqcJYO7bW7CiyrFB1K+uw3ShsdxV6mYrvVqRdQZJnivHd9+1G7HP7lVxAyf18vXeMJOeFnRRUl7Cj2EkhwakheUeR7Zm4/ZnVrRmX+HnvpBAJL0ntY1b8K9QKdPqP2UIfa9bsUtlsYa4w98WySLtTaUdqjpXS0xsbhbZr9PaOp9CWZ2zNeCXFAuWzaQVBUftANLVJK0S3HkC7tcaOn8/+kLZCNU3SYUvNtVXoc2GDklf5kirIXQ2uV5WBeCOqvELtV9pILgkGo8NO94Lx6e+PZ0W08j6oZjOo7mVFBqcGeawrn6887kfSb6mm3PQopg7DyNT/XQyqjayYWgyd5bXNlJnekcJOCQ5azgBZ1C72cb4d4xrhWKJnMaT0omJQwe3O83XnoiRAkhh41jltaPOpNpPOy/8OB0GRbSCa2qQV4tjcuQ0vJ9mosa1Pk5hA1tWXpMN2GYO0UvyYKjOFLMZlHz2LVHmXUVCVTHRIyV4wJhI8mwrB57ywjIL6Af1qJ4UcTg3xsU7bUXQypP4vi9QBUP+XRaozsfjTpJrFOlWiMPXlPnGnIDG9RUpivOU8SknzxXev0nUHld/wnsV+ZfrIGxWeZ0eBKgt2aY6GHUVVrd0FRVI9iMN7R+FrBaVXfmkqh7Qdhc8mkLeGcpbVYFabRN4XXq+2y2qc+LyqZf7En29lrMcs3lCzGVRXs171iR5ibhtSOyxB8WP61ZsS3Zdtxm2v4CcVrHfoc3d1aV5FawR6pWBIN/CxX8k2qDJd+Rm/PbZZbQ1GcK3OeV72dzgIimwD0fDm2iTWU7lCPHxtFL6WjxloH3bzEtmqkCEVtxEkMSs7w6ybzykLU5CEyaDq7p5Qfuaa7Babz/hZT48YaXWfJiDK9/QD+qd2E4+yRPV6jcVG/eb3PkvOzGpUeXmMwiYqW6IlLdDSffaa8VcGVaY9j2qfVb2fcab3u5kvfuNbuwqKLPUgZPfE9mnNHb/8qzRNn51+I6v6wGUeSYkBUf7VYNL1BtXddz+nkuM8fHaKrGNRjZdS2vP16ffdz3KFwGUU1NcsD6YO8Tizik8y3E6qP/mTPRFNS5Tf08weF5ehZjFyS/2sUMk2irJHV2VQZW3Po9nvcBAU2QaioS1Lyo2dt92WO0Ntu4xt/Vt2I7ZhzpqR+F5MyZtFYtbrcl7XxxS+qVxhosfvCwl0+AShxBizqLvqob/OokYzjN41AvsC4Eac45LiG8qtr29ClVVTvjFMK0MqCY+0QEtzXrrROjkfVb7n0ex3OAiKbAPR0JalQEy+FArtNbb1b1leNDcBYJJ9oV/JaoYRFfelz/uCJ6lCyuqy8o4njcnZfZt7rMZ2IrkCV/N8K1fivxFL1+Gq5myjvk/gm5xMrjHZ9B1n3nPmjKl0NZhxLMjzDGXjuXx8sm2hPIZ5PJva4x1uyzTjhwNMsusC6RV9i6CLy1hoft3hdkEBfefX4R8xO6X3XORUzvYIlpArmU8AfwWcBNxNttrLLorE06V3RLT9BXCM9f0L6Lrf5h204aaQtu/R3Jvy0FQintJ9XnStLEnoZeg5fD9HWwnqX+V6/AnrlwAPAt+KrnuGQFcPOml5CVhPZVr2K4B3AZfijunYWAe6vrmNEXQFb/tZzSOe2n0CnbZ7kXCXL6Arh2d55lmT9ZdoRJ30VqKlEq7erV12FL7kZj4bRCt2FM0orJS/ZU1XkKTP9q0KzWowbXXurorTaE4yeJaNo5Xjt0hpNVSSB4t0jyZDqkRHbW6UlWqTfnVx5G6bXRXq242Zcp5ZYmTsxHxmp6g9r9as+TdP/27gnBSrUelB5ac/yUicbkSufMb1TRFejxZUT7UPRN1atZld8ydlq75VU7GvOXEUWVUGaczZ92IuF86zs4oaJpXXAOkTQuX7iMcBmPuwmY/9uVo12GVKVrOtSTjPPN+yoDYBfKaT9DnsM3ybAEfXa82nsnNjTrQNRNOXxnyz2FQmVd7aH/nSyCQ939a2IChqH4i6tWprRTTL66laQdb48cur16308y+nT/C50Sbp+31G0jwGyEJ0bdk4qj1ifOdJ+nopy63EGF1G5BOiyfci1fOYzaDaF8VC7KSgFqeuuLO4ktrn+JI4xueAu+PJbviX+v9ChmeZJLDdeAt9vLwYaJ8WbBRthBLVaycbXT4V8hcgbR5KyCPnK2dp9MXvARbz5S+/EH3+DPERXAR8DVnffx1lXXmSnSMN+6Nrn0Fcl97DggXuqEO5vOvjwJeIl5R9Ar9O3FcMdz+wLro/G7PRNgAZe/f2CudAiSLfZCXvYDfPJxbe3Y+289g8xoY0ltuA1700abhvz/7oc5HKObESbR95k3O++0w7gD8mPp/sfuxxvZN4mdW+iPYVFcdfdNE7qNYe1O5ouZSrZ2uHHQVUVyui3VVjzaHPVxBHriiWjT5fIRu7IprP3pHXpdHQFo+gldUSaStw324qTS2Vf1fxwANPC2M0qTZxnpB6w11RZ70f99rSOSbRni8XlaQG8qmc8niY+ehJcqseFI5vvRtsNe9w2FG0AFl9I1qBavx6mgd75N6FXgHbq+x7kFfRPhjPIVPk3kYnZe8bdyejyD8y9kr0dvROJWkGFInv7WzMRu+mJEjn2it2367Ct0Mq8Oyzc9H3bGOIP+FtDMWu1Qf8FFiDHuMC8HvEvY0U8Ab+sZRm4yr8b4/tCWbvvM4gPh6DxHd2BrOQ9/hFoZ8kTKI9qmy0x/68ngiCooFohhqpWrSzICuP3DziL20vcSbhUyGA/OIrtEulYVwSs7qZfCMjMbDb0czINwNKxAWUjSH0GGQ9t49KwXJX1IcNSQmqBdzf/M1CNN3ulZ4UrtURXe9TwEtRuwM4QriH3yd5LJ8AlgGXWMfZb4920j1woBu4krgaaBx4m0BjT0TfIeICswMtXNy5UxL6SUIn0CVct5Sjj/ZHEBSHMdpZkGmUSH9p01ZvUh8jwO8AP6fMKFzRKdk5klAkLpDG0cxIsq+Af9VvoxT9taNyzLlGuBlGOAH8hEpbhSsAr6NSt18WcIcOdaEZqELbDcwu4IXo77BAqxEYfcCRnvMfpzL+xb4Pswv7Ftq+cL7Tf3mX9r73/UfgE8R3hvOA/4EWILbGpBf4JPB99K7GRg/wbeK7UmnM7rA+j0TN3ouXj+/rm6Cd9uf1RMv1ZvVs7WKjqDft7dBaQ59rs3BdJ8v64KyRxbq+gPmcXgui3PK6shpXT61L10kLpT59Ud3Gw+kKVU5g53o+JUUVG/pMnIHkVZU1orug4BsqW0JAX0S4FCOTFBeRXno0Gz0mAj+v7STpWUueZjPX64lWE95GA9HyFujzNfvF9LuLJtNnM02J+aQJC6lYkct0k/NJ6TToWdJC2O69UvCYzdh8QXlfcei7XskC5TzP9zadPrdiX8tq6Dblat1rDynt4joqnCMJgSw0mb6k8rj1S60xnd/hpN8qc0YEBLQljB0BtIroCbT6pET2Lb7po5+4wbUD7QL5HU9/tv3B6PCvpZymA7St5LJECrq7FSMjReEavnsqoNUerqplPDrWuIm6qrW5aPdPm77Pe6j6B7TKStHXN8nIyAhaHWZg37sLhVbDGPom0OofowK7PLo3n6HbqKxszI76mxV99rEo+9puHxKGgfdH/z9I5f1ksSmYtDIlZqJaKQ3BRhEwDVGLdaVE3BgK2r5QdL4z+nTJo8bFGHBs4hHj4x3IDMnHhIrIXju9Vj9L0MZUs/gDOe+V9N1sNEPWubJ0LiWAP6esuy+Sfu9XA+9Es5OOqD/jaHAF5VgE19Bt06TQzHxYOMa+N4MR9HNZRaWd5hBakLrHd6E93B4nv8+fL17l8EEQFAEBgF65lqzPNnN4EFm42JiF3hVIHlYDwDB/+qd7iBt1DSO1mZD5bYD4Sl6hmd7FlFf7fciCwAezGq90hZ2cNDsQ26NsAL9DgVn5345Oqugy+Qn0jmgOWkgYpi8ZxQfRiQAllqTvq6dnkjJz/yDayF4ZdKn/Hg/8aXSPA8SFQR6fP5877hKSve1mFoKgCDjMUCTuMqrQ6hYpM61hDlC5Ch0X+v4V5RWuiR24G63aGOdznzuJykheKRr7HuDf0Z46W4mrXjqi/r4MXE/6at+3Gv9t0gXLGNqjyOfxZB8HcYHyJuIxBh1otuM+g07gn9BxGfJ1rr12DzJzNzvMFyjvNNcDJwL/STjePidtV1okPsazkT2mZi6CoAg4zHAmsq//XdbnInHmMIz29V8S/R0Ufi9Sjgn4fXTA4GXoVfebGB3tQgsCI4SMO6mNXjQjmkfyLqYD+DPkQEHTRtHxIFdSKeQ+CPyIsgrm9eh4lxaju78fOS2Jfdw24BYqmbxtI7Exgk6nIql//mdEW1xYnHvu6+RTOfqEgeuim4QScgzJPLLF8cwMBEERcBihgF5p2gxRoRlckfILX8JfQ+EpYA9lY6v9+5lUxgR8QOinFx3NWw+MondCNsO9EvjdqJ2Ajge5m7iqpYCOI3kXcA3xfEvuLsuu2WDbAwyTXwJ82kOny/TfhFYzdQDfiGgwK/4C2t7hPqO7OPlkn6DKg7z2Bjuu4g3i9zLzorAlBK+ngMMIRTRztVe5Q2gGN4xm4sZT53L0anEMLQTMinclekegPYXKKpTr0Lp62zPqzzx0uK+dsWP0InvwSKt9089dUSuS7JFje46ZexiNrnkd8aJOQ2j1irGVzKOcoLBofVeKjn/JQ7vL8M13R0b/fwQtgMy4F4k/ozeie/yi596yQvJeM4kXk3YpxivtDKrzmJr+CIIi4DBCifgK33XHNIxDclmVXEU70QxkOXFV0Wj0u3vNR4CllIXQdejdygA6f1Kf08ek07cRULaB1ufWWyTO1F1mqfNS9fX9L0ZG3ohougvt4qqi4w6hx8kwdBtLhHuUMBTdi53d1ainNuLPu9VFZYR6kXQ3Vem4InEhZHYEaeqs/Wib0nVoD65RNPucmVHYLlqiepo/fz6bN2/mxRdfZPPmzRx11FHicePj42zdupWtW7fy4IMPNpnKgJkHNz3DMPEkeG5iPVvHXSRuuxhBe/zcjGxvuI243v5i9Kv3WfQK/W7KxljXGL4KHRORNw+VUbH8I/B89Hc32stKSia4jYcffoZ4MkZTZtZ2ea1FJ+9jOSZt9/noZzRC2dbSBZzPpk3zqVQbrUa2NfjUSyVqK0+6Ei1URyjvxNorS1oj0fTowM9+9rPqhhtuUIC64YYb1F/91V+Jxw0MDDQt8rAdWqCvWfQlRWknpYj2pfZeouTKboeUjjJ+w/nNjhb2Ve+TU0RkS1+dlO7bnxa7PH5JadelKOaCiqdWscfBLkGaXgnQ91x6esaFvu0I/UL0LJKeabXlSbNVG5zO70jbpRlftmwZ99xzDwD33HMPF198cSvICDhsYbtT5gm+8iVo34bsGWMC2iTPH9Cqi5sS6NvvfFciXqxHQhG/2+wY2rNomMrEffa1SvhVSdIKfD/lnZBxozUG7w6rXUHZznEzssvtGHCuQH8nY2MuuzK2Djv9/LeJqwDtXaIUQ5HFC6oo0ORP2Z7dq2p6oCWC4thjj+WVV14B4JVXXuHYY+WI1lmzZrFlyxZ++MMfsmzZsmaSGHDY4H60quVaKr1vko53Gc1+tBpiGNkzZgjNZNzvO4CPks5QCmiBktVbZ4C4V5bBLOBjSOoTnca7PzrOCMQxKheXvcQzvEJ5XP5fdODbR4h7UtmpRz6DzuDrMt8eENOam6BCH0z6+XnCcVKFPCOIs3pBlQSa4kIzrh6bGXEWJlSy7njsscc47rjjYt/ffPPN3HPPPcyfP3/qu1//+tccffTRsWMXLFjA3r17Ofnkk/n+97/P+eefz7/9278lXnffvn3s3r1b/G3x4sU8//zzOe+keQj01YZq6Nu0aT7r1hXp7laMj3ewdm2JpUsPVNVHV5didFSvnsfHy2uwvr4J/uqvdvKxj70Nl4nNnj3BF7/4Aqef7tpK7L5PZmSkMvK6r2+Chx9+hvnzx4Xji0BHdE4ZnZ2Kri4qVuamnyefnMenP/1WOjsnpsbhuONGWL16cYzmnp4JvvGNn3HoUBcLFozGaAAtdC666B2MjNi1GhRr1uzm/e/fb9EJIyOd9PZO0tHB1Pg/+uh8brtNP5ehoc4oatz1oEr+PGvWBEr5n6lEo29cgQqapLly4EA3y5a9k6Gh9OfUKqS9I2effbb3t6brybZv366OO+44BajjjjtObd++PfWcr33ta2r58uUN08G1Qwv0NZu+bHrn/H3IpTyXLfulSs4Em6Vv015XcirwpGyrQ0qnAHczzS73jMNHBXrN/Q2pynThkv1Eyqbrs0HYGWdtG5Jkc1AKxpwxltLPL0l5lpItJimTrLGB+PrtV3PnjuXor73ekbazUTz00EOsWrUKgFWrVokeTUcddRS9vXqrd8wxx/Cbv/mb/OxnP2sqnQEzHUWy653z9GFHcS/EqHZuueXfSc5BlKVvgzeh4wps9UaReIZWG5PEK+bNBe5F1uu7aTYMetEqLJN25Mto11FX1bKNuPppAj0GbmqPkYg2owr6Pto992zPPU2iVYVmjFcRtx3ZBZMklMjuBZVWYEn3pxM/Zulv+qHpUu3oo49Wjz/+uHrxxRfVY489pubPn68AddZZZ6m77rpLAerd7363evrpp9W2bdvU008/rS6//PKGSsx2aIG+ZtOXZ0fh8zrK0odb1CarB1PaDsG9XkHFa0u4XkJpfbkrcre/SaW9tZJ2LcsteqTaH6ZJOw13Z2B2L+51XlOy91VWzzBz/BqV7gWVfZ7o4lTVeFW1/h0JhYuyDUTLW6CvFfRlcZd0ixa5x9yu4m6gKM1Ibpo6Vxcuyss4DH1SwR2baRmmKal7JlWym64kUEzxJElQJQkcMwbDEe2G/tc9dL1ujekSzzGfF763GXVeASE90zUJ52dXUek5WA09rX9H2k71FBDQPkhLOe1LM23XnF5N3A3UpA9fN3WuNprmCViz8zH9Pn5V0Gy0Kgt08N6VVLq/3oyOHs+ahtwkSfTV9JbScti/daC9lEyU+0Lgc55rfY704MHvAVfS2ztJ3KU3yWvJ56YqPdNbEq5fIl+gXvtXo8+LICgCAhJf7CJxO8E4umJbIeF3U4fBZc7GRVSCzdhsBvgT4Bj86b6HqLQ93I2OFj8fzYQ/QzxmZCRq5f/nzh0nbjdJY3ZDlKOoXUxSdod91HP+o9Y1thEfy9Ho+7v5P//naeueTPyDT4gnCZCicJ0k25QvfmbmCII0BEEREJCIEvHV5Dy0INiNXqlLGWJ9mU7nRee4cBnbRuIM0CSmk/ouUSloJOFn755OjFr5/w0bXqRyde/Ltuvitz00dVJedY8jCwHbbdQO3LNTmOh70C6maSlVxtBj5AqQjcCi6JgS+VN55Cl2NPMQBEVAQCLs1aRdt8FEBOuEepWrzWuIZ2M16IjOsdUh0srYZWRmxfsr4JPEV7dLyBboZQuQyv91LIdbilXy6Bp2rv0jdAZYOz/TCJWr7jOFe5ogzpwNQ/4d0hlySejTjLtLt8kltYLqdwgzT6WUFSF7bECACDv7qMkk+3voncSR1nE6oV45/XYJzUgG0LuAScqJ9exzilSujJPcWqFc7+KfKDPBz1IuuLSb/Omz01Aizohnod1b/4XKzKx2Km7QY2JXDLyT+M7k6x769nu+l46T0sH7UqrMIjk7cIAPYUcREBCDqwZajWYoTxLfKRiVhbvaNCtjyQjtqjmkqnujVK54r0OrgSQDbJG4oMkSD5KWk8ikJrHVTR3Ap/Az14NUCgmQ1XMd6Op/teZD8qVU8dlzkrIDB/gQBEVAQAUkNZAJKPsJegXvqixAZrimhoFWc8jGYp8d4GoqGaBk6DVMTxI0aTr3rDmOpKA5SQjZgXJZcxwlGfbzwGePkew5MycArpkIgiIgoAJF4gzZtklcQWVEcAfpDFeveuPGYt/1Biivyg0DLCHr4weQBc11+FfKsreQTgroooR/F2X3t5FyUj6TzdUIzm3IqjXb2N0I2OVbD09vpXohCIqAgAqUSK7WNoZmhk9Fn5NiLGxIxuJCdJ57vW7kVN6SAXYefkHjQ1E4Z4y9e6X7lq67zjnG5/ll7BX70Womk0FXMnY3Coe3t1K9EARFQEAFJC8nG/Zqukj1uaLs3EFdlGMakla9EtMrkU3Q2JDO6WHBAl9eKXPd/xF9/nPyp9C+HzgB+N2onUjzmHawRdSKICgCAmIwjPF8dJSzT3VRorrSmq7qpw/tKnoJ6atel+lV4+opn5OeCvtm5N1TUqCce93HqUzWV0ALviXMpEI/Mw1BUAQEiDAM+W78qotq/fGLyDuRgxnOlZCkXvF5NuVVyfhoLpIWKOfHSuAlYHPUXmKmFPqZaQhxFAEBqUjy66/GH79E+k7EjuNI69N37Er0zmU0ut7lxAVdVsGURnPecTC7qj7ruz60EbzW+I+AeiPsKAICakZeHXjaTiSr62rSsZJn00bKaSxs6F2H7PWUlWZzTNZxKKKDEV3YRvCAdkEQFAEBLYFP9ZOWrdZG0rFF4oZ4O42FQVnQXHTRO0gWSvX0ICoRFBrTB0FQBAS0DNIKvEi6J5WxO5yRcOwA5XQeBnYaiwKuoMmWBr1eHkT70TmxXGEmGcEDWo0g0gMCWgKfXaFEsi3AtTt0eY4totVDc4Vr24JnlEqB4uahaiTujv7eiY7S7iQExLUnwo4iIKDpSLJBJNkCJFUTyMFwJfyFiowwKVGde289YWpnZMkWG9AqBEERENBUZLFB+GwBReS038uIB8OdT1ngmOR4h6gUPJVCqa9vgtas6ENAXLsjCIqAgKaiSLZobol5lpB3AHuQg+FMosAxdAbbdcRX7WWh9PDDz1D/FX1ahtqA6YAgKAICmooS1at78uR7ssuxmkR9vrrQWiilR2bnRR4334B2RhAUAQFNRa31l7Pme5LKsWbNQ1UP5HHzDWh3BEERENB01BqPkCXfk1SOtZmG6iLVJ0wMaDcE99iAgJYgT/qMLJBSaJhyrHaZ0GYZjEvkU7HlSVkS0GyEHUVAwIyBrxxrK2ox5FGxBVtGuyPsKAICZjTqvXPJgyyJAm1bhokL+SohMWB7IQiKgICABiJNUBVpbXR4QBYE1VNAQEALUaL10eEBaQiCIiAgoIWo1V04oBkIqqeAgIAWo5riTwHNRBAUAQEBbYBWGt0D0tAS1dMll1zCs88+y8TEBGeddZb3uKVLl7J9+3Z27NjBDTfc0EQKAwICAgIMWiIonn32Wd7//vfzgx/8wHtMZ2cnGzZs4MILL+S0007jD//wD1m8eHETqQwICAgIgBYJiu1o2zWEAAAJAUlEQVTbt/Piiy8mHnPOOeewc+dOdu3axdjYGPfddx/Lli1rEoUBAYcbCjz33BxCLqYACW1rozjhhBPYs2fP1OeXXnqJc889N/W8hQsXsmXLFvG3xYsXe39rBwT6akOgrzps2jSfdeuKXHttJ319r7B2bYmlSw+0mqwY2nX8bLQ7jdXS1zBB8dhjj3HcccfFvr/55pt56KGHGnVZdu/ezdlnny3+tmXLFu9v7YBAX20I9FWDAjptRhcjIwBd3HLL8dxyy3m0m3G5PcevEu1OYxJ9SQKkYYLiP//n/1zT+S+//DInnXTS1OcTTzyRl19+uVayAgICKlAkREYHpKFtA+62bNnCKaecQrFYpKenh5UrVzZ0JxIQcHiiRIiMDkhDSwTFxRdfzJ49e3j3u9/Nd7/7XTZt2gTA8ccfz3e/+10AJiYmuPrqq3n00Ud5/vnneeCBB/jZz37WCnIDAmYwypHRc+eOEyKjAyS0xJj9ne98h+985zux73/xi1/w3ve+d+rzI488wiOPPNJM0gICDkPoyOgNG/6JD37wPQQhEeCibVVPAQEBzcR+Tj/9EEFIBEgIgiIgICAgIBFBUAQEBAQEJCIIioCAgICARARBERAQEBCQiCAoAgICAgIS0QGoVhNRT+zbt4/du3e3moyAgICAaYWFCxfy5je/WfxtxgmKgICAgID6IqieAgICAgISEQRFQEBAQEAigqAICAgICEhEEBQBAQEBAYkIgiIgICAgIBFBUAQEBAQEJGJGC4pLLrmEZ599lomJCc466yzvcbt27eLpp59m69atTa13m5W+pUuXsn37dnbs2MENN9zQNPrmz5/P5s2befHFF9m8eTNHHXWUeNz4+Dhbt25l69atPPjggw2nK208ent7ue+++9ixYwc/+tGPWLhwYcNpykPfqlWr2Ldv39SYfehDH2oqfV/5ylf45S9/yTPPPOM95vbbb2fHjh389Kc/5cwzz2widen0vec97+HgwYNT47d27dqm0XbiiSfy/e9/n+eee45nn32Wa6+9VjyuVeOXhb5qx0/N1Hbqqaeqt73tbeof/uEf1FlnneU9bteuXeqYY45pS/o6O///9u4opKk3DAP4g7Vctsga4URjnYuK6mpUyrKIiIJd1ISCuilBKIkIuhPqKoKwbroo6qJuFpSjEmuSRYsVCNlYtLM5mtrIi7mxigKxQJR6u5D82791PE13zqrnBwPn+Th7eM9hL9+3T1cmqVRKFEURi8UiqqrK2rVrDcl37tw5aW1tFQDS2toqbW1teceNjo4aVjM99Th69KhcuXJFAMj+/fvF7/eXVL6mpia5ePGi4ffb98fWrVvF5XJJX19f3uMej0e6u7sFgNTX18vz589LKt+2bdukq6vLlNo5HA5xuVwCQGw2mwwMDPx0fc2sn558hdTvr55R9Pf3Y3Bw0OwYv6QnX11dHVKpFIaGhjAxMQG/3w+v12tIPq/XC5/PBwDw+XxobGw05HW16KnH9Nx37tzBjh07Siqf2Xp6evDx48dfHvd6vbh+/ToAIBwOo7KyEg6Hw6h4M+YzUy6XQzQaBQB8+vQJyWQSNTU1P4wxs3568hXir24UeokIHj16hBcvXuDw4cNmx/lBTU0N0un01PPh4eE5ufB6VFVVIZfLAZi8AauqqvKOs1qtiEQi6O3tLfqbop56TB/z5csXjIyMwG63FzXX7+QDgL179yIWi+H27duora01JJteZt5zerndbqiqiu7ubqxbt86UDE6nEy6XC+Fw+Iffl0r9fpUP+P36mfJVqHMpGAzm7danTp1CIBDQdY4tW7Ygm81i+fLlCAaD6O/vR09PT8nkKyatfP8nInnP4XQ6kc1moSgKQqEQ+vr68ObNmznP+rfo6upCe3s7xsfHceTIEfh8PkNnPX+6ly9fwul04vPnz/B4PLh79y5Wr15taIZFixaho6MDJ06cwOjoqKGvrYdWvkLq98c3ip07d876HNlsFgDw/v17dHZ2oq6ubs4axWzzZTIZrFixYup5bW0tMpnMbGNN0cr39u1bOBwO5HI5OBwOvHv3Lu+47/UbGhrC06dP4XK5itYo9NTj+5hMJoN58+ZhyZIl+PDhQ1HyFJJv+rLKtWvXcP78eUOy6VXse262pr/xPXjwAJcvX4bdbjfsGs+fPx8dHR24ceMGOjs7fzpudv1myldI/f75paeKigrYbLapn3ft2oVEImFyqv9EIhGsWrUKK1euhMViwYEDBwybiQQCATQ1NQGY3KmTb0dTZWUlFixYAACw2+1oaGjAq1evipZJTz2m5963bx9CoVDR8hSSb/oMbs+ePUgmk4bl0yMQCODQoUMAgPr6eoyMjEwtQZaC6UugmzZtQllZmWFNApjclZVMJnHhwoW8x82u30z5Cq2fKbsHjHg0NjZKOp2WsbExyeVy8vDhQwEg1dXVcv/+fQEgiqKIqqqiqqokEgk5efJkSeUDJndRDAwMSCqVMjTfsmXL5PHjxzI4OCjBYFCWLl0qAGTDhg1y9epVASBut1vi8bioqirxeFyam5uLnitfPU6fPi27d+8WAFJeXi63bt2S169fSzgcFkVRDL3vZsp39uxZSSQSoqqqhEIhWbNmjaH5bt68KdlsVsbHxyWdTktzc7O0tLRIS0vL1JhLly5JKpWSeDyuuWPQjHzHjh2bql9vb6+43W7DsjU0NIiISCwWk2g0KtFoVDweT8nUT0++QurHfzNORESa/vmlJyIi0sZGQUREmtgoiIhIExsFERFpYqMgIiJNbBRERKSJjYKIiDSxURAV2caNGxGLxVBeXo6KigokEgmsX7/e7FhEuvEP7ogMcObMGVitVixcuBDDw8Noa2szOxKRbmwURAawWCyIRCIYGxvD5s2b8fXrV7MjEenGpSciA9jtdthsNixevBhWq9XsOES/hTMKIgPcu3cPfr8fiqKguroax48fNzsSkW5//PdREJW6gwcPYmJiAu3t7SgrK8OzZ8+wfft2PHnyxOxoRLpwRkFERJr4GQUREWlioyAiIk1sFEREpImNgoiINLFREBGRJjYKIiLSxEZBRESavgEb6+0te1cqwgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1V3Z1HpokA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return (1/(1+np.exp(-x)))\n",
        "def relu(x):\n",
        "    return np.maximum(0,x)\n",
        "def tang(x):\n",
        "  return np.tanh(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pR71Fydolfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dims = [X_tr.shape[1],4,6,6,5,1]\n",
        "act_fn = [\"relu\",\"tang\",\"relu\",\"tang\",\"sigmoid\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqvuIXEDo2Ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters(layer_dims,activation_fn):\n",
        "  parameters = {}\n",
        "  relu_init = 2\n",
        "  tang_init = 1\n",
        "  for i in range(1,len(layer_dims)):\n",
        "    if activation_fn[i-1] is \"relu\":\n",
        "      initi = relu_init\n",
        "    if activation_fn[i-1] is \"tang\":\n",
        "      initi = tang_init\n",
        "    parameters[\"W\"+str(i)] = np.random.randn(layer_dims[i],layer_dims[i-1])*np.sqrt(initi/layer_dims[i-1])\n",
        "    parameters[\"b\"+str(i)] = np.random.randn(layer_dims[i],1)*0.01\n",
        "  return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2szTq5wmo4OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forw_prop(X,parameters,activation_fn):\n",
        "  outputs = {}\n",
        "  activations = {}\n",
        "  A_prev = X.T\n",
        "  for i in range(1,int(len(layer_dims))-1):\n",
        "    if activation_fn[i-1] is \"relu\":\n",
        "      activ = relu\n",
        "    if activation_fn[i-1] is \"tang\":\n",
        "      activ = tang\n",
        "    if activation_fn[i-1] is \"sigmoid\":\n",
        "      activ = sigmoid\n",
        "    outputs[\"Z\" + str(i)] = np.dot(parameters[\"W\" + str(i)],A_prev) + parameters[\"b\"+str(i)]\n",
        "    activations[\"A\" + str(i)] = activ(outputs[\"Z\" + str(i)])\n",
        "    A_prev = activations[\"A\" + str(i)]\n",
        "  A_prev = activations[\"A\" + str(len(layer_dims)-2)]\n",
        "  if activation_fn[len(layer_dims)-2] is \"relu\":\n",
        "    activ = relu\n",
        "  if activation_fn[len(layer_dims)-2] is \"tang\":\n",
        "    activ = tang\n",
        "  if activation_fn[len(layer_dims)-2] is \"sigmoid\":\n",
        "    activ = sigmoid\n",
        "  outputs[\"Z\" + str(len(layer_dims)-1)] = np.dot(parameters[\"W\" + str(len(layer_dims)-1)],A_prev) + parameters[\"b\"+str(len(layer_dims)-1)]\n",
        "  activations[\"A\" + str(len(layer_dims)-1)] = activ(outputs[\"Z\" + str(len(layer_dims)-1)])\n",
        "  activations[\"A0\"] = X.T\n",
        "  return outputs,activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgTZNoBko6H7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost_func(A,y,m_ex):\n",
        "  cost = ((-1/m_ex)*(np.sum(np.sum((y*np.log(A)) + ((1-y)*np.log(1-A))))))\n",
        "  return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMhW4VMNo-Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_backward(z):\n",
        "  grad_back = np.exp(-z)/np.square(1+np.exp(-z))\n",
        "  return grad_back\n",
        "def relu_backward(x):\n",
        "  x[x<=0] = 0\n",
        "  x[x>0] = 1\n",
        "  return x\n",
        "def tang_backward(x):\n",
        "  return (1 - np.square(np.tanh(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5plu3-apArP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(A):\n",
        "  predictions = np.zeros((A.shape))\n",
        "  for i in range(0,A.shape[0]):\n",
        "    for j in range(0,A.shape[1]):\n",
        "      if A[i,j]>0.5:\n",
        "        predictions[i,j]=1\n",
        "      else:\n",
        "        predictions[i,j]=0\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSfxmf6TpFGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(X,Y,m_ex,num_iterations,alpha,parameters,activation_fn,print_cost,callback=None):\n",
        "  costs = []\n",
        "  p = 0\n",
        "  for i in range(1,num_iterations+1):\n",
        "    grads = {}\n",
        "    outputs,activations = forw_prop(X,parameters,activation_fn)\n",
        "    cost = cost_func(activations[\"A\" + str(len(layer_dims)-1)],Y,m_ex)\n",
        "    costs.append(cost)\n",
        "    predictions = predict(activations[\"A\" + str(len(layer_dims)-1)])\n",
        "    if activation_fn[len(layer_dims)-2] is \"relu\":\n",
        "      backward = relu_backward\n",
        "    if activation_fn[len(layer_dims)-2] is \"tang\":\n",
        "      backward = tang_backward\n",
        "    if activation_fn[len(layer_dims)-2] is \"sigmoid\":\n",
        "      backward = sigmoid_backward\n",
        "    \n",
        "    grads[\"dA\" + str(len(layer_dims)-1)] = (1/m_ex)*(((1-Y)/(1-activations[\"A\" + str(len(layer_dims)-1)])) - (Y/activations[\"A\" + str(len(layer_dims)-1)]))\n",
        "    grads[\"dZ\" + str(len(layer_dims)-1)] = grads[\"dA\" + str(len(layer_dims)-1)]*backward(outputs[\"Z\" + str(len(layer_dims)-1)])\n",
        "    grads[\"dW\" + str(len(layer_dims)-1)] = np.dot(grads[\"dZ\" + str(len(layer_dims)-1)],activations[\"A\" + str(len(layer_dims)-2)].T)\n",
        "    grads[\"db\" + str(len(layer_dims)-1)] = np.sum(grads[\"dZ\" + str(len(layer_dims)-1)],axis=1,keepdims=True)\n",
        "    for j in reversed(range(1,len(layer_dims)-1)):\n",
        "      if activation_fn[j-1] is \"relu\":\n",
        "        backward = relu_backward\n",
        "      if activation_fn[j-1] is \"tang\":\n",
        "        backward = tang_backward\n",
        "      if activation_fn[j-1] is \"sigmoid\":\n",
        "        backward = sigmoid_backward\n",
        "      grads[\"dA\" + str(j)] = np.dot(parameters[\"W\" + str(j+1)].T,grads[\"dZ\" + str(j+1)])\n",
        "      grads[\"dZ\" + str(j)] = grads[\"dA\" + str(j)]*backward(outputs[\"Z\" + str(j)])\n",
        "      grads[\"dW\" + str(j)] = np.dot(grads[\"dZ\" + str(j)],activations[\"A\" + str(j-1)].T)\n",
        "      grads[\"db\" + str(j)] = np.sum(grads[\"dZ\" + str(j)],axis=1,keepdims=True)\n",
        "    for k in range(1,len(layer_dims)):\n",
        "      parameters[\"W\" + str(k)] -= (alpha*(grads[\"dW\" + str(k)]))\n",
        "      parameters[\"b\" + str(k)] -= (alpha*(grads[\"db\" + str(k)]))\n",
        "    if print_cost is True:\n",
        "      print(\"Cost after iteration \" + str(i) + \" is \" + str(costs[p]) + \" -------- \" + \"Training accuracy = \" + str(float(np.mean(predictions==Y,axis=1))*100))\n",
        "    p = p+1\n",
        "    if(i % 50 == 0):\n",
        "      if(callback is not None):\n",
        "                callback(i, parameters)\n",
        "  return costs, parameters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1DSgF-3pIVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prec_rec(A,y):\n",
        "  tp = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  for i in range(0,y.shape[1]):\n",
        "    if ((A[0,i]==1)and(y[0,i]==1)):\n",
        "      tp = tp+1\n",
        "    if ((A[0,i]==1)and(y[0,i]==0)):\n",
        "      fp = fp+1\n",
        "    if (A[0,i]==0)and(y[0,i]==1):\n",
        "      fn = fn+1\n",
        "  prec = tp/(tp+fp)\n",
        "  rec = tp/(tp+fn)\n",
        "  f1 = (2*prec*rec)/(prec+rec)\n",
        "  return prec,rec,f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzgIW2DZzJPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_val(X,y,params_tr,print_values):\n",
        "  out_cv,act_cv = forw_prop(X,params_tr,act_fn)\n",
        "  predictions_cv = predict(act_cv[\"A\" + str(len(layer_dims)-1)])\n",
        "  accu_cv = float(np.mean(predictions_cv==y,axis=1))*100\n",
        "  prec_cv,rec_cv,f1_cv = prec_rec(predictions_cv,y)\n",
        "  if print_values is True:\n",
        "    print(\"CROSS VAL RESULTS: \")\n",
        "    print(\"Cross val accuracy = \" + str(accu_cv))\n",
        "    print(\"Precision: \" + str(prec_cv))\n",
        "    print(\"Recall: \" + str(rec_cv))\n",
        "    print(\"F1 score: \" + str(f1_cv))\n",
        "    print('\\n')\n",
        "    print('\\n')\n",
        "  return accu_cv,prec_cv,rec_cv,f1_cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfWfeWBEzNiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(X,y,params_tr,print_values):\n",
        "  out_te,act_te = forw_prop(X,params_tr,act_fn)\n",
        "  predictions_te = predict(act_te[\"A\" + str(len(layer_dims)-1)])\n",
        "  accu_te = float(np.mean(predictions_te==y,axis=1))*100\n",
        "  prec_te,rec_te,f1_te = prec_rec(predictions_te,y)\n",
        "  if print_values is True:\n",
        "    print(\"TEST RESULTS: \")\n",
        "    print(\"Testing accuracy = \" + str(accu_te))\n",
        "    print(\"Precision: \" + str(prec_te))\n",
        "    print(\"Recall: \" + str(rec_te))\n",
        "    print(\"F1 score: \" + str(f1_te))\n",
        "    print('\\n')\n",
        "    print('\\n')\n",
        "  return accu_te,prec_te,rec_te,f1_te"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFHen-5-pKrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4fa6b98-b3cb-4c88-89f9-2311e2c8bb46"
      },
      "source": [
        "parameters_dat = initialize_parameters(layer_dims,act_fn)\n",
        "costs,parameters = fit(X_tr,y_tr,m_tr,10000,0.015,parameters_dat,act_fn,print_cost=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Cost after iteration 5002 is 0.0767301117607949 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5003 is 0.07672766318400517 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5004 is 0.07672521868429168 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5005 is 0.07672278074059301 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5006 is 0.07672034523505936 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5007 is 0.07671791249942433 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5008 is 0.07671548183358261 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5009 is 0.07671305314692148 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5010 is 0.07671062637511658 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5011 is 0.07670820147168844 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5012 is 0.07670577845699778 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5013 is 0.07670335735070062 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5014 is 0.0767009380306789 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5015 is 0.0766985204821611 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5016 is 0.07669610469329598 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5017 is 0.07669369065440194 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5018 is 0.07669127840811468 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5019 is 0.07668886800289101 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5020 is 0.07668645932605749 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5021 is 0.0766840523727566 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5022 is 0.07668164713868152 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5023 is 0.07667924361997142 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5024 is 0.07667684181312898 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5025 is 0.07667444171495441 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5026 is 0.07667204332249229 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5027 is 0.07666964663298867 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5028 is 0.07666725164385607 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5029 is 0.07666485835264501 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5030 is 0.07666246675702063 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5031 is 0.07666007685474341 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5032 is 0.07665768864365342 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5033 is 0.07665530212165747 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5034 is 0.07665291728671807 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5035 is 0.0766505341368447 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5036 is 0.07664815267227118 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5037 is 0.07664577289169863 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5038 is 0.07664339583723372 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5039 is 0.07664102026932447 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5040 is 0.0766386454560662 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5041 is 0.07663627234529871 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5042 is 0.07663390092512631 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5043 is 0.07663153139287854 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5044 is 0.07662916538582487 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5045 is 0.07662679885417853 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5046 is 0.07662443404228733 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5047 is 0.07662207092978125 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5048 is 0.07661971047391344 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5049 is 0.07661735228356628 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5050 is 0.0766149941463822 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5051 is 0.07661263773682148 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5052 is 0.07661028334109138 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5053 is 0.07660793268496147 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5054 is 0.07660558111906078 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5055 is 0.07660323128997713 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5056 is 0.0766008835761348 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5057 is 0.07659853954200292 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5058 is 0.07659619454293497 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5059 is 0.07659385128259764 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5060 is 0.07659151074767614 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5061 is 0.07658917277108206 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5062 is 0.07658683432462675 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5063 is 0.07658449761508733 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5064 is 0.07658216463545502 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5065 is 0.07657983227942222 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5066 is 0.07657750036608275 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5067 is 0.07657517057133566 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5068 is 0.07657284488122137 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5069 is 0.076570517786237 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5070 is 0.07656819244216097 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5071 is 0.07656587120944497 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5072 is 0.07656355003924088 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5073 is 0.07656122947317888 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5074 is 0.07655891196548983 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5075 is 0.0765565968395565 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5076 is 0.07655428107075794 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5077 is 0.0765519677405387 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5078 is 0.07654965817419493 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5079 is 0.0765473472107106 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5080 is 0.07654503838011642 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5081 is 0.07654273402398386 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5082 is 0.07654042786524758 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5083 is 0.07653812377912544 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5084 is 0.07653582436117166 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5085 is 0.07653352300122167 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5086 is 0.0765312238574578 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5087 is 0.07652892915197064 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5088 is 0.07652663258166845 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5089 is 0.0765243385485565 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5090 is 0.07652204835893744 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5091 is 0.07651975656730116 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5092 is 0.0765174677936503 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5093 is 0.076515181942534 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5094 is 0.07651289491750718 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5095 is 0.07651061153869068 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5096 is 0.07650832986205824 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5097 is 0.07650604759095185 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5098 is 0.07650376973265513 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5099 is 0.07650149207618696 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5100 is 0.07649921454593687 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5101 is 0.07649694232657134 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5102 is 0.07649466854329391 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5103 is 0.07649239636494967 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5104 is 0.07649012877448241 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5105 is 0.07648785898674769 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5106 is 0.0764855932538387 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5107 is 0.0764833287332859 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5108 is 0.07648106370147592 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5109 is 0.07647881129200206 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5110 is 0.0764765704726853 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5111 is 0.07647433238646222 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5112 is 0.07647209829121586 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5113 is 0.07646986292344689 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5114 is 0.0764676321036624 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5115 is 0.07646540224760981 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5116 is 0.07646317244950368 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5117 is 0.07646094796630855 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5118 is 0.07645872245895464 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5119 is 0.076456498273105 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5120 is 0.07645427929567962 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5121 is 0.07645205801170292 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5122 is 0.07644984060454958 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5123 is 0.07644762509278498 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5124 is 0.07644540887331919 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5125 is 0.07644319812995776 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5126 is 0.0764409859958811 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5127 is 0.07643877593476217 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5128 is 0.07643656965092087 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5129 is 0.07643436153901802 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5130 is 0.07643215889812391 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5131 is 0.07642995507820075 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5132 is 0.07642775351440449 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5133 is 0.07642555503002459 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5134 is 0.07642335497275357 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5135 is 0.07642116136499395 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5136 is 0.07641896438117873 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5137 is 0.07641677273653857 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5138 is 0.07641458045356027 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5139 is 0.07641239038881749 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5140 is 0.07641020280488169 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5141 is 0.07640801468702621 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5142 is 0.07640583146804333 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5143 is 0.07640364569899946 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5144 is 0.0764014666072023 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5145 is 0.07639928382559892 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5146 is 0.07639710737535836 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5147 is 0.07639492854607428 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5148 is 0.07639275414645144 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5149 is 0.07639057940614027 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5150 is 0.07638840735840524 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5151 is 0.0763862363964297 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5152 is 0.07638406692944441 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5153 is 0.07638189950681647 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5154 is 0.0763797327986046 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5155 is 0.07637756872434401 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5156 is 0.07637540491728019 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5157 is 0.07637324403335993 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5158 is 0.07637108324465881 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5159 is 0.0763689254162115 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5160 is 0.0763667725685586 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5161 is 0.07636462306837533 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5162 is 0.07636247512255549 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5163 is 0.07636032868632861 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5164 is 0.07635818509429167 -------- Training accuracy = 97.0\n",
            "Cost after iteration 5165 is 0.0763560434353464 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5166 is 0.07635390144432427 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5167 is 0.07635176097773486 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5168 is 0.07634962523687236 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5169 is 0.07634748808313976 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5170 is 0.07634535196586496 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5171 is 0.07634322043484172 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5172 is 0.07634108817925385 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5173 is 0.07633895640133169 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5174 is 0.07633683003198585 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5175 is 0.07633470158127163 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5176 is 0.0763325752554593 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5177 is 0.07633045265667637 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5178 is 0.07632832800921964 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5179 is 0.07632620844421964 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5180 is 0.07632408795753484 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5181 is 0.07632196917281359 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5182 is 0.07631985370307016 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5183 is 0.07631773623092351 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5184 is 0.07631562508768336 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5185 is 0.0763135108061407 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5186 is 0.07631140087991788 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5187 is 0.07630929112009019 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5188 is 0.07630718284973242 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5189 is 0.07630507716504586 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5190 is 0.07630297088771502 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5191 is 0.0763008689472001 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5192 is 0.07629876492794074 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5193 is 0.0762966664600245 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5194 is 0.07629456490415096 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5195 is 0.07629246969746076 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5196 is 0.07629037077401343 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5197 is 0.07628827865300224 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5198 is 0.07628618250315583 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5199 is 0.0762840933181704 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5200 is 0.07628200006252213 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5201 is 0.07627991368304879 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5202 is 0.07627782342830869 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5203 is 0.07627573974412023 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5204 is 0.07627365258806586 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5205 is 0.07627157148494922 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5206 is 0.0762694875089183 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5207 is 0.07626740889108866 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5208 is 0.07626532817159412 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5209 is 0.07626325195019663 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5210 is 0.07626117455794412 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5211 is 0.07625910064978729 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5212 is 0.07625702665071704 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5213 is 0.07625495497730818 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5214 is 0.07625288443339681 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5215 is 0.07625081492019489 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5216 is 0.07624874789008144 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5217 is 0.07624668046590996 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5218 is 0.07624461700539194 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5219 is 0.07624255160197047 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5220 is 0.07624049176440141 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5221 is 0.07623842853326515 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5222 is 0.07623636373699721 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5223 is 0.07623429806264004 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5224 is 0.07623223319493311 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5225 is 0.07623017072210636 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5226 is 0.07622811106425449 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5227 is 0.07622605033833497 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5228 is 0.07622399116797554 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5229 is 0.07622193548344962 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5230 is 0.0762198801685119 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5231 is 0.07621782508270447 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5232 is 0.07621577152686106 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5233 is 0.07621372192951283 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5234 is 0.07621167158447144 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5235 is 0.0762096220771878 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5236 is 0.07620757408389804 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5237 is 0.0762055300801572 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5238 is 0.07620348513985334 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5239 is 0.0762014411679703 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5240 is 0.07619939869862621 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5241 is 0.0761973599064352 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5242 is 0.07619532070040497 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5243 is 0.07619328222959951 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5244 is 0.07619124525219743 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5245 is 0.07618921135453023 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5246 is 0.07618717815048327 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5247 is 0.07618514515109032 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5248 is 0.07618311363726235 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5249 is 0.07618108435788393 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5250 is 0.07617905738471925 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5251 is 0.07617702982978762 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5252 is 0.07617500375336957 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5253 is 0.07617297915924359 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5254 is 0.07617095835095723 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5255 is 0.07616893738411484 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5256 is 0.07616691715983488 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5257 is 0.07616489838608138 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5258 is 0.07616288119964908 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5259 is 0.07616086736584612 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5260 is 0.07615885249796836 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5261 is 0.07615683908497009 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5262 is 0.07615482709319578 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5263 is 0.07615281701412704 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5264 is 0.07615083505647931 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5265 is 0.07614891348225197 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5266 is 0.07614700998851318 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5267 is 0.07614510510946991 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5268 is 0.07614320449350781 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5269 is 0.07614130717836481 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5270 is 0.07613941254251219 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5271 is 0.07613752018359965 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5272 is 0.07613562984033595 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5273 is 0.07613374134227409 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5274 is 0.0761318545775246 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5275 is 0.07612996947198906 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5276 is 0.07612808597599692 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5277 is 0.07612620398964184 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5278 is 0.07612432339315037 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5279 is 0.0761224442510198 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5280 is 0.07612056653776415 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5281 is 0.07611869033844777 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5282 is 0.07611681564520369 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5283 is 0.07611494245154886 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5284 is 0.07611307075194217 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5285 is 0.07611120054149524 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5286 is 0.07610933181578168 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5287 is 0.07610746457071042 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5288 is 0.0761055988269576 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5289 is 0.07610373458350399 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5290 is 0.07610187180976857 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5291 is 0.07610001050238598 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5292 is 0.07609815065809651 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5293 is 0.07609629227373206 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5294 is 0.07609443534620537 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5295 is 0.07609257987250209 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5296 is 0.07609072584967401 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5297 is 0.07608887327483425 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5298 is 0.0760870221451527 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5299 is 0.07608517245785255 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5300 is 0.07608332421020716 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5301 is 0.07608147739953736 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5302 is 0.07607963202320901 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5303 is 0.07607778807863089 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5304 is 0.07607594556325278 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5305 is 0.07607410447456366 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5306 is 0.07607226481008997 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5307 is 0.07607042656739431 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5308 is 0.0760685897440739 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5309 is 0.07606675433775931 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5310 is 0.07606492034611323 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5311 is 0.07606308776682927 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5312 is 0.076061256597631 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5313 is 0.07605942683627066 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5314 is 0.07605759848439697 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5315 is 0.07605577157583794 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5316 is 0.07605394606835893 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5317 is 0.0760521219598202 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5318 is 0.07605029924810633 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5319 is 0.0760484774749024 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5320 is 0.07604665067296933 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5321 is 0.07604482533127073 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5322 is 0.0760430014328918 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5323 is 0.0760411789660064 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5324 is 0.07603935792208837 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5325 is 0.07603753829475947 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5326 is 0.0760357200790463 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5327 is 0.07603390327090073 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5328 is 0.07603208786688931 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5329 is 0.07603027386399212 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5330 is 0.07602846125947153 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5331 is 0.07602665005078658 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5332 is 0.07602484023553671 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5333 is 0.07602303181142439 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5334 is 0.07602122477623018 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5335 is 0.0760194191277958 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5336 is 0.0760176148640126 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5337 is 0.07601581198281351 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5338 is 0.07601401048216704 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5339 is 0.07601221036007315 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5340 is 0.07601041161456012 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5341 is 0.07600861424368198 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5342 is 0.07600681824551653 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5343 is 0.0760050236181638 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5344 is 0.07600323035974466 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5345 is 0.07600143846839971 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5346 is 0.07599964794228818 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5347 is 0.07599785877958724 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5348 is 0.07599607097849093 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5349 is 0.07599428453720959 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5350 is 0.07599249945396928 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5351 is 0.0759907157270109 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5352 is 0.07598893335458996 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5353 is 0.0759871523349757 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5354 is 0.07598537266645086 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5355 is 0.07598363802929478 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5356 is 0.07598188899681549 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5357 is 0.07598011271773464 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5358 is 0.07597833803913105 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5359 is 0.07597656487063024 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5360 is 0.07597480060030283 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5361 is 0.07597310039621814 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5362 is 0.07597133010744961 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5363 is 0.07596956163191107 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5364 is 0.07596779480728802 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5365 is 0.0759660295267978 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5366 is 0.07596434345512951 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5367 is 0.07596258508903292 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5368 is 0.0759608226430081 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5369 is 0.0759590620393862 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5370 is 0.07595730990582572 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5371 is 0.07595563199612781 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5372 is 0.07595387405938978 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5373 is 0.07595211814772644 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5374 is 0.07595036403178144 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5375 is 0.07594865259115241 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5376 is 0.07594694996370695 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5377 is 0.07594519839513993 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5378 is 0.07594344883554746 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5379 is 0.07594170190284288 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5380 is 0.07594004798595189 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5381 is 0.07593830099273764 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5382 is 0.07593655612076122 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5383 is 0.07593481311352418 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5384 is 0.07593314012197289 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5385 is 0.07593142742552289 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5386 is 0.07592968683544762 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5387 is 0.07592794830175968 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5388 is 0.07592626364733428 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5389 is 0.0759245751831093 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5390 is 0.07592283909893016 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5391 is 0.07592110516989241 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5392 is 0.07591942188791712 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5393 is 0.07591774429382606 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5394 is 0.07591601281366804 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5395 is 0.07591428354042477 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5396 is 0.07591261295239494 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5397 is 0.07591093465671722 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5398 is 0.07590920781048142 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5399 is 0.0759074832009643 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5400 is 0.07590583554272494 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5401 is 0.07590414609996925 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5402 is 0.07590242389373933 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5403 is 0.07590070394371935 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5404 is 0.07589908867784699 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5405 is 0.07589737842796063 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5406 is 0.07589566084003559 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5407 is 0.0758939755969248 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5408 is 0.07589234428087963 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5409 is 0.0758906293479265 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5410 is 0.07588891688192945 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5411 is 0.07588728669758346 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5412 is 0.07588561178161558 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5413 is 0.07588390188313178 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5414 is 0.07588221666678353 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5415 is 0.07588060551797399 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5416 is 0.07587889831544073 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5417 is 0.07587719365341855 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5418 is 0.07587558156215926 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5419 is 0.07587390834031267 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5420 is 0.07587220609516662 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5421 is 0.07587055139305139 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5422 is 0.07586892912847656 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5423 is 0.07586722956649299 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5424 is 0.07586554107471678 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5425 is 0.07586396084073924 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5426 is 0.07586226413011543 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5427 is 0.07586057009692429 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5428 is 0.07585898036793229 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5429 is 0.07585731217655133 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5430 is 0.0758556205819111 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5431 is 0.07585400587127153 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5432 is 0.07585237067528536 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5433 is 0.07585068176978603 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5434 is 0.07584904992770426 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5435 is 0.07584743980842297 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5436 is 0.07584575374673398 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5437 is 0.07584411151266995 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5438 is 0.07584251968292345 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5439 is 0.07584083655663447 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5440 is 0.07583918995707023 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5441 is 0.07583761033355112 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5442 is 0.07583593018916845 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5443 is 0.0758342847557112 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5444 is 0.07583271176704394 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5445 is 0.0758310347326121 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5446 is 0.0758293957358012 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5447 is 0.0758278241958795 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5448 is 0.07582615017584587 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5449 is 0.07582452243253679 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5450 is 0.07582294728640537 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5451 is 0.07582127629458563 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5452 is 0.07581966446881507 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5453 is 0.07581808099373821 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5454 is 0.07581641303723716 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5455 is 0.0758148215711397 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5456 is 0.07581322526753384 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5457 is 0.07581156034984607 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5458 is 0.07580999349176999 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5459 is 0.07580838005585996 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5460 is 0.07580671817854837 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5461 is 0.07580518000208586 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5462 is 0.07580354530720373 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5463 is 0.07580189272596925 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5464 is 0.07580037653553992 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5465 is 0.07579871808884193 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5466 is 0.0757971093420116 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5467 is 0.07579555710069685 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5468 is 0.07579390219353581 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5469 is 0.07579233882476617 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5470 is 0.07579074959842505 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5471 is 0.07578909905768162 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5472 is 0.07578758283391775 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5473 is 0.07578595463941785 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5474 is 0.07578433513926836 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5475 is 0.07578281410360811 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5476 is 0.07578116707388337 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5477 is 0.07577960746395736 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5478 is 0.07577803420486992 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5479 is 0.075776390771911 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5480 is 0.07577489162893197 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5481 is 0.07577326531384014 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5482 is 0.07577167154734317 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5483 is 0.07577014363422346 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5484 is 0.0757685040168001 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5485 is 0.0757669823309034 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5486 is 0.07576539000440118 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5487 is 0.07576378032153562 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5488 is 0.07576227965351816 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5489 is 0.07576064424253512 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5490 is 0.0757591157809072 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5491 is 0.07575754167450534 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5492 is 0.0757559397208512 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5493 is 0.07575446751408177 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5494 is 0.07575285219350147 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5495 is 0.07575134735257737 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5496 is 0.07574979269073258 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5497 is 0.07574821372859258 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5498 is 0.0757467368526596 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5499 is 0.07574512504240544 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5500 is 0.07574364855209814 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5501 is 0.07574207662676966 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5502 is 0.07574053196546358 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5503 is 0.07573903157243718 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5504 is 0.07573742459555191 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5505 is 0.07573598995228478 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5506 is 0.07573438312360732 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5507 is 0.07573289317232454 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5508 is 0.07573134955477395 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5509 is 0.07572979935738769 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5510 is 0.0757283192749571 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5511 is 0.07572671741199805 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5512 is 0.07572528780430332 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5513 is 0.07572369493282756 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5514 is 0.07572220764637869 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5515 is 0.07572067565159342 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5516 is 0.07571913589331326 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5517 is 0.07571765971341794 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5518 is 0.07571607185716318 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5519 is 0.07571464727343921 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5520 is 0.07571305195198032 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5521 is 0.07571160061142942 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5522 is 0.07571004789659005 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5523 is 0.07570854822577865 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5524 is 0.07570704700925499 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5525 is 0.07570550362890928 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5526 is 0.07570404945518021 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5527 is 0.07570246627605169 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5528 is 0.07570105538324336 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5529 is 0.07569946732625406 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5530 is 0.07569803246725514 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5531 is 0.07569648172423522 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5532 is 0.07569500599188782 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5533 is 0.07569349922356093 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5534 is 0.07569198700155753 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5535 is 0.07569051999501158 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5536 is 0.07568897498097715 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5537 is 0.07568754418968016 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5538 is 0.07568596959437082 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5539 is 0.07568457192880386 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5540 is 0.07568299248237717 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5541 is 0.07568158058994377 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5542 is 0.07568002889474663 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5543 is 0.07567858514263666 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5544 is 0.07567706835753146 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5545 is 0.07567559681169765 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5546 is 0.075674111045871 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5547 is 0.07567261512447361 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5548 is 0.07567115711039235 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5549 is 0.07566963977251705 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5550 is 0.07566820666440352 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5551 is 0.07566667054122475 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5552 is 0.07566525978812952 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5553 is 0.07566370727245281 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5554 is 0.07566231653654758 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5555 is 0.07566074984357986 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5556 is 0.0756593769465432 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5557 is 0.07565781037856112 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5558 is 0.07565642811975477 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5559 is 0.07565487979911067 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5560 is 0.07565347934959699 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5561 is 0.07565195222695757 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5562 is 0.07565053717954877 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5563 is 0.07564902783929833 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5564 is 0.07564760119256034 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5565 is 0.0756461067837262 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5566 is 0.07564467111846929 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5567 is 0.07564318916995387 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5568 is 0.07564174677105151 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5569 is 0.07564027686648846 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5570 is 0.07563884394096589 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5571 is 0.07563737749764064 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5572 is 0.07563592226779646 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5573 is 0.0756344694147913 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5574 is 0.07563301057445486 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5575 is 0.07563156528509173 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5576 is 0.07563010647996922 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5577 is 0.07562866478845158 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5578 is 0.07562720878904583 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5579 is 0.07562576790168439 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5580 is 0.07562431687016126 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5581 is 0.07562287467411094 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5582 is 0.07562143037221546 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5583 is 0.07561998515543557 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5584 is 0.07561855540847183 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5585 is 0.07561711595977823 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5586 is 0.07561568597803825 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5587 is 0.07561423130537143 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5588 is 0.07561280832811623 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5589 is 0.07561135151933822 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5590 is 0.07560993910892187 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5591 is 0.07560847578479991 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5592 is 0.07560707656605181 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5593 is 0.07560560387811174 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5594 is 0.07560421980032174 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5595 is 0.07560273576343382 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5596 is 0.07560137642557495 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5597 is 0.07559988979544105 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5598 is 0.07559853633970873 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5599 is 0.07559702595831996 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5600 is 0.07559568775712616 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5601 is 0.07559416995439297 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5602 is 0.07559284527911463 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5603 is 0.07559133871108988 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5604 is 0.07558998895416692 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5605 is 0.07558851231295702 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5606 is 0.07558713727455542 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5607 is 0.07558569889153714 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5608 is 0.07558430958893989 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5609 is 0.07558288881845177 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5610 is 0.07558146303839937 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5611 is 0.07558006874132472 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5612 is 0.0755786220478255 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5613 is 0.0755772568089578 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5614 is 0.07557578561840697 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5615 is 0.07557445121503624 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5616 is 0.07557295700033598 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5617 is 0.07557165827644195 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5618 is 0.07557018583742815 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5619 is 0.07556885708222372 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5620 is 0.07556741565406416 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5621 is 0.07556605870719899 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5622 is 0.0755646553206852 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5623 is 0.07556326234763383 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5624 is 0.07556190012561077 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5625 is 0.07556047134931024 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5626 is 0.07555914906238852 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5627 is 0.07555768947098856 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5628 is 0.07555638588830076 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5629 is 0.07555492953700649 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5630 is 0.07555364899397972 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5631 is 0.07555218426257507 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5632 is 0.07555085536858089 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5633 is 0.07554944311353406 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5634 is 0.07554807919179284 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5635 is 0.07554669867400055 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5636 is 0.07554531152625654 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5637 is 0.07554396158884104 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5638 is 0.07554254016645437 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5639 is 0.07554125291336088 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5640 is 0.07553980786625483 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5641 is 0.0755385231668946 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5642 is 0.07553706977341816 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5643 is 0.07553576410970622 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5644 is 0.07553435625593405 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5645 is 0.07553299376045118 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5646 is 0.07553164827898554 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5647 is 0.07553024571793379 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5648 is 0.07552897483575675 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5649 is 0.07552751435725244 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5650 is 0.07552624532021943 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5651 is 0.0755248100448109 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5652 is 0.0755235060644192 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5653 is 0.0755221074496399 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5654 is 0.0755207666529599 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5655 is 0.07551942766630393 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5656 is 0.07551805735778531 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5657 is 0.07551675412689703 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5658 is 0.07551531803348067 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5659 is 0.07551405831651598 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5660 is 0.07551264341991415 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5661 is 0.0755113127682142 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5662 is 0.07550998213915523 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5663 is 0.0755086128941031 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5664 is 0.07550732739066238 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5665 is 0.07550590050394212 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5666 is 0.07550463315349058 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5667 is 0.07550324170818411 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5668 is 0.07550191601910901 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5669 is 0.07550057689318357 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5670 is 0.07549920968362936 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5671 is 0.07549795090400473 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5672 is 0.07549654076527237 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5673 is 0.07549526882512929 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5674 is 0.07549388909135286 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5675 is 0.07549255123708047 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5676 is 0.07549125627226025 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5677 is 0.0754898763867177 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5678 is 0.07548863963756267 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5679 is 0.07548723565333017 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5680 is 0.07548592328087059 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5681 is 0.07548460965248442 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5682 is 0.07548322967561621 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5683 is 0.07548198004649764 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5684 is 0.07548062943920313 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5685 is 0.07547932822694005 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5686 is 0.07547798738190498 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5687 is 0.07547663941836201 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5688 is 0.07547537256436947 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5689 is 0.07547398108973988 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5690 is 0.0754727350549046 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5691 is 0.07547140639819365 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5692 is 0.07547006809734118 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5693 is 0.07546880290632552 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5694 is 0.07546741713353422 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5695 is 0.07546615910260429 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5696 is 0.075464836313192 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5697 is 0.07546351136390876 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5698 is 0.07546226340127292 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5699 is 0.07546088318282611 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5700 is 0.07545961504027253 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5701 is 0.07545829999813418 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5702 is 0.07545695203062289 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5703 is 0.07545575296070131 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5704 is 0.07545437837379053 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5705 is 0.07545309770005407 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5706 is 0.0754517963246479 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5707 is 0.07545043735272963 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5708 is 0.07544923000861382 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5709 is 0.07544788390426337 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5710 is 0.07544660870323962 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5711 is 0.07544533553458391 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5712 is 0.0754439724441749 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5713 is 0.07544273704810896 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5714 is 0.07544142283483979 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5715 is 0.07544008807072097 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5716 is 0.07543891733844096 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5717 is 0.07543754351782542 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5718 is 0.07543626135285159 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5719 is 0.07543499948163114 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5720 is 0.07543365282625138 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5721 is 0.07543242958642515 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5722 is 0.07543115993604965 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5723 is 0.07542981218465984 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5724 is 0.07542860145115277 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5725 is 0.07542726126278873 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5726 is 0.07542598873090425 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5727 is 0.07542473902977115 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5728 is 0.0754234400983988 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5729 is 0.0754221929543359 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5730 is 0.07542090125710804 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5731 is 0.07541956778578383 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5732 is 0.07541838004113983 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5733 is 0.07541706112118286 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5734 is 0.07541578795170624 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5735 is 0.07541457582701945 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5736 is 0.07541324282863812 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5737 is 0.07541197031333029 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5738 is 0.07541074429441154 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5739 is 0.07540943029402654 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5740 is 0.07540821349885989 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5741 is 0.07540694979975167 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5742 is 0.07540562597918435 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5743 is 0.07540441376569902 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5744 is 0.0754031362444811 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5745 is 0.07540183726910993 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5746 is 0.0754006638102582 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5747 is 0.07539936810482528 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5748 is 0.07539805598722393 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5749 is 0.07539687891419468 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5750 is 0.07539556483213682 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5751 is 0.07539430966728493 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5752 is 0.07539312610203422 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5753 is 0.07539181673447183 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5754 is 0.07539055540204061 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5755 is 0.07538934510962725 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5756 is 0.0753880393594261 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5757 is 0.07538679622261144 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5758 is 0.07538561210116468 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5759 is 0.07538430564152131 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5760 is 0.07538307315563199 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5761 is 0.07538185243162653 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5762 is 0.07538055488709748 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5763 is 0.07537933307225983 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5764 is 0.07537815959999976 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5765 is 0.07537684013238938 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5766 is 0.0753756137627407 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5767 is 0.07537439886142078 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5768 is 0.07537310961005456 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5769 is 0.07537190377860327 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5770 is 0.07537071589374633 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5771 is 0.07536941442930524 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5772 is 0.07536818786007832 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5773 is 0.0753669759753749 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5774 is 0.07536570697084145 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5775 is 0.0753645005800788 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5776 is 0.07536330227215077 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5777 is 0.07536202459756176 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5778 is 0.0753607878494803 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5779 is 0.07535959915032095 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5780 is 0.07535832213955714 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5781 is 0.07535710608538251 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5782 is 0.0753559432855663 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5783 is 0.07535466709353067 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5784 is 0.07535341768410299 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5785 is 0.07535226094165962 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5786 is 0.0753509925640987 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5787 is 0.07534977111410561 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5788 is 0.07534861344184743 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5789 is 0.0753473525313379 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5790 is 0.07534608668652219 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5791 is 0.07534492618566394 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5792 is 0.07534371774886357 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5793 is 0.07534247112749941 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5794 is 0.07534127831945546 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5795 is 0.07534007839821144 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5796 is 0.07533881905817819 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5797 is 0.07533759686905887 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5798 is 0.07533644960313257 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5799 is 0.07533521558222257 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5800 is 0.07533396327040995 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5801 is 0.07533283543839323 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5802 is 0.07533158495345277 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5803 is 0.07533033896715725 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5804 is 0.07532921892671414 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5805 is 0.07532799820201572 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5806 is 0.07532674936104242 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5807 is 0.07532555450824238 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5808 is 0.07532438686499834 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5809 is 0.07532318557666565 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5810 is 0.07532196983103634 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5811 is 0.07532083622250958 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5812 is 0.07531960425625922 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5813 is 0.07531837048894371 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5814 is 0.07531727443090233 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5815 is 0.07531608018230959 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5816 is 0.07531483700792294 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5817 is 0.0753136771148413 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5818 is 0.07531249822449129 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5819 is 0.0753112971530351 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5820 is 0.0753101904611816 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5821 is 0.07530899860353708 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5822 is 0.07530781615779994 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5823 is 0.07530664819620646 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5824 is 0.07530558640976551 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5825 is 0.0753044119217435 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5826 is 0.0753031907454296 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5827 is 0.0753020854796167 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5828 is 0.07530091041551931 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5829 is 0.07529979072291021 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5830 is 0.07529861992902782 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5831 is 0.07529744654160613 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5832 is 0.07529640321867963 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5833 is 0.07529512872457372 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5834 is 0.07529404409692429 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5835 is 0.07529290940043867 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5836 is 0.07529175123855067 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5837 is 0.07529064729481326 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5838 is 0.07528940432067995 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5839 is 0.07528837633694994 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5840 is 0.07528723286941297 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5841 is 0.07528604179681625 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5842 is 0.07528488358440659 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5843 is 0.07528378757591044 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5844 is 0.07528274100490524 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5845 is 0.07528149663905553 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5846 is 0.07528038138000141 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5847 is 0.0752792696964934 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5848 is 0.07527821787748692 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5849 is 0.07527699365348639 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5850 is 0.07527594511624312 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5851 is 0.07527475120103333 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5852 is 0.07527365882340803 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5853 is 0.07527254022920514 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5854 is 0.07527142007506489 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5855 is 0.07527032181942805 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5856 is 0.0752691577924201 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5857 is 0.07526809677621257 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5858 is 0.07526697204580156 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5859 is 0.07526581017544698 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5860 is 0.07526472422857432 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5861 is 0.07526366267493516 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5862 is 0.07526252648731663 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5863 is 0.07526140451242529 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5864 is 0.07526030110150442 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5865 is 0.07525913414888126 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5866 is 0.07525811894927295 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5867 is 0.07525705023185945 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5868 is 0.07525588791264998 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5869 is 0.07525476181589302 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5870 is 0.0752536824420313 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5871 is 0.07525255921753443 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5872 is 0.07525153860058073 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5873 is 0.07525040117721353 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5874 is 0.07524927052830332 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5875 is 0.07524822975709733 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5876 is 0.07524709704101028 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5877 is 0.07524606484085003 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5878 is 0.07524492181998195 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 5879 is 0.0752438573548558 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5880 is 0.0752427241590419 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5881 is 0.0752416377379814 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5882 is 0.07524058886331905 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5883 is 0.07523950397913072 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5884 is 0.07523844992547915 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5885 is 0.07523731188039613 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5886 is 0.07523622195000836 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5887 is 0.07523515744403492 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5888 is 0.0752340777462221 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5889 is 0.07523303491815432 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5890 is 0.07523194715719358 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5891 is 0.07523083791557891 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5892 is 0.07522977999369439 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5893 is 0.07522868981526956 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5894 is 0.07522761856113104 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5895 is 0.0752266186379496 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5896 is 0.07522549910071538 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5897 is 0.07522441219189056 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5898 is 0.07522337341741392 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5899 is 0.07522226634901058 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5900 is 0.07522119240720498 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5901 is 0.07522018170328808 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5902 is 0.07521910832113866 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5903 is 0.07521803417860462 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5904 is 0.07521698595195644 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5905 is 0.07521589745038616 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5906 is 0.07521482403723635 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5907 is 0.07521378379465306 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5908 is 0.07521272776255361 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5909 is 0.07521168100036435 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5910 is 0.07521064479378863 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5911 is 0.07520956937639471 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5912 is 0.07520848329317527 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5913 is 0.07520747604713682 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5914 is 0.0752064045932549 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5915 is 0.07520531503698602 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5916 is 0.07520433058618291 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5917 is 0.07520328970875824 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5918 is 0.07520220377443325 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5919 is 0.0752011599482758 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5920 is 0.07520013571233168 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5921 is 0.07519905131844626 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5922 is 0.07519799284619207 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5923 is 0.07519696324404279 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5924 is 0.07519593871317268 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5925 is 0.07519490470138508 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5926 is 0.07519384295384574 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5927 is 0.07519283278171143 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5928 is 0.07519177102939158 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5929 is 0.07519071385747776 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5930 is 0.07518968672193699 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5931 is 0.07518867074564406 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5932 is 0.07518760101893039 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5933 is 0.07518655723341859 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5934 is 0.0751855758660526 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5935 is 0.07518454311261247 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5936 is 0.07518348144359108 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5937 is 0.07518244684130501 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5938 is 0.07518145054239997 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5939 is 0.07518038812505476 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5940 is 0.07517934980616539 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5941 is 0.07517830409881517 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5942 is 0.07517731076031849 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5943 is 0.07517629570460069 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5944 is 0.07517526756473926 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5945 is 0.07517422308155546 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5946 is 0.07517321466074844 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5947 is 0.07517220494587491 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5948 is 0.07517115619009462 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5949 is 0.07517012694668256 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5950 is 0.07516910278650828 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5951 is 0.07516810628356009 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5952 is 0.07516706765376642 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5953 is 0.07516604282428757 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5954 is 0.07516501060483292 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5955 is 0.07516404346931237 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5956 is 0.07516303550032398 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5957 is 0.07516199915566081 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5958 is 0.07516097537266095 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5959 is 0.07515996520803156 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5960 is 0.07515897476207145 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5961 is 0.07515794000716065 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5962 is 0.07515692731125569 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5963 is 0.07515590360102106 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5964 is 0.07515491115407767 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5965 is 0.07515392278302055 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5966 is 0.07515289143825735 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5967 is 0.07515186643862415 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5968 is 0.07515086354235899 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5969 is 0.07514991630726947 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5970 is 0.07514889019699872 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5971 is 0.07514787476480725 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5972 is 0.07514686850767649 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5973 is 0.07514585246460334 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5974 is 0.07514487611277763 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5975 is 0.07514388621525137 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5976 is 0.07514286577673987 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5977 is 0.07514185066359767 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5978 is 0.07514085274018394 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5979 is 0.07513985124647206 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5980 is 0.07513888044019315 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5981 is 0.07513786533426359 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5982 is 0.07513687395311616 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5983 is 0.07513586600748415 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5984 is 0.07513490437536073 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5985 is 0.07513401031152567 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5986 is 0.07513293810073379 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5987 is 0.07513190101305049 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5988 is 0.07513085725396187 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5989 is 0.07512981989505695 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5990 is 0.07512883805038661 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5991 is 0.07512779598694673 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5992 is 0.07512676006998488 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5993 is 0.07512575245468894 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5994 is 0.07512474899683093 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5995 is 0.0751237130511946 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5996 is 0.07512268245253428 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5997 is 0.07512168813517697 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5998 is 0.07512067849732257 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 5999 is 0.07511964719142246 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6000 is 0.07511862084123741 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6001 is 0.07511763146642125 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6002 is 0.07511662444557243 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6003 is 0.07511559722300629 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6004 is 0.07511458033798606 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6005 is 0.07511361284958747 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6006 is 0.07511260559818823 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6007 is 0.07511158203916168 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6008 is 0.07511056244917479 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6009 is 0.07510956787274609 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6010 is 0.07510857676304429 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6011 is 0.07510755562508785 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6012 is 0.07510653887962011 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6013 is 0.07510554319768052 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6014 is 0.07510455979277929 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6015 is 0.07510354155056541 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6016 is 0.07510252784899889 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6017 is 0.07510153227141222 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6018 is 0.0751005548865625 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6019 is 0.07509953968572164 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6020 is 0.07509852905171376 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6021 is 0.07509753304472888 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6022 is 0.07509656200367769 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6023 is 0.07509554982576333 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6024 is 0.07509454219911481 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6025 is 0.0750935449035856 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6026 is 0.0750925917832352 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6027 is 0.07509158782773745 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6028 is 0.07509058299412585 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6029 is 0.0750895808965981 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6030 is 0.07508861351362864 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6031 is 0.07508762409053125 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6032 is 0.07508662019019081 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6033 is 0.07508561993234562 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6034 is 0.075084635189908 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6035 is 0.07508367042204413 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6036 is 0.07508266807552964 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6037 is 0.0750816699041582 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6038 is 0.07508067696833971 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6039 is 0.07507972622532649 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6040 is 0.07507872615997031 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6041 is 0.07507773044845556 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6042 is 0.07507673798532438 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6043 is 0.07507578029551218 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6044 is 0.07507480104576396 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6045 is 0.07507380616731867 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6046 is 0.07507281527337158 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6047 is 0.07507184340797042 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6048 is 0.07507088500037756 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6049 is 0.07506989202432757 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6050 is 0.07506890328625132 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6051 is 0.07506792365494798 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6052 is 0.07506697838703379 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6053 is 0.07506598769720613 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6054 is 0.07506500135299568 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6055 is 0.07506401822492585 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6056 is 0.07506307302929567 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6057 is 0.07506209957968586 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6058 is 0.07506111389013449 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6059 is 0.07506013204641232 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6060 is 0.07505916918669944 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6061 is 0.07505821884741823 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6062 is 0.07505723475851926 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6063 is 0.07505625481207046 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6064 is 0.07505528123246434 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6065 is 0.07505434682624254 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6066 is 0.0750533647977429 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6067 is 0.07505238704783242 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6068 is 0.07505141245522629 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6069 is 0.0750504710185095 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6070 is 0.07504951049496884 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6071 is 0.07504853324744792 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6072 is 0.07504755980271173 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6073 is 0.07504659932595899 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6074 is 0.0750456621040854 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6075 is 0.07504468517161535 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6076 is 0.07504371239051856 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6077 is 0.07504274267234824 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6078 is 0.07504180990296384 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6079 is 0.07504084994412719 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6080 is 0.07503987748805829 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6081 is 0.0750389088845755 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6082 is 0.07503795593273167 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6083 is 0.07503702156826585 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6084 is 0.07503605055823086 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6085 is 0.07503508361479097 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6086 is 0.07503411967177104 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6087 is 0.07503319289853552 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6088 is 0.0750322381375066 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6089 is 0.07503127139197659 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6090 is 0.07503030835333495 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6091 is 0.0750293604107712 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6092 is 0.07502843202478406 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6093 is 0.07502746656682745 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6094 is 0.07502650522573737 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6095 is 0.07502554685949267 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6096 is 0.07502462447541966 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6097 is 0.07502367634532679 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6098 is 0.07502271513492893 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6099 is 0.07502175761476862 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6100 is 0.07502081364042977 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6101 is 0.07501989224527209 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6102 is 0.07501893223756723 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6103 is 0.0750179762689142 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6104 is 0.07501702327409379 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6105 is 0.07501610463721971 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6106 is 0.07501516350806797 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6107 is 0.07501420764135962 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6108 is 0.07501325546206225 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6109 is 0.07501231517435603 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6110 is 0.07501140077366382 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6111 is 0.07501044607948687 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6112 is 0.07500949542075394 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6113 is 0.0750085477305204 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6114 is 0.07500763270796329 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6115 is 0.0750066985667838 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6116 is 0.07500574797677366 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6117 is 0.07500480106989971 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6118 is 0.07500386430941047 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6119 is 0.07500295692354797 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6120 is 0.07500200747500357 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6121 is 0.0750010620582227 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6122 is 0.07500011960485527 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6123 is 0.07499920803231754 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6124 is 0.07499828090968302 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6125 is 0.07499733553000533 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6126 is 0.07499639382966206 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6127 is 0.07499546043241136 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6128 is 0.07499456009543283 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6129 is 0.07499361582792258 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6130 is 0.07499267558903142 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6131 is 0.07499173831126954 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6132 is 0.07499083005271226 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6133 is 0.07498991001742612 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6134 is 0.07498896981524401 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6135 is 0.07498803328834679 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6136 is 0.07498710311893303 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6137 is 0.07498620990233816 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6138 is 0.07498527078344276 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6139 is 0.07498433569034756 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6140 is 0.07498340355197067 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6141 is 0.07498249842388083 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6142 is 0.07498158548157478 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6143 is 0.07498065038024902 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6144 is 0.07497971898849316 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6145 is 0.07497879191064746 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6146 is 0.07497790592620725 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6147 is 0.07497697195952592 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6148 is 0.07497604200985497 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6149 is 0.07497511500723603 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6150 is 0.07497421278960562 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6151 is 0.07497330719591676 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6152 is 0.07497237719147189 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6153 is 0.07497145085595883 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6154 is 0.07497052638259766 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6155 is 0.07496963737820418 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6156 is 0.07496871990590191 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6157 is 0.07496779084353228 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6158 is 0.07496686537738118 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6159 is 0.07496595249293705 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6160 is 0.07496506374723538 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6161 is 0.07496413558592445 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6162 is 0.07496321140198868 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6163 is 0.07496229013074242 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6164 is 0.07496140111795409 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6165 is 0.07496049369185982 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6166 is 0.07495956939716517 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6167 is 0.07495864874582894 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6168 is 0.07495773731609254 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6169 is 0.07495685707655211 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6170 is 0.07495593373731259 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6171 is 0.0749550144010495 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6172 is 0.07495409799445328 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6173 is 0.07495321142811669 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6174 is 0.07495231141778118 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6175 is 0.07495139194568042 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6176 is 0.0749504761287425 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6177 is 0.07494956752330371 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6178 is 0.07494869424023332 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6179 is 0.07494777572230728 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6180 is 0.07494686121406186 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6181 is 0.07494594963874174 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6182 is 0.07494506618755044 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6183 is 0.07494417278519211 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6184 is 0.07494325812586222 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6185 is 0.07494234712400223 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6186 is 0.07494144171904722 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6187 is 0.07494057491034983 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6188 is 0.07493966118897409 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6189 is 0.07493875147868818 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6190 is 0.07493784470065676 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6191 is 0.07493696451219582 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6192 is 0.07493607746644668 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6193 is 0.07493516758411344 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6194 is 0.07493426135908324 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6195 is 0.07493335919339103 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6196 is 0.07493249872009669 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6197 is 0.07493158975568666 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6198 is 0.07493068480224203 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6199 is 0.07492978277918791 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6200 is 0.07492890580404685 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6201 is 0.07492802506547844 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6202 is 0.07492711991738321 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6203 is 0.07492621842563742 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6204 is 0.07492531962451694 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6205 is 0.0749244576922778 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6206 is 0.07492356694676326 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6207 is 0.07492266490503002 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6208 is 0.07492176638790786 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6209 is 0.07492087859636228 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6210 is 0.0749200183825036 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6211 is 0.07491911701991101 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6212 is 0.0749182196903139 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6213 is 0.07491732522805765 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6214 is 0.07491645988756561 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6215 is 0.07491558222545817 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6216 is 0.07491468475486836 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6217 is 0.07491379089860488 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6218 is 0.07491290214949153 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6219 is 0.07491205269763015 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6220 is 0.07491115602675136 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6221 is 0.07491026334205202 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6222 is 0.07490937356457991 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6223 is 0.07490850867544674 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6224 is 0.07490764015908705 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6225 is 0.07490674719514573 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6226 is 0.07490585787318754 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6227 is 0.07490497122638648 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6228 is 0.07490412041351299 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6229 is 0.07490324273134356 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6230 is 0.0749023527870807 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6231 is 0.07490146635782549 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6232 is 0.07490058899850635 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6233 is 0.07489974243887319 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6234 is 0.0748988531085034 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6235 is 0.0748979677124351 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6236 is 0.07489708518374591 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6237 is 0.07489622969477484 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6238 is 0.07489536599209448 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6239 is 0.07489448022807195 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6240 is 0.07489359808229065 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6241 is 0.07489271871386642 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6242 is 0.07489188331021664 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6243 is 0.07489099830327342 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6244 is 0.07489011728316326 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6245 is 0.07488923916577235 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6246 is 0.07488838333993995 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6247 is 0.07488752906045003 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6248 is 0.07488664770551613 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6249 is 0.07488576998995528 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6250 is 0.07488489494309483 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6251 is 0.07488405280802256 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6252 is 0.0748831896207275 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6253 is 0.07488231122471387 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6254 is 0.074881436340317 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6255 is 0.0748805672753509 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6256 is 0.07487973549461356 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6257 is 0.07487885765897855 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6258 is 0.07487798375562284 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6259 is 0.07487711271363862 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6260 is 0.07487626513643655 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6261 is 0.07487541646963651 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6262 is 0.07487454214112237 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6263 is 0.07487367142783369 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6264 is 0.0748728033627929 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6265 is 0.07487196830335317 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6266 is 0.07487111184158228 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6267 is 0.07487024039942561 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6268 is 0.07486937247629022 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6269 is 0.07486850984916867 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6270 is 0.07486768544722001 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6271 is 0.07486681453689371 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6272 is 0.07486594755122941 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6273 is 0.07486508341837846 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6274 is 0.07486424169702033 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6275 is 0.07486340091941363 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6276 is 0.07486253346703711 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6277 is 0.07486166962478945 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6278 is 0.0748608084242485 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6279 is 0.07485997875021932 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6280 is 0.0748591305775907 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6281 is 0.07485826595787799 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6282 is 0.07485740483350706 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6283 is 0.07485654719775343 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6284 is 0.07485573136388132 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6285 is 0.07485486722147376 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6286 is 0.0748540070014155 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6287 is 0.0748531496296716 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6288 is 0.07485231254699891 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6289 is 0.07485148061780757 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6290 is 0.07485061989562147 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6291 is 0.07484976278123712 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6292 is 0.07484890835724299 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6293 is 0.0748480829652825 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6294 is 0.07484724407726819 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6295 is 0.07484638627706165 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6296 is 0.07484553201533982 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6297 is 0.07484468029363645 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6298 is 0.07484386225425564 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6299 is 0.07484302073511885 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6300 is 0.0748421655142604 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6301 is 0.07484131373111727 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6302 is 0.07484046559212032 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6303 is 0.07483965857569513 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6304 is 0.07483880370407367 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6305 is 0.07483795274320489 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6306 is 0.0748371046472298 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6307 is 0.07483627534389152 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6308 is 0.0748354539639248 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6309 is 0.07483460253056835 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6310 is 0.07483375467059558 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6311 is 0.0748329094196056 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6312 is 0.07483209029614035 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6313 is 0.07483126324566841 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6314 is 0.07483041449337541 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6315 is 0.07482956921779431 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6316 is 0.07482872648357959 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6317 is 0.07482791427660027 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6318 is 0.07482708487746006 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6319 is 0.07482623860521265 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6320 is 0.07482539577011528 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6321 is 0.07482455544705871 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6322 is 0.07482374853071927 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6323 is 0.07482291842237086 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6324 is 0.07482207453981544 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6325 is 0.07482123407617923 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6326 is 0.07482039611007275 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6327 is 0.07481959356583556 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6328 is 0.0748187636608189 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6329 is 0.07481792211961945 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6330 is 0.0748170839879401 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6331 is 0.07481624971401768 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6332 is 0.0748154558362791 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6333 is 0.0748146145416585 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6334 is 0.07481377711970086 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6335 is 0.07481294249941772 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6336 is 0.07481212572929051 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6337 is 0.07481131858339089 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6338 is 0.07481048049336028 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6339 is 0.07480964598898106 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6340 is 0.07480881424825579 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6341 is 0.07480800701255874 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6342 is 0.07480719487115617 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6343 is 0.07480635959308936 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6344 is 0.07480552778125472 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6345 is 0.07480469843193667 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 6346 is 0.074803897570585 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6347 is 0.07480308345431756 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6348 is 0.0748022506149277 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6349 is 0.07480142111395098 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6350 is 0.07480059403066147 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6351 is 0.07479979805592865 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6352 is 0.0747989835569802 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6353 is 0.07479815296544812 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6354 is 0.07479732565261149 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6355 is 0.0747965008524692 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6356 is 0.07479570895980703 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6357 is 0.07479489479784862 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6358 is 0.07479406637189222 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6359 is 0.07479324136587963 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6360 is 0.07479241885173513 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6361 is 0.07479163045207285 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6362 is 0.07479081720670454 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6363 is 0.07478999104909757 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6364 is 0.07478916829893653 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6365 is 0.07478834803060282 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6366 is 0.07478756248532754 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6367 is 0.074786750784935 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6368 is 0.07478592685962265 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6369 is 0.074785106374271 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6370 is 0.0747842884660492 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6371 is 0.07478350528093088 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6372 is 0.07478269586334421 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6373 is 0.07478187424723223 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6374 is 0.0747810561090544 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6375 is 0.07478024042722556 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6376 is 0.0747794588593308 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6377 is 0.07477865215861003 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6378 is 0.07477783279039116 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6379 is 0.0747770168085462 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6380 is 0.0747762032903347 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6381 is 0.07477542332492693 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6382 is 0.07477461937443754 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6383 is 0.07477380216280728 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6384 is 0.07477298834169002 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6385 is 0.07477217698608919 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6386 is 0.07477139859861658 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6387 is 0.07477059739569215 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6388 is 0.07476978233777531 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6389 is 0.07476897067171598 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6390 is 0.0747681614712456 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6391 is 0.07476738456472659 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6392 is 0.07476658618230769 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6393 is 0.07476577326999524 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6394 is 0.07476496374993287 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6395 is 0.07476415669490391 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6396 is 0.07476338114493541 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6397 is 0.07476258568458503 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6398 is 0.07476177490797331 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6399 is 0.07476096752366895 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6400 is 0.07476016260361606 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6401 is 0.07475938827453238 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6402 is 0.07475859584961699 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6403 is 0.07475778719816845 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6404 is 0.07475698193896499 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6405 is 0.074756179143149 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6406 is 0.07475540589431108 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6407 is 0.07475461662347739 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6408 is 0.0747538100248036 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6409 is 0.07475300674314468 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6410 is 0.07475220592899348 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6411 is 0.07475143359941641 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6412 is 0.07475064739029891 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6413 is 0.07474984282681783 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6414 is 0.0747490416579963 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6415 is 0.07474824295249795 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6416 is 0.07474747165879173 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6417 is 0.07474668893102654 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6418 is 0.07474588683858106 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6419 is 0.07474508808848639 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6420 is 0.07474429177016519 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6421 is 0.07474352097855662 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6422 is 0.07474274832183546 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6423 is 0.07474194700580968 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6424 is 0.0747411505212771 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6425 is 0.07474036124738458 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6426 is 0.07473961003385345 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6427 is 0.07473881114859801 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6428 is 0.07473801678400324 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6429 is 0.07473722564628572 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6430 is 0.07473646071422765 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6431 is 0.07473568919573388 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6432 is 0.07473489465624941 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6433 is 0.07473410392811866 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6434 is 0.07473331595375338 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6435 is 0.07473255737286658 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6436 is 0.07473178341072904 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6437 is 0.07473099179001669 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6438 is 0.07473020373430873 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6439 is 0.07472941826170615 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6440 is 0.07472865878103051 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6441 is 0.07472788971865953 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6442 is 0.07472711605933129 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6443 is 0.0747263515321387 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6444 is 0.07472556421618978 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6445 is 0.07472478014046922 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6446 is 0.0747240378125399 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6447 is 0.07472329914141637 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6448 is 0.0747225055693304 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6449 is 0.07472171781817451 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6450 is 0.07472093408819039 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6451 is 0.07472017548673651 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6452 is 0.07471945820845967 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6453 is 0.07471866513484014 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6454 is 0.07471787833653669 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6455 is 0.07471709585950205 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6456 is 0.0747163346144246 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6457 is 0.07471557366338434 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6458 is 0.07471482383307114 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6459 is 0.07471405836129054 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6460 is 0.074713273189651 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6461 is 0.0747125051948611 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6462 is 0.07471175119438524 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6463 is 0.07471097696218923 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6464 is 0.07471023955941443 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6465 is 0.07470945456516984 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6466 is 0.0747086895094933 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6467 is 0.0747079350696696 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6468 is 0.07470715687586746 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6469 is 0.0747064139469165 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6470 is 0.07470565029675867 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6471 is 0.07470488203584863 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6472 is 0.07470413157856774 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6473 is 0.07470335363167895 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6474 is 0.0747025942261458 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6475 is 0.07470185094067061 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6476 is 0.07470108692316528 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6477 is 0.07470033469729735 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6478 is 0.0746995579489718 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6479 is 0.07469879092867868 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6480 is 0.07469805909090128 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6481 is 0.0746973020922778 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6482 is 0.0746965460229647 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6483 is 0.07469577075017103 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6484 is 0.07469499998419558 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6485 is 0.07469427554035074 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6486 is 0.07469352650878866 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6487 is 0.07469276576714992 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6488 is 0.0746919922536929 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6489 is 0.0746912228615865 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6490 is 0.07469052625245858 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6491 is 0.07468977630943625 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6492 is 0.07468899750044682 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6493 is 0.07468822504606651 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6494 is 0.07468746093630138 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6495 is 0.07468672852778414 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6496 is 0.07468598724491589 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6497 is 0.0746852420223183 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6498 is 0.07468446959037216 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6499 is 0.07468370860936999 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6500 is 0.07468297538180584 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6501 is 0.07468222190713807 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6502 is 0.07468149251187423 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6503 is 0.07468072118743142 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6504 is 0.07467996684713507 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6505 is 0.07467923005203832 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6506 is 0.07467847030412923 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6507 is 0.0746777509097705 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6508 is 0.0746769811115542 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6509 is 0.07467623467954082 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6510 is 0.07467549305603356 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6511 is 0.074674730031789 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6512 is 0.07467401036716906 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6513 is 0.07467325540866936 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6514 is 0.07467250663245413 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6515 is 0.07467176754190466 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6516 is 0.07467100503491395 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6517 is 0.07467027278163632 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6518 is 0.07466953406928582 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6519 is 0.07466878936164732 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6520 is 0.07466804880551221 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6521 is 0.0746672875968904 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6522 is 0.07466654945081808 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6523 is 0.07466582030968455 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6524 is 0.07466508170717052 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6525 is 0.07466433824313642 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6526 is 0.07466357863947362 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6527 is 0.07466283743198153 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6528 is 0.07466211504403485 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6529 is 0.07466138323463678 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6530 is 0.07466063640518128 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6531 is 0.07465987852295106 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6532 is 0.0746591355543329 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6533 is 0.07465841861057797 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6534 is 0.07465769378882994 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6535 is 0.07465694349061074 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6536 is 0.07465618737550773 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6537 is 0.07465544826964415 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6538 is 0.07465477654853538 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6539 is 0.0746540116703152 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6540 is 0.07465325414008472 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6541 is 0.07465250163156734 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6542 is 0.07465178493668806 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6543 is 0.07465109391986337 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6544 is 0.07465033217764498 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6545 is 0.07464957731617318 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6546 is 0.07464882717779191 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6547 is 0.07464812176689233 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6548 is 0.07464742285737427 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6549 is 0.0746466633563115 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6550 is 0.07464591058869137 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6551 is 0.07464516244823578 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6552 is 0.0746444643070509 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6553 is 0.07464376163968572 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6554 is 0.07464300408792901 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6555 is 0.07464225322181776 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6556 is 0.07464150695050627 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6557 is 0.07464081442099042 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6558 is 0.07464010968825262 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6559 is 0.07463935398036078 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6560 is 0.07463860494282083 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6561 is 0.07463786371981916 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6562 is 0.07463715580703195 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6563 is 0.07463642713712812 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6564 is 0.07463571789896839 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6565 is 0.07463496912259729 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6566 is 0.07463422986748616 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6567 is 0.07463352237595466 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6568 is 0.07463278426270699 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6569 is 0.07463208786028092 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6570 is 0.07463134026051174 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6571 is 0.07463060571703568 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6572 is 0.07462989653287408 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6573 is 0.07462915621035311 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6574 is 0.07462845627513673 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6575 is 0.07462772653078335 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6576 is 0.07462698776076795 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6577 is 0.07462628349859911 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6578 is 0.07462554342903469 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6579 is 0.07462482808767863 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6580 is 0.07462411718248922 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6581 is 0.07462338055089728 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6582 is 0.07462267643000006 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6583 is 0.07462193750158942 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6584 is 0.07462121415369624 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6585 is 0.074620514726967 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6586 is 0.07461978242933832 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6587 is 0.07461907690600955 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6588 is 0.07461833945451998 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6589 is 0.0746176112358809 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6590 is 0.07461692016592679 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6591 is 0.07461619293177857 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6592 is 0.07461548553237353 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6593 is 0.07461474968633354 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6594 is 0.07461401805014228 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6595 is 0.07461333387537059 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6596 is 0.07461261190114073 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6597 is 0.074611902532805 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6598 is 0.07461116834346525 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6599 is 0.07461043831297846 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6600 is 0.0746097654139238 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6601 is 0.07460907051362439 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6602 is 0.07460833078986452 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6603 is 0.07460759750194033 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6604 is 0.07460686862109885 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6605 is 0.07460618857466797 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6606 is 0.07460550455015585 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6607 is 0.07460476604101075 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6608 is 0.07460403410795004 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6609 is 0.07460330667904061 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6610 is 0.0746026237391772 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6611 is 0.0746019461451357 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6612 is 0.07460120910744619 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6613 is 0.07460047870568981 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6614 is 0.07459975284964794 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6615 is 0.07459906885080225 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6616 is 0.07459839576811444 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6617 is 0.07459766025174847 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6618 is 0.07459693061740277 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6619 is 0.07459620558421869 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6620 is 0.07459552056269306 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6621 is 0.07459485033031285 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6622 is 0.0745941156813691 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6623 is 0.07459338771175336 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6624 is 0.07459266432034771 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6625 is 0.07459197949821829 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6626 is 0.07459131244111097 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6627 is 0.07459057942780188 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6628 is 0.07458985310767115 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6629 is 0.07458913256831515 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6630 is 0.07458844918862685 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6631 is 0.07458772892665515 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6632 is 0.07458704645615034 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6633 is 0.07458633733194364 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6634 is 0.07458561401943042 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6635 is 0.07458492593295292 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6636 is 0.07458421490981317 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6637 is 0.0745835012036577 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6638 is 0.07458282635883914 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6639 is 0.07458210260297778 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6640 is 0.07458141183432045 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6641 is 0.07458070519284166 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6642 is 0.07457998815256604 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6643 is 0.07457930109993739 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6644 is 0.07457860389716539 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6645 is 0.07457790451825948 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6646 is 0.0745772064895632 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6647 is 0.07457648934699512 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6648 is 0.07457578154209733 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6649 is 0.07457510839997072 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6650 is 0.07457440799856599 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6651 is 0.07457371285040737 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6652 is 0.0745729966018885 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6653 is 0.07457228437357008 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6654 is 0.07457162602717672 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6655 is 0.07457095082412746 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6656 is 0.07457022872543642 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6657 is 0.07456951299689056 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6658 is 0.074568801618271 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6659 is 0.07456812881154792 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6660 is 0.07456747177489174 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6661 is 0.07456675060982883 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6662 is 0.07456603600778369 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6663 is 0.07456532590783611 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6664 is 0.07456464479045946 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6665 is 0.07456399957510138 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6666 is 0.07456327977187475 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6667 is 0.07456256660516873 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6668 is 0.07456185797288864 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6669 is 0.07456117545734751 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6670 is 0.07456048369238248 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6671 is 0.07455980379675704 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6672 is 0.07455911759130161 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6673 is 0.07455840648212732 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6674 is 0.07455771287991929 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6675 is 0.07455703256346159 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6676 is 0.07455632735695998 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6677 is 0.07455565946157727 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6678 is 0.07455496538820539 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6679 is 0.07455425973088416 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6680 is 0.07455359144594549 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6681 is 0.07455288604361221 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6682 is 0.07455219057274805 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6683 is 0.07455152750341042 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6684 is 0.07455081977223532 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6685 is 0.07455015510027535 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6686 is 0.07454945033904263 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6687 is 0.0745487495707067 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6688 is 0.07454807925277548 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6689 is 0.07454743848684836 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6690 is 0.07454672775116447 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6691 is 0.07454602337047284 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6692 is 0.07454532332146652 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6693 is 0.07454463543012096 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6694 is 0.07454401590844727 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6695 is 0.07454330598134135 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6696 is 0.07454260262095219 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6697 is 0.07454190373783534 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6698 is 0.0745412106406948 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6699 is 0.07454054891017113 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6700 is 0.07453987626295847 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6701 is 0.07453920159641551 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6702 is 0.07453850008711559 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6703 is 0.07453780309609348 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6704 is 0.07453713800066525 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6705 is 0.0745364520416826 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6706 is 0.07453577937248787 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6707 is 0.07453510848712178 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6708 is 0.07453440888404979 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6709 is 0.07453373221350172 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6710 is 0.07453305798401175 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6711 is 0.07453236421906281 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6712 is 0.0745316995059914 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6713 is 0.0745310245027221 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6714 is 0.07453033508446315 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6715 is 0.07452967269773009 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6716 is 0.07452897827442775 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6717 is 0.07452828756049086 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6718 is 0.0745276377095324 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6719 is 0.07452699464794 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6720 is 0.07452629383183033 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6721 is 0.07452559920090625 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6722 is 0.07452490871713549 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6723 is 0.07452423332731682 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6724 is 0.07452361947219463 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6725 is 0.07452291903041314 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6726 is 0.07452222527774406 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6727 is 0.07452153594488206 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6728 is 0.07452085285927842 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6729 is 0.07452019993049828 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6730 is 0.07451953339398691 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6731 is 0.07451887118359407 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6732 is 0.07451817907699841 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6733 is 0.07451749147259713 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6734 is 0.07451683492208219 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6735 is 0.07451615889445473 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6736 is 0.07451548988747561 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6737 is 0.07451483367922808 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6738 is 0.07451414325851147 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6739 is 0.07451347388609976 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6740 is 0.07451281061750914 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6741 is 0.07451212602173958 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6742 is 0.07451146348135726 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6743 is 0.07451080454429146 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6744 is 0.07451012129782314 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6745 is 0.0745094708789235 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6746 is 0.07450878556458058 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6747 is 0.0745081039614316 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6748 is 0.07450745118887743 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6749 is 0.07450682899590261 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6750 is 0.07450613710451351 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6751 is 0.07450545144433306 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6752 is 0.07450477001792653 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6753 is 0.07450409153458133 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6754 is 0.07450347886996393 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6755 is 0.07450281898790909 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6756 is 0.0745021301482022 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6757 is 0.07450144713956365 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6758 is 0.07450076807468699 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6759 is 0.07450011658302787 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6760 is 0.07449945112101318 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6761 is 0.07449879803647333 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6762 is 0.07449814047035705 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6763 is 0.07449745800181909 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6764 is 0.07449679068950629 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6765 is 0.0744961406680132 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6766 is 0.07449546371049835 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6767 is 0.07449480990339086 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6768 is 0.07449415672783964 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6769 is 0.07449347639699125 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6770 is 0.07449283619574529 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6771 is 0.07449216274404612 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6772 is 0.07449148769283372 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6773 is 0.07449083038087913 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6774 is 0.07449018429083482 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6775 is 0.0744895277704308 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6776 is 0.07448886915767092 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6777 is 0.07448819309405191 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6778 is 0.07448752068799062 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6779 is 0.07448688546474176 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6780 is 0.07448626379818328 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6781 is 0.07448558112873602 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6782 is 0.0744849046668754 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6783 is 0.07448423241691786 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6784 is 0.07448357800932696 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6785 is 0.07448292981925927 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6786 is 0.07448227407383154 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6787 is 0.07448163369406363 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6788 is 0.07448095828590572 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6789 is 0.07448028880374076 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6790 is 0.0744796553252186 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6791 is 0.07447898553745369 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6792 is 0.07447832970208049 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6793 is 0.07447769305585698 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6794 is 0.07447701990785667 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6795 is 0.07447637745124679 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6796 is 0.07447572074722418 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6797 is 0.07447505294089256 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6798 is 0.07447439292733013 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6799 is 0.07447376400395683 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6800 is 0.07447310470236533 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6801 is 0.07447246328575724 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6802 is 0.0744717944316365 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6803 is 0.07447112924157884 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6804 is 0.07447048001296724 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6805 is 0.07446988678702054 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6806 is 0.07446921139024398 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6807 is 0.07446854221434489 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6808 is 0.07446787725591975 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6809 is 0.0744672194701029 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6810 is 0.07446658932828511 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6811 is 0.07446592877263687 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6812 is 0.07446530779351943 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6813 is 0.07446463967381652 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6814 is 0.07446397599956157 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6815 is 0.07446334164496111 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6816 is 0.07446269111480608 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6817 is 0.07446203080416353 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6818 is 0.07446139535717243 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6819 is 0.0744607530517757 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6820 is 0.0744600939924315 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6821 is 0.0744594654926248 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6822 is 0.07445880322992118 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6823 is 0.07445814440805272 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6824 is 0.07445749768138865 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6825 is 0.07445687018132119 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6826 is 0.07445623489650861 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6827 is 0.07445558565488318 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6828 is 0.0744549249322097 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6829 is 0.07445426767656088 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6830 is 0.07445363501311726 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6831 is 0.07445299283920384 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6832 is 0.0744523554694176 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6833 is 0.0744517227113174 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6834 is 0.07445106140439356 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6835 is 0.07445040858402013 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6836 is 0.07444978496536026 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6837 is 0.07444912740511392 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6838 is 0.07444847650380368 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6839 is 0.07444785802461881 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6840 is 0.07444719690700563 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6841 is 0.0744465667170935 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6842 is 0.07444592139960289 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6843 is 0.07444526541746409 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6844 is 0.0744446122739924 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6845 is 0.07444399834058527 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6846 is 0.07444338846186607 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6847 is 0.07444272479835115 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6848 is 0.07444206687505073 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6849 is 0.07444141283964302 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6850 is 0.07444076706301354 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6851 is 0.07444014562461986 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6852 is 0.07443949569879843 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6853 is 0.07443888371412527 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6854 is 0.07443822601442954 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6855 is 0.07443757265532851 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6856 is 0.07443694706769662 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6857 is 0.07443630797621392 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6858 is 0.07443565784262338 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6859 is 0.07443502471719446 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6860 is 0.07443439974520218 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6861 is 0.07443374762947777 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6862 is 0.07443313226013 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6863 is 0.07443248010027743 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6864 is 0.07443183134612477 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6865 is 0.07443118495920814 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6866 is 0.07443059327790522 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6867 is 0.0744299716067179 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6868 is 0.07442931466048129 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6869 is 0.07442866315649531 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6870 is 0.07442801534089656 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6871 is 0.07442738508294737 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6872 is 0.07442675990904575 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6873 is 0.07442611454306407 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6874 is 0.07442549682960548 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6875 is 0.07442486354022194 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6876 is 0.07442421364695732 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6877 is 0.0744235933060133 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6878 is 0.07442295845505242 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6879 is 0.0744223128206419 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6880 is 0.07442166979418387 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6881 is 0.07442106399907267 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6882 is 0.07442046406307397 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6883 is 0.07441981044360386 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6884 is 0.0744191624217666 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6885 is 0.07441851818058734 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6886 is 0.07441787655116214 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6887 is 0.07441727375186714 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6888 is 0.07441667430775693 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6889 is 0.07441602204902201 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6890 is 0.07441537541187174 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6891 is 0.0744147325813797 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6892 is 0.0744141111200008 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6893 is 0.07441348734011309 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6894 is 0.0744128471088727 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6895 is 0.07441222014242953 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6896 is 0.074411607303924 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6897 is 0.07441096285237825 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6898 is 0.07441035146014154 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6899 is 0.07440971861018744 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6900 is 0.07440907845949803 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6901 is 0.07440844092982613 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6902 is 0.0744078295204889 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6903 is 0.07440724627722693 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6904 is 0.07440659809990516 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6905 is 0.07440595554261029 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6906 is 0.07440531677974 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6907 is 0.07440468189368034 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6908 is 0.07440407958473028 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6909 is 0.07440344336720675 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6910 is 0.0744028204723527 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6911 is 0.07440221120693713 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6912 is 0.07440157075005227 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6913 is 0.07440094542214469 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6914 is 0.07440033443997338 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6915 is 0.07439969824430487 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6916 is 0.07439906465933754 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6917 is 0.07439844083430815 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6918 is 0.07439783601236481 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6919 is 0.07439721825355161 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6920 is 0.07439659963452896 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6921 is 0.07439596311491944 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6922 is 0.07439532980448411 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6923 is 0.07439470919857671 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6924 is 0.07439410177055351 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6925 is 0.07439347037140247 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6926 is 0.07439286177058149 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6927 is 0.07439224599775113 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6928 is 0.07439161022191883 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6929 is 0.07439099506314885 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6930 is 0.07439038262089184 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6931 is 0.07438975083117423 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6932 is 0.07438912157715606 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6933 is 0.07438850893704667 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6934 is 0.07438795929278368 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6935 is 0.0743873324921225 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6936 is 0.07438671078817104 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6937 is 0.07438609253397914 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6938 is 0.07438547989798473 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6939 is 0.07438489947747146 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6940 is 0.07438428338785716 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6941 is 0.07438366931484873 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6942 is 0.07438306338640893 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6943 is 0.07438247463288149 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6944 is 0.07438188375965747 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6945 is 0.07438128015027254 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6946 is 0.07438066256161253 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6947 is 0.07438004797527561 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6948 is 0.07437946775970519 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6949 is 0.07437886087611383 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6950 is 0.07437824795009125 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6951 is 0.07437763688029937 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6952 is 0.07437706287304725 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6953 is 0.07437649145415359 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6954 is 0.07437586979000746 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6955 is 0.07437525325075686 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6956 is 0.07437464017417766 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6957 is 0.07437405575717135 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6958 is 0.07437345728935539 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6959 is 0.07437284625992373 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6960 is 0.07437223720830856 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6961 is 0.07437164915049736 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6962 is 0.07437105760453924 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6963 is 0.07437044804692286 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6964 is 0.07436986027613535 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6965 is 0.07436926116491324 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6966 is 0.07436865016739429 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6967 is 0.07436807597680767 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6968 is 0.07436746302570475 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6969 is 0.07436685308979873 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6970 is 0.07436625233092017 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6971 is 0.07436567513682017 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6972 is 0.07436506678213065 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6973 is 0.07436446026229916 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6974 is 0.07436386732515435 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6975 is 0.0743632781970003 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6976 is 0.07436269496824631 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6977 is 0.07436209839683929 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6978 is 0.07436148816693673 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6979 is 0.07436088084353108 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6980 is 0.07436030646802864 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6981 is 0.07435970787233326 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6982 is 0.07435910204191912 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6983 is 0.07435849801868229 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6984 is 0.0743579173803145 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6985 is 0.07435736552814776 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6986 is 0.07435675089810098 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6987 is 0.07435614132782623 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6988 is 0.07435553515131076 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6989 is 0.07435495430407142 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6990 is 0.07435436596877996 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6991 is 0.07435376177420094 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6992 is 0.07435315955735451 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6993 is 0.0743525744146243 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6994 is 0.07435199408988423 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6995 is 0.07435139253045091 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6996 is 0.07435079246794335 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6997 is 0.07435021290415639 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6998 is 0.07434966639609338 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 6999 is 0.07434904841888963 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7000 is 0.07434844472384251 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7001 is 0.07434784358869422 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7002 is 0.07434726678646247 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7003 is 0.07434668196211783 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7004 is 0.07434608196850331 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7005 is 0.0743454836640803 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7006 is 0.07434489776530964 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7007 is 0.07434433034160122 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7008 is 0.07434373649109578 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7009 is 0.0743431677203949 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7010 is 0.07434255647902227 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7011 is 0.07434200532509086 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7012 is 0.07434138430358274 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7013 is 0.07434080557126733 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7014 is 0.0743402344187652 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7015 is 0.07433962674567371 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7016 is 0.07433904271067537 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7017 is 0.07433847942068662 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7018 is 0.07433790610523984 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7019 is 0.07433732339820348 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7020 is 0.07433670584828554 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7021 is 0.07433615956636909 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7022 is 0.07433556091559879 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7023 is 0.07433495050749164 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7024 is 0.07433438423483403 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7025 is 0.07433382372173858 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7026 is 0.07433322045986059 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7027 is 0.07433265405721552 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7028 is 0.0743320797648265 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7029 is 0.07433149090973684 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7030 is 0.07433089004672652 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7031 is 0.07433034943098257 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7032 is 0.07432974009150682 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7033 is 0.07432915395356748 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7034 is 0.07432866000971527 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7035 is 0.0743280381459948 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7036 is 0.07432742563800379 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7037 is 0.07432685407088918 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7038 is 0.07432628934367583 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7039 is 0.07432568307801501 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7040 is 0.07432511443847062 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7041 is 0.07432455188857946 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7042 is 0.07432394908849933 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7043 is 0.07432339913691824 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7044 is 0.07432287214536144 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7045 is 0.0743222560452041 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7046 is 0.0743216482368279 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7047 is 0.07432108181615421 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7048 is 0.07432051870957167 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7049 is 0.07431991601825036 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7050 is 0.07431934535034262 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7051 is 0.07431879107247898 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7052 is 0.07431819161239234 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7053 is 0.07431762753684577 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7054 is 0.07431712014857542 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7055 is 0.07431650637337106 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7056 is 0.07431590255815132 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7057 is 0.07431532790791563 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7058 is 0.07431476459538133 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7059 is 0.07431416772014615 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7060 is 0.07431361713228912 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7061 is 0.07431304865421036 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7062 is 0.07431245340723971 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7063 is 0.07431190259182402 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7064 is 0.07431138518664278 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7065 is 0.07431077634941512 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7066 is 0.07431017537150776 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7067 is 0.07430960874827605 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7068 is 0.07430904272235554 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7069 is 0.07430844858133977 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7070 is 0.07430790544543155 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7071 is 0.0743073344977987 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7072 is 0.07430674190841376 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7073 is 0.07430618731823481 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7074 is 0.0743056781544382 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7075 is 0.07430507195779576 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7076 is 0.07430447359508482 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7077 is 0.07430391214116876 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7078 is 0.07430334592853644 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7079 is 0.07430275431059673 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7080 is 0.0743022145736395 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7081 is 0.07430164486522813 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7082 is 0.07430105471946298 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7083 is 0.07430049315968786 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7084 is 0.07429994722037041 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7085 is 0.07429935826580153 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7086 is 0.07429879035219503 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7087 is 0.07429828329839766 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7088 is 0.0742976839604391 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7089 is 0.07429709127381699 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7090 is 0.07429653579575585 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7091 is 0.07429597179095807 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7092 is 0.07429538451816538 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7093 is 0.0742948486423185 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7094 is 0.07429428186110629 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7095 is 0.0742936955823756 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7096 is 0.07429313408332462 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7097 is 0.07429259456673581 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7098 is 0.07429200918183634 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7099 is 0.07429144028360708 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7100 is 0.07429087932617269 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7101 is 0.07429034754921338 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7102 is 0.07428975708695675 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7103 is 0.07428919330594103 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7104 is 0.07428864322005932 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7105 is 0.07428805873502167 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7106 is 0.07428751368305218 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7107 is 0.07428696202135543 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7108 is 0.07428637869560663 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7109 is 0.07428580799628072 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7110 is 0.0742852836524274 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7111 is 0.07428470128920656 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7112 is 0.07428412354949808 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7113 is 0.07428357619187959 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7114 is 0.07428304006696178 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7115 is 0.07428246415438165 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7116 is 0.07428188747105606 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7117 is 0.07428135514894926 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7118 is 0.0742807730499972 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7119 is 0.07428021347463508 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7120 is 0.07427968200422953 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7121 is 0.07427910143609216 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7122 is 0.07427852392531496 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7123 is 0.07427800344101346 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7124 is 0.07427743621354077 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7125 is 0.07427685854636625 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7126 is 0.07427630402005118 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7127 is 0.0742757720197654 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7128 is 0.07427519457945864 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7129 is 0.07427462608262536 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7130 is 0.07427407673992356 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7131 is 0.07427355246138254 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7132 is 0.07427297347430052 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7133 is 0.0742724073431173 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7134 is 0.07427187290976428 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7135 is 0.07427129508049449 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7136 is 0.07427074201826436 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7137 is 0.07427020003540095 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7138 is 0.07426962547833449 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7139 is 0.07426908042552605 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7140 is 0.07426854473233621 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7141 is 0.07426797033668817 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7142 is 0.0742673985042233 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7143 is 0.07426688931104385 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7144 is 0.07426636103624451 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7145 is 0.07426577545794431 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7146 is 0.07426520948285353 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7147 is 0.07426470186605491 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7148 is 0.07426415907138997 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7149 is 0.07426361007530352 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7150 is 0.07426310927209821 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7151 is 0.07426255447235693 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7152 is 0.0742619904365145 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7153 is 0.07426037117605702 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7154 is 0.07425893716889688 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7155 is 0.0742575363216538 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7156 is 0.07425624080367435 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7157 is 0.07425501977584208 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7158 is 0.07425381125534339 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7159 is 0.07425265938031045 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7160 is 0.07425147908727266 -------- Training accuracy = 97.33333333333334\n",
            "Cost after iteration 7161 is 0.07425030357897558 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7162 is 0.07424918905726008 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7163 is 0.07424805180338176 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7164 is 0.07424690367162043 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7165 is 0.0742458011684224 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7166 is 0.07424470893173775 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7167 is 0.07424358827807774 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7168 is 0.07424249141145046 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7169 is 0.07424142593989203 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7170 is 0.07424036742500138 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7171 is 0.0742392696096184 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7172 is 0.07423820252987551 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7173 is 0.07423718788134209 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7174 is 0.07423610803335738 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7175 is 0.07423505559975858 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7176 is 0.07423404276754768 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7177 is 0.07423301903937599 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7178 is 0.07423196817860554 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7179 is 0.07423096781511462 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7180 is 0.0742299624016533 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7181 is 0.07422892951141 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7182 is 0.0742279456938876 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7183 is 0.07422694930302677 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7184 is 0.07422593459977792 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7185 is 0.07422497048388756 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7186 is 0.07422398135886644 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7187 is 0.0742229862590333 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7188 is 0.07422201922023444 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7189 is 0.07422105826214669 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7190 is 0.07422007378394375 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7191 is 0.07421911006210914 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7192 is 0.07421816829156061 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7193 is 0.07421719359364813 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7194 is 0.07421623759975624 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7195 is 0.07421530850268047 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7196 is 0.07421434283461452 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7197 is 0.07421339786884033 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7198 is 0.0742124763650831 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7199 is 0.07421151903511843 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7200 is 0.07421058771765766 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7201 is 0.07420966965175575 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7202 is 0.0742087075769609 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7203 is 0.07420776567098646 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7204 is 0.0742068212500899 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7205 is 0.07420585277757069 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7206 is 0.07420492877093374 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7207 is 0.07420398208969452 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7208 is 0.07420302081018734 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7209 is 0.07420211596646976 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7210 is 0.0742011646536699 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7211 is 0.07420021986446705 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7212 is 0.07419931703205448 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7213 is 0.07419836578933943 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7214 is 0.07419744685009487 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7215 is 0.0741965314744509 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7216 is 0.07419558675108985 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7217 is 0.07419469286691596 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7218 is 0.07419376489104772 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7219 is 0.07419283398859174 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7220 is 0.07419195003293376 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7221 is 0.07419101388535214 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7222 is 0.07419011279559486 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7223 is 0.07418921056538721 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7224 is 0.0741882801140522 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7225 is 0.07418740728709995 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7226 is 0.0741864874626897 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7227 is 0.074185579499939 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7228 is 0.07418470076943125 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7229 is 0.07418377782361717 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7230 is 0.07418290222762292 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7231 is 0.07418200137057772 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7232 is 0.0741810924185755 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7233 is 0.07418023038990447 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7234 is 0.07417931474827189 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7235 is 0.07417843936411853 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7236 is 0.07417755167006472 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7237 is 0.07417664390895809 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7238 is 0.07417579366973083 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7239 is 0.07417488417686627 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7240 is 0.07417401211448177 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7241 is 0.07417313546324825 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7242 is 0.07417223164536368 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7243 is 0.07417139147953387 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7244 is 0.07417048869996848 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7245 is 0.07416962141449368 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7246 is 0.07416875356629253 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7247 is 0.0741678554163294 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7248 is 0.07416702172469043 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7249 is 0.07416612844076313 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7250 is 0.07416526242408794 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7251 is 0.07416440574007664 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7252 is 0.07416351337184143 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7253 is 0.0741626835858338 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7254 is 0.07416179880227439 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7255 is 0.07416069528761035 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7256 is 0.07415836867891225 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7257 is 0.07415621547493738 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7258 is 0.07415413102600568 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7259 is 0.07415207359410016 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7260 is 0.074150037053217 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7261 is 0.07414801732221622 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7262 is 0.07414601167843067 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7263 is 0.07414401825747174 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7264 is 0.07414203575094575 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7265 is 0.07414006321385533 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7266 is 0.07413809994143065 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7267 is 0.0741361454485073 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7268 is 0.07413423370281991 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7269 is 0.07413231201897001 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7270 is 0.07413038259663848 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7271 is 0.07412846057230969 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7272 is 0.07412656628926276 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7273 is 0.07412469752532272 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7274 is 0.07412279508193663 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7275 is 0.07412089979318548 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7276 is 0.07411905167672574 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7277 is 0.07411719399028738 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7278 is 0.07411531576495106 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7279 is 0.07411345886483348 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7280 is 0.07411164888591995 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7281 is 0.07410978684943427 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7282 is 0.07410794482248854 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7283 is 0.07410612852482375 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7284 is 0.07410432598150504 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7285 is 0.07410248789919596 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7286 is 0.07410066942771397 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7287 is 0.07409887187818495 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7288 is 0.07409709608596025 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7289 is 0.07409527740165422 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7290 is 0.07409347993251787 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7291 is 0.07409171278713447 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7292 is 0.07408994501794149 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7293 is 0.07408814792351932 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7294 is 0.07408637577105426 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7295 is 0.07408464116238889 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7296 is 0.07408285802701875 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7297 is 0.07408109268487809 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7298 is 0.07407936212417782 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7299 is 0.07407761517842269 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7300 is 0.07407587208271729 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7301 is 0.07407420042435 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7302 is 0.07407258261862466 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7303 is 0.07407090709736372 -------- Training accuracy = 97.22222222222221\n",
            "Cost after iteration 7304 is 0.07406925642630052 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7305 is 0.07406763823870678 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7306 is 0.07406598479293322 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7307 is 0.0740643358031557 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7308 is 0.0740623602544352 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7309 is 0.07405688049098494 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7310 is 0.074052063363768 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7311 is 0.07404767176650812 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7312 is 0.07404362370654075 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7313 is 0.07403982714781271 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7314 is 0.07403621831711095 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7315 is 0.07403275227875081 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7316 is 0.07402939864124423 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7317 is 0.07402613538464578 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7318 is 0.07402293924651845 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7319 is 0.07401979937165035 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7320 is 0.07401670684108085 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7321 is 0.07401365650853899 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7322 is 0.07401063818024012 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7323 is 0.07400764595309138 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7324 is 0.07400467738605569 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7325 is 0.0740017294898025 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7326 is 0.07399879986335363 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7327 is 0.07399588635265111 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7328 is 0.0739929873401601 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7329 is 0.07399010118010019 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7330 is 0.07398722592837335 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7331 is 0.0739843620661343 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7332 is 0.07398150866198354 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7333 is 0.0739786651070392 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7334 is 0.07397583189354268 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7335 is 0.07397300903860417 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7336 is 0.07397019467909997 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7337 is 0.07396740032434766 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7338 is 0.0739646444652931 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7339 is 0.07396189804122656 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7340 is 0.0739591604249007 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7341 is 0.07395643112963417 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7342 is 0.07395370977111239 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7343 is 0.07395099604085222 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7344 is 0.07394828968746112 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7345 is 0.07394559050317209 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7346 is 0.07394265915262016 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7347 is 0.07393935084601774 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7348 is 0.0739360688877149 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7349 is 0.07393280701068738 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7350 is 0.0739295619213426 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7351 is 0.07392632994050924 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7352 is 0.07392316353402836 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7353 is 0.07391996947878464 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7354 is 0.07391680178727708 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7355 is 0.0739136418445878 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7356 is 0.07391047339458251 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7357 is 0.07390734667955065 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7358 is 0.07390417780713411 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7359 is 0.07390108360254696 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7360 is 0.07389792685195362 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7361 is 0.07389483855040337 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7362 is 0.07389171257311022 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7363 is 0.07388861969285962 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7364 is 0.0738855287933542 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7365 is 0.0738825224174727 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7366 is 0.0738797150946987 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7367 is 0.07387688214789556 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7368 is 0.0738740835185692 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7369 is 0.0738712965271814 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7370 is 0.07386848255549208 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7371 is 0.07386572574165644 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7372 is 0.07386293792507202 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7373 is 0.07386015954607399 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7374 is 0.07385741911424017 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7375 is 0.07385463513862302 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7376 is 0.0738519167099627 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7377 is 0.07384915834466152 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7378 is 0.0738464248659892 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7379 is 0.0738437058161671 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7380 is 0.07384096097361363 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7381 is 0.07383827730511373 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7382 is 0.07383553590819836 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7383 is 0.07383285993673565 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7384 is 0.07383014470833116 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7385 is 0.07382745839377246 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7386 is 0.07382477689441971 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7387 is 0.07382208338975195 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7388 is 0.0738194330184547 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7389 is 0.07381673405010045 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7390 is 0.0738141127834281 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7391 is 0.07381142678471127 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7392 is 0.07380880933718027 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7393 is 0.07380614989870538 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7394 is 0.07380352751123559 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7395 is 0.07380089531429257 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7396 is 0.0737982699505121 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7397 is 0.07379566297235912 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7398 is 0.07379303611415577 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7399 is 0.0737904527826881 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7400 is 0.07378788323799629 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7401 is 0.073785678143724 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7402 is 0.07378336025896987 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7403 is 0.07378106856564182 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7404 is 0.0737786645864287 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7405 is 0.07377596196496926 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7406 is 0.07377311668797047 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7407 is 0.07377028687481144 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7408 is 0.07376755449957804 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7409 is 0.0737648604629429 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7410 is 0.07376206294878296 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7411 is 0.0737593331381769 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7412 is 0.07375655928044933 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7413 is 0.07375394057364214 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7414 is 0.07375120708904635 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7415 is 0.07374844925359349 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7416 is 0.07374576234320165 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7417 is 0.07374311097928869 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7418 is 0.07374045118820992 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7419 is 0.07373766284271442 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7420 is 0.07373433558951348 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7421 is 0.07373103754332792 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7422 is 0.07372786598247988 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7423 is 0.07372459695987407 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7424 is 0.07372132321805462 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7425 is 0.07371806566296414 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7426 is 0.07371486684866137 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7427 is 0.07371309411102235 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7428 is 0.0737108888238329 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7429 is 0.07370907125093222 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7430 is 0.07370736297646564 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7431 is 0.07370580708125728 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7432 is 0.07370428869901786 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7433 is 0.07370274358347749 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7434 is 0.07370122480130542 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7435 is 0.07369979436779804 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7436 is 0.07369838697323389 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7437 is 0.0736969152564082 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7438 is 0.07369545559027847 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7439 is 0.07369406374864158 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7440 is 0.07369270432866667 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7441 is 0.07369126872828995 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7442 is 0.07368984193344652 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7443 is 0.07368847247786277 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7444 is 0.07368719246476324 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7445 is 0.07368586000172153 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7446 is 0.07368449951540429 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7447 is 0.07368313787104515 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7448 is 0.07368188637245586 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7449 is 0.0736803884133649 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7450 is 0.0736788170833948 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7451 is 0.07367732495305464 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7452 is 0.07367579663546998 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7453 is 0.07367442330940686 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7454 is 0.07367291436635483 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7455 is 0.0736714342363827 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7456 is 0.07366996304815578 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7457 is 0.07366847875119181 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7458 is 0.07366715257411238 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7459 is 0.07366566380205448 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7460 is 0.07366422968961274 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7461 is 0.07366277726278454 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7462 is 0.07366131901262044 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7463 is 0.07365998488649475 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7464 is 0.07365855614741368 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7465 is 0.07365713962626973 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7466 is 0.0736557131436844 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7467 is 0.07365427014572935 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7468 is 0.07365289917204398 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7469 is 0.07365154732489218 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7470 is 0.07365014508851636 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7471 is 0.07364873988116606 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7472 is 0.07364731170986592 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7473 is 0.07364594777393889 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7474 is 0.07364455426460802 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7475 is 0.07364323485315942 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7476 is 0.0736418454911396 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7477 is 0.07364043398426041 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7478 is 0.07363908205983924 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7479 is 0.07363767088668507 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7480 is 0.073636331510304 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7481 is 0.07363501968792997 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7482 is 0.0736336285534434 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7483 is 0.07363228121549002 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7484 is 0.07363088151723629 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7485 is 0.07362954354123503 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7486 is 0.0736281626136478 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7487 is 0.07362688225952528 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7488 is 0.07362555695016057 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7489 is 0.07362419248438012 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7490 is 0.07362287568321865 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7491 is 0.07362150499493032 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7492 is 0.07362020580073335 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7493 is 0.07361886169931471 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7494 is 0.07361761931851453 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7495 is 0.07361626387359997 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7496 is 0.0736149505178683 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7497 is 0.07361361366580411 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7498 is 0.07361229136171202 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7499 is 0.07361097247905257 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7500 is 0.07360967413851366 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7501 is 0.07360842101445535 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7502 is 0.07360707942642991 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7503 is 0.07360579014797963 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7504 is 0.07360444444193395 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7505 is 0.07360316869076548 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7506 is 0.07360182198202347 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7507 is 0.07360057242304928 -------- Training accuracy = 97.11111111111111\n",
            "Cost after iteration 7508 is 0.07359929328759321 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7509 is 0.07359801028694711 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7510 is 0.07359668772596656 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7511 is 0.0735953996190534 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7512 is 0.07359409041956665 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7513 is 0.0735927973098311 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7514 is 0.07359150148953995 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7515 is 0.07359026868318248 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7516 is 0.07358899577483322 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7517 is 0.0735876908546136 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7518 is 0.0735864156006982 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7519 is 0.07358510988695012 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7520 is 0.07358384365141132 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7521 is 0.0735825360346488 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7522 is 0.0735812969013123 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7523 is 0.07358004242526306 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7524 is 0.07357879241051411 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7525 is 0.07357748044033362 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7526 is 0.0735762366905116 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7527 is 0.07357492524400389 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7528 is 0.07357369015077264 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7529 is 0.07357239576390542 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7530 is 0.07357120921951374 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7531 is 0.07356996571380094 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7532 is 0.07356874496323151 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7533 is 0.07356746941604032 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7534 is 0.07356624566818441 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7535 is 0.07356497876402245 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7536 is 0.07356375407930013 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7537 is 0.07356249778330959 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7538 is 0.07356130498301662 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7539 is 0.07356009031966981 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7540 is 0.0735588681736781 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7541 is 0.07355761259010916 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7542 is 0.0735563925723406 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7543 is 0.07355514078277679 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7544 is 0.07355392251626856 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7545 is 0.07355267481198367 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7546 is 0.07355145790106891 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7547 is 0.07355027865958677 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7548 is 0.07354906798175691 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7549 is 0.07354782813274517 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7550 is 0.07354661432376806 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7551 is 0.07354539294350682 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7552 is 0.07354417848118405 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7553 is 0.07354297406772789 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7554 is 0.07354174984526246 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7555 is 0.0735406028399186 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7556 is 0.07353939649572352 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7557 is 0.07353821786000958 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7558 is 0.0735369757563467 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7559 is 0.0735358122780043 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7560 is 0.07353457186351696 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7561 is 0.0735334011016801 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7562 is 0.07353222873343036 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7563 is 0.07353114691436743 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7564 is 0.07352994114590217 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7565 is 0.07352885746936368 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7566 is 0.07352764965215206 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7567 is 0.07352661573842835 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7568 is 0.07352538328361714 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7569 is 0.07352433356804532 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7570 is 0.07352312255370874 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7571 is 0.07352203613991978 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7572 is 0.0735209762947113 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7573 is 0.07351983365399563 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7574 is 0.0735188134371558 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7575 is 0.07351766774007996 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7576 is 0.07351652086888553 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7577 is 0.07351540098176189 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7578 is 0.07351429050404383 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7579 is 0.0735131661999356 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7580 is 0.0735121141136187 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7581 is 0.0735110584911988 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7582 is 0.07350987809010189 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7583 is 0.07350849245620426 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7584 is 0.07350708158529987 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7585 is 0.07350567601597173 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7586 is 0.0735042752481006 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7587 is 0.07350291465549497 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7588 is 0.07350152899156494 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7589 is 0.07350013955073662 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7590 is 0.0734987539244019 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7591 is 0.07349741479899471 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7592 is 0.07349603744284496 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7593 is 0.07349466028533724 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7594 is 0.07349329956385524 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7595 is 0.07349196229616714 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7596 is 0.07349059326788666 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7597 is 0.07348922768839485 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7598 is 0.07348789879767811 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7599 is 0.07348655183868685 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7600 is 0.07348519547740728 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7601 is 0.07348386806341452 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7602 is 0.07348255309191819 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7603 is 0.07348119799431932 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7604 is 0.07347984696868136 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7605 is 0.07347854308303153 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7606 is 0.07347720248197569 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7607 is 0.07347585780776043 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7608 is 0.07347454111196482 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7609 is 0.07347322613372197 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7610 is 0.07347188740054363 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7611 is 0.07347055922677288 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7612 is 0.07346926786715532 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7613 is 0.07346793476498104 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7614 is 0.07346660461436821 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7615 is 0.07346531745374543 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7616 is 0.07346400054937173 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7617 is 0.073462680615154 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7618 is 0.07346139874801592 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7619 is 0.07346010386952849 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7620 is 0.07345878041915542 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7621 is 0.07345747748114936 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7622 is 0.07345619528977237 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7623 is 0.07345487817713686 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7624 is 0.07345357163995352 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7625 is 0.07345230413056762 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7626 is 0.07345099245727689 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7627 is 0.07344968384961673 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7628 is 0.07344842569412827 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7629 is 0.07344712412613473 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7630 is 0.07344581979063547 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7631 is 0.0734445538565627 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7632 is 0.07344326959053836 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7633 is 0.07344196957399358 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7634 is 0.07344070659794973 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7635 is 0.07343945259743354 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7636 is 0.07343815290161942 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7637 is 0.07343687987006108 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7638 is 0.07343561795728963 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7639 is 0.07343432475232951 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7640 is 0.07343305380276677 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7641 is 0.07343180016921931 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7642 is 0.07343051210457709 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7643 is 0.07342924071843802 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7644 is 0.07342799679880621 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7645 is 0.07342671325843302 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7646 is 0.07342544041723237 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7647 is 0.07342420615217173 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7648 is 0.07342292680142018 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7649 is 0.07342165338314026 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7650 is 0.07342042916025988 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7651 is 0.07341915420788632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7652 is 0.0734178960129414 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7653 is 0.07341658694078962 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7654 is 0.07341496892587807 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7655 is 0.07341336192679279 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7656 is 0.07341181316828904 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7657 is 0.07341024208088334 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7658 is 0.07340867401682535 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7659 is 0.0734071203854539 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7660 is 0.07340560862151715 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7661 is 0.07340406542733455 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7662 is 0.07340253066025262 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7663 is 0.07340100299162022 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7664 is 0.07339950149773194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7665 is 0.07339799801945442 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7666 is 0.07339648427490633 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7667 is 0.07339497597218933 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7668 is 0.07339348220656672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7669 is 0.07339201642567847 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7670 is 0.07339053743231536 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7671 is 0.07338904221684055 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7672 is 0.07338755202018228 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7673 is 0.07338606613175923 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7674 is 0.07338459749523189 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7675 is 0.07338313682139275 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7676 is 0.07338166010550658 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7677 is 0.07338018729509542 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7678 is 0.07337871799467965 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7679 is 0.07337725476546063 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7680 is 0.07337581974473906 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7681 is 0.07337438086751298 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7682 is 0.07337293110121815 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7683 is 0.073371473186552 -------- Training accuracy = 97.0\n",
            "Cost after iteration 7684 is 0.07337001903535272 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7685 is 0.07336859623759846 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7686 is 0.0733671519852428 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7687 is 0.07336570528792724 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7688 is 0.0733642619802901 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7689 is 0.07336282169669753 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7690 is 0.07336140480486146 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7691 is 0.07335998103872163 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7692 is 0.0733585471546249 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7693 is 0.07335714342346436 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7694 is 0.07335571924247353 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7695 is 0.07335430788085519 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7696 is 0.07335289991866463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7697 is 0.073351475505688 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7698 is 0.07335005461462477 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7699 is 0.07334863674792082 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7700 is 0.07334724069549323 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7701 is 0.07334584192349196 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7702 is 0.07334442993717206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7703 is 0.0733430208663867 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7704 is 0.07334161738602052 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7705 is 0.0733402588952972 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7706 is 0.0733388716444037 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7707 is 0.07333746753405636 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7708 is 0.07333606704321169 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7709 is 0.07333466957989287 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7710 is 0.07333330232222002 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7711 is 0.07333191635740519 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7712 is 0.07333052440700068 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7713 is 0.07332913528405592 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7714 is 0.07332774867922531 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7715 is 0.07332639567435094 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7716 is 0.07332501710766093 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7717 is 0.07332366204564805 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7718 is 0.07332228976305187 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7719 is 0.07332091719521666 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7720 is 0.07331957373552365 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7721 is 0.07331819904905248 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7722 is 0.07331682767257455 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7723 is 0.07331545906504207 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7724 is 0.07331411296501653 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7725 is 0.07331276407707088 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7726 is 0.07331140033003428 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7727 is 0.07331044438481901 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7728 is 0.07330958346682868 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7729 is 0.07330805367489932 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7730 is 0.07330746709093842 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7731 is 0.0733061967769586 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7732 is 0.07330507936611533 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7733 is 0.0733043087613294 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7734 is 0.07330283839105521 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7735 is 0.07330239919248287 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7736 is 0.07330074652294548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7737 is 0.07330026880237248 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7738 is 0.07329890740279199 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7739 is 0.0732983264234571 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7740 is 0.0732969486913743 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7741 is 0.0732963629055463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7742 is 0.07329503012588945 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7743 is 0.07329438551470784 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7744 is 0.0732931405835931 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7745 is 0.0732923995923655 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7746 is 0.07329108910956478 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7747 is 0.07329060505224216 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7748 is 0.07328927360585201 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7749 is 0.07328858510065506 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7750 is 0.07328746153188208 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7751 is 0.07328657308534665 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7752 is 0.0732856547839993 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7753 is 0.07328456670567962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7754 is 0.07328385497106672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7755 is 0.07328256713676985 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7756 is 0.07328188274166872 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7757 is 0.07328076922959081 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7758 is 0.07328013003159992 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7759 is 0.0732787472623092 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7760 is 0.07327837397663893 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7761 is 0.07327688104187628 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7762 is 0.07327626902897388 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7763 is 0.0732753483826674 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7764 is 0.07327421483862177 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7765 is 0.07327348104248634 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7766 is 0.07327235272956503 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7767 is 0.07327180156317838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7768 is 0.07327035048975984 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7769 is 0.07326982959897063 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7770 is 0.07326887076356997 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7771 is 0.07326777691900557 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7772 is 0.07326704848687794 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7773 is 0.07326587829409768 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7774 is 0.0732654045610463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7775 is 0.07326394850964543 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7776 is 0.07326358971150534 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7777 is 0.0732623774200931 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7778 is 0.07326142065317598 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7779 is 0.07326070522371567 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7780 is 0.07325924438705946 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7781 is 0.07325881769776685 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7782 is 0.07325746067752277 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7783 is 0.07325677918406209 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7784 is 0.07325589725843493 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7785 is 0.07325455081622274 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7786 is 0.07325406945260107 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7787 is 0.07325272943975905 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7788 is 0.0732520390670571 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7789 is 0.0732512123132777 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7790 is 0.07324982038897752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7791 is 0.07324941395045388 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7792 is 0.07324805718652919 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7793 is 0.07324726854428922 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7794 is 0.0732465928137484 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7795 is 0.0732452124949809 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7796 is 0.07324472838300898 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7797 is 0.07324366052537208 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7798 is 0.07324245855122775 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7799 is 0.07324191520672099 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7800 is 0.07324057629378593 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7801 is 0.07323987790830563 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7802 is 0.07323900803648577 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7803 is 0.07323780681775571 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7804 is 0.07323743868598935 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7805 is 0.07323606752593517 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7806 is 0.07323529847504671 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7807 is 0.07323453688376583 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7808 is 0.07323320065329865 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7809 is 0.07323272292840928 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7810 is 0.07323169051125904 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7811 is 0.07323038405692617 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7812 is 0.07322987808519947 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7813 is 0.0732288639373209 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7814 is 0.07322777448493176 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7815 is 0.07322733120390414 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7816 is 0.07322598606489625 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7817 is 0.07322526323019157 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7818 is 0.0732244855485413 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7819 is 0.07322317023582905 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7820 is 0.07322269320693468 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7821 is 0.07322168718832374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7822 is 0.0732203887977755 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7823 is 0.07322009270505225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7824 is 0.07321891733026414 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7825 is 0.07321775332208669 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7826 is 0.0732172548165193 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7827 is 0.07321600012620878 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7828 is 0.07321520934549622 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7829 is 0.07321461436966918 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7830 is 0.07321330431972822 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7831 is 0.07321267763530165 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7832 is 0.07321183949061208 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7833 is 0.07321055002709075 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7834 is 0.07321010560867905 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7835 is 0.07320909794737535 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7836 is 0.0732078258534047 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7837 is 0.073207454340049 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7838 is 0.07320616559002457 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7839 is 0.07320528759909656 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7840 is 0.07320469813882131 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7841 is 0.0732034532053655 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7842 is 0.07320271618844862 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7843 is 0.07320197783544226 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7844 is 0.07320076019274195 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7845 is 0.07320013078081852 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7846 is 0.07319940846585281 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7847 is 0.07319811757261621 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7848 is 0.0731975410652473 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7849 is 0.0731966621111585 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7850 is 0.07319538823643641 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7851 is 0.07319492004278412 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7852 is 0.07319394404968847 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7853 is 0.07319268058840912 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7854 is 0.07319228412958378 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7855 is 0.07319124878682047 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7856 is 0.07318999680394978 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7857 is 0.07318961934510732 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7858 is 0.07318833554567845 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7859 is 0.07318763601673342 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7860 is 0.07318690985889388 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7861 is 0.07318564287720446 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7862 is 0.07318482239785969 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7863 is 0.07318420207764353 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7864 is 0.07318298339608378 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7865 is 0.07318222393071312 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7866 is 0.07318167084629927 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7867 is 0.07318040140320829 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7868 is 0.07317968377624157 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7869 is 0.07317898512538618 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7870 is 0.07317772934855901 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7871 is 0.0731771184446097 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7872 is 0.07317632227026186 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7873 is 0.07317507487530238 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7874 is 0.07317454177704387 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7875 is 0.07317367482054951 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7876 is 0.07317243315327807 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7877 is 0.07317196109533573 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7878 is 0.07317103904463824 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7879 is 0.07316980600062377 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7880 is 0.07316915132606172 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7881 is 0.07316839925163557 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7882 is 0.073167201414122 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7883 is 0.07316656196662567 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7884 is 0.07316577455510882 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7885 is 0.07316460708559538 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7886 is 0.07316399121858015 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7887 is 0.07316331057562056 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7888 is 0.07316206612121275 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7889 is 0.07316146790559708 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7890 is 0.07316068550944635 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7891 is 0.07315945148441667 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7892 is 0.07315892665031529 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7893 is 0.07315807836330401 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7894 is 0.07315685085958774 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7895 is 0.07315637806841042 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7896 is 0.07315548419312608 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7897 is 0.07315425958364613 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7898 is 0.07315383092776696 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7899 is 0.07315289936449362 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7900 is 0.07315170039885456 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7901 is 0.07315103897810278 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7902 is 0.07315030689290634 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7903 is 0.0731491473963324 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7904 is 0.07314850628181041 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7905 is 0.07314788004373575 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7906 is 0.07314664695910954 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7907 is 0.07314602153167511 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7908 is 0.07314529162673204 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7909 is 0.07314406972443795 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7910 is 0.07314351610518403 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7911 is 0.07314272196598447 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7912 is 0.07314150686240221 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7913 is 0.0731410072245449 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7914 is 0.0731401834235141 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7915 is 0.07313899678968255 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7916 is 0.0731382937392038 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7917 is 0.07313766061090386 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7918 is 0.07313651389486994 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7919 is 0.07313581547080174 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7920 is 0.07313530724312572 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7921 is 0.07313411995991068 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7922 is 0.07313344925211555 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7923 is 0.07313285386459116 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7924 is 0.07313167130434423 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7925 is 0.07313109370577439 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7926 is 0.07313041016629741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7927 is 0.07312923096050666 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7928 is 0.07312873883262495 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7929 is 0.07312797416109716 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7930 is 0.07312682231207313 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7931 is 0.07312613581363125 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7932 is 0.0731255311363206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7933 is 0.07312442816698374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7934 is 0.07312379734197472 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7935 is 0.07312325626729224 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7936 is 0.07312206632076744 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7937 is 0.07312150315919443 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7938 is 0.07312081420021989 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7939 is 0.07311963482223559 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7940 is 0.07311918814535233 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7941 is 0.0731183895524935 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7942 is 0.07311724536210586 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7943 is 0.07311660962846374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7944 is 0.07311611951010213 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7945 is 0.07311493094772892 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7946 is 0.07311434482184545 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7947 is 0.07311369897470864 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7948 is 0.07311252682490339 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7949 is 0.07311206115052708 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7950 is 0.07311131192438867 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7951 is 0.07311015496491934 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7952 is 0.07310977113556634 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7953 is 0.07310894349187505 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7954 is 0.0731078252528352 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7955 is 0.07310723133121437 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7956 is 0.07310672380670133 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7957 is 0.07310554981384074 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7958 is 0.07310503969630147 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7959 is 0.07310459923822984 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7960 is 0.07310337094145578 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7961 is 0.07310249106354168 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7962 is 0.07310213660819247 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7963 is 0.0731009472885887 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7964 is 0.07310032334648113 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7965 is 0.07309973300724772 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7966 is 0.07309861136569706 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7967 is 0.07309788194306606 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7968 is 0.0730978195903491 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7969 is 0.0730965030400001 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7970 is 0.07309547216262767 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7971 is 0.07309529346791202 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7972 is 0.07309405754104302 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7973 is 0.07309317522802845 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7974 is 0.07309314561278088 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7975 is 0.07309189049122936 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7976 is 0.07309088817633301 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7977 is 0.07309045364727453 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7978 is 0.07309017287548719 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7979 is 0.07308885515247014 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7980 is 0.07308805460150115 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7981 is 0.0730876329443764 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7982 is 0.07308638526832223 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7983 is 0.07308591758520856 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7984 is 0.07308547878041231 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7985 is 0.07308424774755622 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7986 is 0.07308347555130307 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7987 is 0.0730834327554725 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7988 is 0.07308210944979164 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7989 is 0.07308124249046216 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7990 is 0.0730812038104056 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7991 is 0.0730799083200949 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7992 is 0.07307887742751983 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7993 is 0.07307853906525945 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7994 is 0.07307809278067155 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7995 is 0.07307679561230675 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7996 is 0.07307624294231532 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7997 is 0.07307586252758862 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7998 is 0.07307458191360953 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 7999 is 0.07307368779230905 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8000 is 0.07307380413206695 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8001 is 0.07307247158646987 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8002 is 0.07307151139620355 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8003 is 0.07307152868194837 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8004 is 0.07307024204342424 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8005 is 0.07306921749990487 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8006 is 0.07306891457290664 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8007 is 0.07306844406092751 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8008 is 0.07306715306175562 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8009 is 0.07306662954468701 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8010 is 0.07306623214594689 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8011 is 0.07306495731993021 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8012 is 0.07306408429330276 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8013 is 0.07306419312920222 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8014 is 0.07306286721244737 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8015 is 0.07306192237427947 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8016 is 0.0730619387732286 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8017 is 0.07306065861527068 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8018 is 0.07305967492396014 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8019 is 0.07305889214223633 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8020 is 0.07305891994206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8021 is 0.07305799451879254 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8022 is 0.07305676937158664 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8023 is 0.07305632519844069 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8024 is 0.07305599620692454 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8025 is 0.07305468648260043 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8026 is 0.07305414315644476 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8027 is 0.07305377316949023 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8028 is 0.07305251965938175 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8029 is 0.07305165844037036 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8030 is 0.07305174113220995 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8031 is 0.07305041643365685 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8032 is 0.07304953132803733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8033 is 0.07304950142243778 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8034 is 0.07304825680238515 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8035 is 0.07304732797670606 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8036 is 0.073046485643182 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8037 is 0.07304627984031987 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8038 is 0.07304576842681955 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8039 is 0.07304447664741755 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8040 is 0.07304407330057433 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8041 is 0.07304357984276738 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8042 is 0.07304229155862904 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8043 is 0.07304158153501632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8044 is 0.07304157709805842 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8045 is 0.07304026330656936 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8046 is 0.0730394579351317 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8047 is 0.07303936429925945 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8048 is 0.07303807888645818 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8049 is 0.07303723264391584 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8050 is 0.07303641847339297 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8051 is 0.07303588914162108 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8052 is 0.0730358008385449 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8053 is 0.07303447262220043 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8054 is 0.0730338193522644 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8055 is 0.07303357166094915 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8056 is 0.07303235265971846 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8057 is 0.07303142933281019 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8058 is 0.07303072710880328 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8059 is 0.07303052367910788 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8060 is 0.07302931335365405 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8061 is 0.07302857234250448 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8062 is 0.07302850933422989 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8063 is 0.07302769867556852 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8064 is 0.0730264554900098 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8065 is 0.07302602203094251 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8066 is 0.07302572925142915 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8067 is 0.07302442635397073 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8068 is 0.07302391006248517 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8069 is 0.0730235463620317 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8070 is 0.07302230067041457 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8071 is 0.07302153230729638 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8072 is 0.07302078212636044 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8073 is 0.07302069565161129 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8074 is 0.073019479263022 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8075 is 0.07301868329153992 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8076 is 0.07301870736697265 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8077 is 0.07301740011400194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8078 is 0.0730165791141199 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8079 is 0.07301579260999584 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8080 is 0.07301525927940175 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8081 is 0.07301516518741545 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8082 is 0.07301383866680178 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8083 is 0.07301323150345394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8084 is 0.07301295548984212 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8085 is 0.07301174579256411 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8086 is 0.07301090770296716 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8087 is 0.07301016776323532 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8088 is 0.07301030227895303 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8089 is 0.07300896784974294 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8090 is 0.07300817303462329 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8091 is 0.07300808584524969 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8092 is 0.07300684971732545 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8093 is 0.07300602678441374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8094 is 0.0730052055552159 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8095 is 0.0730045204215808 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8096 is 0.07300420623058834 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8097 is 0.07300320712659644 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8098 is 0.07300239263860879 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8099 is 0.07300173055504998 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8100 is 0.07300139728393595 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8101 is 0.07300040361520742 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8102 is 0.07299959335519327 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8103 is 0.0729989820204967 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8104 is 0.07299877448293726 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8105 is 0.07299755854014937 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8106 is 0.07299682112055537 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8107 is 0.072996876559846 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8108 is 0.072995968714545 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8109 is 0.07299477151897107 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8110 is 0.07299401204049391 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8111 is 0.07299413609571868 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8112 is 0.07299316027111147 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8113 is 0.07299199404484064 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8114 is 0.0729912384234411 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8115 is 0.07299112234446309 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8116 is 0.07299053387482404 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8117 is 0.07298923012649858 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8118 is 0.072989087640709 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8119 is 0.0729883774879797 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8120 is 0.0729872051516965 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8121 is 0.07298642319745612 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8122 is 0.07298611465720171 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8123 is 0.07298574773731158 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8124 is 0.07298445473366001 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8125 is 0.07298365282267463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8126 is 0.07298293393169346 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8127 is 0.07298286573578806 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8128 is 0.07298164960490368 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8129 is 0.07298091032942011 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8130 is 0.07298026787924118 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8131 is 0.07298003846338272 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8132 is 0.07297890902351475 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8133 is 0.07297812202266085 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8134 is 0.07297761581371329 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8135 is 0.07297759525330115 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8136 is 0.07297630371755703 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8137 is 0.07297542105565474 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8138 is 0.07297557463531248 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8139 is 0.07297424416001592 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8140 is 0.07297348693284147 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8141 is 0.07297339091101561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8142 is 0.07297220152358154 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8143 is 0.07297147368751561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8144 is 0.07297067822139543 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8145 is 0.07296989312252834 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8146 is 0.07296953479280761 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8147 is 0.07296931414483608 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8148 is 0.07296803630192196 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8149 is 0.07296731306808217 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8150 is 0.07296734161288755 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8151 is 0.07296604353720182 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8152 is 0.07296536159976501 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8153 is 0.07296522354620502 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8154 is 0.0729640380175917 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8155 is 0.07296333177715998 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8156 is 0.07296254474612714 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8157 is 0.07296179045846887 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8158 is 0.07296185756901823 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8159 is 0.07296065034759672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8160 is 0.07295987547308433 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8161 is 0.07295918906550962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8162 is 0.0729593114741661 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8163 is 0.07295799773912827 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8164 is 0.07295729095993245 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8165 is 0.07295717510010705 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8166 is 0.07295596789387992 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8167 is 0.07295526410268624 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8168 is 0.07295448468881656 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8169 is 0.0729537855937871 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8170 is 0.0729538096365688 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8171 is 0.07295258975273174 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8172 is 0.07295183597963732 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8173 is 0.07295119350575052 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8174 is 0.0729512717859267 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8175 is 0.07294995767060669 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8176 is 0.07294930863465968 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8177 is 0.07294914131657963 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8178 is 0.07294795244593846 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8179 is 0.07294721936557308 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8180 is 0.07294649431090743 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8181 is 0.07294588757471855 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8182 is 0.07294575650908598 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8183 is 0.07294455132597168 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8184 is 0.07294384596548059 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8185 is 0.07294335906762461 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8186 is 0.07294320649946241 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8187 is 0.07294191644448417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8188 is 0.07294116804132571 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8189 is 0.07294045882844978 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8190 is 0.07294028358031211 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8191 is 0.07293981014624502 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8192 is 0.07293853367895081 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8193 is 0.07293780103072924 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8194 is 0.07293719978921527 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8195 is 0.07293703312478561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8196 is 0.07293589591326717 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8197 is 0.07293515813499062 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8198 is 0.07293466752534197 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8199 is 0.07293467795172756 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8200 is 0.07293339470460157 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8201 is 0.07293256131200887 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8202 is 0.07293272112482074 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8203 is 0.07293140719054052 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8204 is 0.07293071136862765 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8205 is 0.07293006480048528 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8206 is 0.07292999785720664 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8207 is 0.07292875755408396 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8208 is 0.07292805328236807 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8209 is 0.07292729716253023 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8210 is 0.07292671678880872 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8211 is 0.07292664504586283 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8212 is 0.07292542127657141 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8213 is 0.07292480491698018 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8214 is 0.07292475023779939 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8215 is 0.07292350653715875 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8216 is 0.07292280453617903 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8217 is 0.07292237589557374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8218 is 0.0729220133689343 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8219 is 0.0729209158566178 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8220 is 0.07292016944083739 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8221 is 0.07291945833042711 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8222 is 0.07291932181874061 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8223 is 0.07291867230689782 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8224 is 0.07291759174779311 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8225 is 0.07291684963506062 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8226 is 0.0729161313565751 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8227 is 0.07291624947770832 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8228 is 0.07291534803749625 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8229 is 0.07291428281496365 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8230 is 0.07291354458732374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8231 is 0.0729128552687179 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8232 is 0.07291281061481833 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8233 is 0.07291168049496662 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8234 is 0.07291098755945086 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8235 is 0.07291040739725194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8236 is 0.07291049305248 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8237 is 0.07290917034250069 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8238 is 0.0729083929672389 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8239 is 0.07290779529792213 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8240 is 0.07290771836968436 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8241 is 0.07290652456692863 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8242 is 0.07290582862313044 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8243 is 0.07290540814765907 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8244 is 0.07290519041082422 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8245 is 0.07290394245308972 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8246 is 0.07290324950481314 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8247 is 0.07290252320264583 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8248 is 0.07290242526195428 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8249 is 0.07290190330399342 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8250 is 0.07290068347041427 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8251 is 0.07290000728676356 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8252 is 0.0728999905093119 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8253 is 0.07289926090494528 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8254 is 0.07289817119694839 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8255 is 0.07289744526503207 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8256 is 0.07289678204519373 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8257 is 0.0728969651795359 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8258 is 0.0728960350980299 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8259 is 0.07289494397078386 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8260 is 0.07289422188971309 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8261 is 0.07289366206944967 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8262 is 0.07289336801209467 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8263 is 0.07289245126267477 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8264 is 0.07289172687756965 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8265 is 0.07289117026424817 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8266 is 0.07289134944155556 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8267 is 0.07289002220336328 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8268 is 0.07288946001421215 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8269 is 0.07288925281234937 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8270 is 0.07288809308926003 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8271 is 0.07288739238322929 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8272 is 0.07288682689848978 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8273 is 0.07288679672541078 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8274 is 0.07288557555222824 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8275 is 0.0728848860980076 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8276 is 0.07288417016839369 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8277 is 0.07288349161043287 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8278 is 0.07288340348637723 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8279 is 0.07288292264810137 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8280 is 0.0728816970630508 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8281 is 0.07288098717595518 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8282 is 0.0728804216963671 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8283 is 0.07288065204648575 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8284 is 0.0728793221686441 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8285 is 0.07287872938392938 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8286 is 0.07287855677336362 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8287 is 0.07287739016156149 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8288 is 0.07287671887560564 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8289 is 0.07287612183143687 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8290 is 0.07287605261949659 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8291 is 0.07287482993043753 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8292 is 0.07287416688213129 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8293 is 0.0728734690438091 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8294 is 0.07287276556922456 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8295 is 0.07287208615385453 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8296 is 0.07287176834896403 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8297 is 0.07287138611835353 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8298 is 0.07287022607103485 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8299 is 0.07286954310242552 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8300 is 0.07286887315607227 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8301 is 0.07286822352163444 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8302 is 0.07286820900726583 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8303 is 0.07286702767901226 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8304 is 0.07286632660144082 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8305 is 0.07286562706957649 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8306 is 0.07286494391680097 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8307 is 0.07286445042760938 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8308 is 0.07286419769014818 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8309 is 0.07286309287136568 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8310 is 0.07286243270243088 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8311 is 0.07286174491792903 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8312 is 0.07286104884770124 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8313 is 0.07286038757395225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8314 is 0.07286019595642976 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8315 is 0.07285921756461805 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8316 is 0.07285852112626322 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8317 is 0.07285785300448483 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8318 is 0.07285717101745977 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8319 is 0.07285653660324089 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8320 is 0.07285645117469433 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8321 is 0.07285537846560211 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8322 is 0.07285463824121936 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8323 is 0.07285397054115478 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8324 is 0.07285327415571487 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8325 is 0.07285278722336562 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8326 is 0.07285244285043654 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8327 is 0.07285146365392062 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8328 is 0.07285074859476667 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8329 is 0.07285009267299714 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8330 is 0.07284939368952265 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8331 is 0.07284874839068822 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8332 is 0.07284845484128163 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8333 is 0.07284756126404746 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8334 is 0.07284690110142271 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8335 is 0.07284619827979526 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8336 is 0.07284555002485431 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8337 is 0.0728448940311636 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8338 is 0.07284453203854548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8339 is 0.07284375331717843 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8340 is 0.07284306831448409 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8341 is 0.07284236384851414 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8342 is 0.07284172021665304 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8343 is 0.072841007607231 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8344 is 0.072840372587983 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8345 is 0.07283991355949884 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8346 is 0.07283959156448074 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8347 is 0.07283857288296647 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8348 is 0.07283784212513521 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8349 is 0.07283719947076929 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8350 is 0.07283650899893243 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8351 is 0.07283620778237075 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8352 is 0.0728353628042231 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8353 is 0.07283470084503535 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8354 is 0.07283402292339275 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8355 is 0.07283335294815622 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8356 is 0.07283279004173013 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8357 is 0.07283244013701337 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8358 is 0.07283165446732576 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8359 is 0.07283090116915998 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8360 is 0.07283023440655675 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8361 is 0.07282954179682154 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8362 is 0.07282890456467248 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8363 is 0.07282820168291185 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8364 is 0.07282788020432458 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8365 is 0.07282736650379797 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8366 is 0.07282642076242 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8367 is 0.07282575006133038 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8368 is 0.07282507474440371 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8369 is 0.07282447219125693 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8370 is 0.07282417568311697 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8371 is 0.07282329201237646 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8372 is 0.07282259511476212 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8373 is 0.07282194451905709 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8374 is 0.07282126833842105 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8375 is 0.07282061235403962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8376 is 0.07282019174723504 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8377 is 0.07281970457271171 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8378 is 0.07281892688670186 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8379 is 0.07281818050653246 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8380 is 0.07281750688261537 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8381 is 0.0728168330287967 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8382 is 0.07281618758325614 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8383 is 0.07281555491754059 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8384 is 0.07281520820161147 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8385 is 0.07281443600405561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8386 is 0.07281376821900523 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8387 is 0.07281306844747959 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8388 is 0.07281244439624632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8389 is 0.07281175664639651 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8390 is 0.07281112353869461 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8391 is 0.07281071781454285 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8392 is 0.0728102931157262 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8393 is 0.07280936706056143 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8394 is 0.0728086596559857 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8395 is 0.07280804458975884 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8396 is 0.07280735676441838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8397 is 0.0728070264239613 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8398 is 0.07280646828441197 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8399 is 0.07280570597988326 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8400 is 0.07280497438691652 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8401 is 0.0728043470685035 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8402 is 0.0728036564419701 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8403 is 0.07280304533334067 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8404 is 0.0728024212735551 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8405 is 0.07280220925372545 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8406 is 0.07280130098828791 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8407 is 0.07280059285508457 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8408 is 0.0727999699396251 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8409 is 0.07279929382567105 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8410 is 0.07279880396793664 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8411 is 0.07279841535982175 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8412 is 0.07279765400775315 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8413 is 0.07279692418685332 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8414 is 0.07279629787245966 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8415 is 0.07279561138821122 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8416 is 0.0727950043196973 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8417 is 0.07279432354260117 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8418 is 0.07279373697787715 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8419 is 0.07279342526513369 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8420 is 0.0727926695479093 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8421 is 0.0727919624872093 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8422 is 0.07279133422224233 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8423 is 0.07279067302528001 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8424 is 0.07279002960583139 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8425 is 0.07278947479009445 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8426 is 0.07278918736356593 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8427 is 0.07278830257457852 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8428 is 0.07278762193070468 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8429 is 0.07278700079438727 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8430 is 0.07278634128490981 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8431 is 0.07278571433943395 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8432 is 0.07278532188024693 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8433 is 0.07278484825540038 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8434 is 0.07278409239551491 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8435 is 0.07278336817200656 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8436 is 0.07278270927470663 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8437 is 0.07278206532020735 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8438 is 0.07278143382653988 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8439 is 0.07278080089827711 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8440 is 0.07278050276396975 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8441 is 0.07277975235294373 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8442 is 0.07277909608181313 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8443 is 0.07277842835995899 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8444 is 0.07277781883398053 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8445 is 0.07277714196056763 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8446 is 0.07277654015088166 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8447 is 0.07277606742744938 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8448 is 0.07277569083048632 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8449 is 0.07277492915614131 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8450 is 0.0727742024885199 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8451 is 0.07277354240378169 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8452 is 0.07277290229386339 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8453 is 0.07277227520634552 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8454 is 0.07277165713264053 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8455 is 0.0727713528545466 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8456 is 0.07277060106163283 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8457 is 0.07276995553824027 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8458 is 0.07276928370150335 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8459 is 0.0727686867174141 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8460 is 0.07276801436802335 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8461 is 0.07276740694572213 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8462 is 0.07276698240790622 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8463 is 0.07276658495639239 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8464 is 0.07276570517532224 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8465 is 0.07276501393099219 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8466 is 0.07276442275206424 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8467 is 0.07276375528931098 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8468 is 0.07276323590571364 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8469 is 0.07276288804865676 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8470 is 0.0727621446620035 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8471 is 0.07276144827053183 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8472 is 0.07276083560920951 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8473 is 0.07276018673523486 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8474 is 0.07275955740256838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8475 is 0.07275906162997796 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8476 is 0.07275872680914507 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8477 is 0.07275797198896665 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8478 is 0.07275725218573989 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8479 is 0.07275663409773886 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8480 is 0.0727559668671504 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8481 is 0.07275537812703314 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8482 is 0.07275472071091652 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8483 is 0.07275455455003112 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8484 is 0.07275369252114061 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8485 is 0.07275300264832739 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8486 is 0.07275236654799881 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8487 is 0.07275167154450779 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8488 is 0.07275140499138498 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8489 is 0.07275063951978548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8490 is 0.07274968498644145 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8491 is 0.0727489060247606 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8492 is 0.07274871244063692 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8493 is 0.07274774840003125 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8494 is 0.07274697696941418 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8495 is 0.07274645838481367 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8496 is 0.07274606117479025 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8497 is 0.07274511299499112 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8498 is 0.07274426553569642 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8499 is 0.07274374092184871 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8500 is 0.0727433124542608 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8501 is 0.0727423976701763 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8502 is 0.07274164668001955 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8503 is 0.07274119433784673 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8504 is 0.07274076360446198 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8505 is 0.07273984005881387 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8506 is 0.07273897934644481 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8507 is 0.07273847184470618 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8508 is 0.07273807396704011 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8509 is 0.07273717224134826 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8510 is 0.0727363927020838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8511 is 0.07273588733408644 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8512 is 0.0727355605659918 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8513 is 0.07273464537282309 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8514 is 0.07273378812972416 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8515 is 0.07273341344409877 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8516 is 0.07273291078574781 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8517 is 0.0727320103029292 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8518 is 0.07273118753465727 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8519 is 0.07273063684228613 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8520 is 0.072730278567747 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8521 is 0.07272938974117163 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8522 is 0.07272863613214199 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8523 is 0.07272807668144135 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8524 is 0.07272780378550733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8525 is 0.07272689752743787 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8526 is 0.07272604817967536 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8527 is 0.072725624008469 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8528 is 0.07272518489991263 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8529 is 0.0727242912372383 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8530 is 0.07272348943142068 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8531 is 0.07272285813929026 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8532 is 0.07272257913468394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8533 is 0.07272169603372623 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8534 is 0.07272096407966712 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8535 is 0.07272034130539855 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8536 is 0.07272012898043098 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8537 is 0.07271922789870004 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8538 is 0.07271838365910409 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8539 is 0.07271791771136128 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8540 is 0.072717532759988 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8541 is 0.07271664395804296 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8542 is 0.07271586696737434 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8543 is 0.07271516029792785 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8544 is 0.07271494831214972 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8545 is 0.07271407372421881 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8546 is 0.07271335295147004 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8547 is 0.07271272198749529 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8548 is 0.07271250873871551 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8549 is 0.07271161574361464 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8550 is 0.07271079883052814 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8551 is 0.07271008274254014 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8552 is 0.07270991142501354 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8553 is 0.07270924461915007 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8554 is 0.07270837150929885 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8555 is 0.07270755974116486 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8556 is 0.07270717565387565 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8557 is 0.07270670076562559 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8558 is 0.07270583186568236 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8559 is 0.07270508520413049 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8560 is 0.07270466339301013 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8561 is 0.072704302046612 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8562 is 0.07270341271873187 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8563 is 0.07270257974599463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8564 is 0.07270228154771904 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8565 is 0.07270175199923784 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8566 is 0.07270087380284786 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8567 is 0.07270008381583457 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8568 is 0.07269959156438689 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8569 is 0.07269921166967967 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8570 is 0.07269834335023613 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8571 is 0.07269762769734354 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8572 is 0.07269714489626099 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8573 is 0.0726968267762597 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8574 is 0.07269593998970719 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8575 is 0.07269511031827139 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8576 is 0.0726945582842168 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8577 is 0.07269427986565052 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8578 is 0.07269340987881877 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8579 is 0.07269266510645063 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8580 is 0.07269211506187377 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8581 is 0.07269190060426427 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8582 is 0.07269101454764787 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8583 is 0.07269018622215996 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8584 is 0.07268978686519686 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8585 is 0.07268937500674783 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8586 is 0.07268850215000362 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8587 is 0.0726877293719426 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8588 is 0.07268712851830152 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8589 is 0.07268686221092314 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8590 is 0.07268600002937636 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8591 is 0.07268530577682812 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8592 is 0.07268473208615338 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8593 is 0.07268450668803066 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8594 is 0.07268362626330184 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8595 is 0.07268282095099733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8596 is 0.07268216174551738 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8597 is 0.07268198812430035 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8598 is 0.07268112456889149 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8599 is 0.07268040699042523 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8600 is 0.07267976972184194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8601 is 0.07267963788965158 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8602 is 0.07267875824957946 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8603 is 0.07267793649460626 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8604 is 0.07267747294225516 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8605 is 0.07267714027307579 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8606 is 0.07267627384613144 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8607 is 0.07267553305661457 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8608 is 0.07267482733492209 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8609 is 0.07267479266365967 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8610 is 0.07267391317520179 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8611 is 0.07267309239086851 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8612 is 0.07267255240204229 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8613 is 0.07267230168491338 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8614 is 0.07267143672323183 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8615 is 0.07267068065792946 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8616 is 0.07266995729079562 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8617 is 0.07266984943348681 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8618 is 0.07266917053937486 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8619 is 0.07266832150992385 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8620 is 0.0726675754336116 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8621 is 0.0726671647116371 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8622 is 0.07266672511034489 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8623 is 0.07266588040353 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8624 is 0.07266519590601962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8625 is 0.07266482244490476 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8626 is 0.0726644137206407 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8627 is 0.07266355039040892 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8628 is 0.07266276834318837 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8629 is 0.07266225676738818 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8630 is 0.07266195066715958 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8631 is 0.07266110042986854 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8632 is 0.07266040405658494 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8633 is 0.07265990138605957 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8634 is 0.07265964991182741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8635 is 0.07265878209415313 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8636 is 0.07265797920205748 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8637 is 0.07265739537117345 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8638 is 0.07265716781005717 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8639 is 0.07265618969674004 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8640 is 0.07265537308164877 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8641 is 0.07265465562140162 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8642 is 0.07265441973515446 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8643 is 0.07265347060441495 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8644 is 0.07265259046129184 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8645 is 0.07265184645505024 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8646 is 0.07265162674559517 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8647 is 0.0726507129132055 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8648 is 0.07264985768899607 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8649 is 0.07264914257784275 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8650 is 0.07264842075727804 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8651 is 0.07264820161044767 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8652 is 0.07264731150428642 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8653 is 0.07264647370218225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8654 is 0.07264570556328946 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8655 is 0.07264498947155322 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8656 is 0.0726447208208302 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8657 is 0.07264386318356018 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8658 is 0.07264307954993181 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8659 is 0.07264235085828402 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8660 is 0.07264171232200305 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8661 is 0.07264142512399561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8662 is 0.0726405627989771 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8663 is 0.07263974604151084 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8664 is 0.07263900375236407 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8665 is 0.07263827620437581 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8666 is 0.07263794864517618 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8667 is 0.07263735598457598 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8668 is 0.07263651115187834 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8669 is 0.07263570728430145 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8670 is 0.07263496632504753 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8671 is 0.07263440288444918 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8672 is 0.07263400502074224 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8673 is 0.07263316977135004 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8674 is 0.07263239517534996 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8675 is 0.0726316919018536 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8676 is 0.0726311263399768 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8677 is 0.07263079063246242 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8678 is 0.0726299434203812 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8679 is 0.07262914038685254 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8680 is 0.07262839785243475 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8681 is 0.072627695701349 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8682 is 0.07262741465424538 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8683 is 0.07262679879722976 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8684 is 0.07262596551270366 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8685 is 0.07262517282248458 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8686 is 0.07262443214732245 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8687 is 0.0726239350965443 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8688 is 0.07262350417699741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8689 is 0.07262267932911563 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8690 is 0.07262190703890935 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8691 is 0.07262122266388552 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8692 is 0.07262070653378229 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8693 is 0.07262034354455096 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8694 is 0.07261950578526931 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8695 is 0.07261871221560164 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8696 is 0.07261797656327172 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8697 is 0.07261732512182294 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8698 is 0.07261705942515369 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8699 is 0.07261623657708391 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8700 is 0.07261547766710284 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8701 is 0.07261478810750539 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8702 is 0.07261416123628142 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8703 is 0.07261392425561698 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8704 is 0.07261308977416306 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8705 is 0.07261230030065838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8706 is 0.07261158704071696 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8707 is 0.07261089077255674 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8708 is 0.07261055937782217 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8709 is 0.07261003102885828 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8710 is 0.07260920905077532 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8711 is 0.07260843203778339 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8712 is 0.0726077290153794 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8713 is 0.07260715183125298 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8714 is 0.07260681365593956 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8715 is 0.07260600317500378 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8716 is 0.07260527488545172 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8717 is 0.07260457776029389 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8718 is 0.07260404194821898 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8719 is 0.07260373176748891 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8720 is 0.07260290810387195 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8721 is 0.07260212861302752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8722 is 0.0726014503533394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8723 is 0.07260073425008702 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8724 is 0.07260051266050269 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8725 is 0.07259989028086193 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8726 is 0.07259907958071529 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8727 is 0.07259830946616244 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8728 is 0.0725976507931867 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8729 is 0.07259711540158165 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8730 is 0.07259671429964473 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8731 is 0.07259591130236762 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8732 is 0.07259523249742167 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8733 is 0.07259450764275938 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8734 is 0.07259386000116218 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8735 is 0.07259360318828846 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8736 is 0.07259302973679796 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8737 is 0.07259221767040382 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8738 is 0.07259144851795835 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8739 is 0.0725907700086885 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8740 is 0.07259062565468145 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8741 is 0.07258980153973024 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8742 is 0.07258902515514898 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8743 is 0.07258833749996345 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8744 is 0.07258764481570668 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8745 is 0.0725873706219561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8746 is 0.0725868221807007 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8747 is 0.07258601801749964 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8748 is 0.07258525531951408 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8749 is 0.07258459977767805 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8750 is 0.07258404534426664 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8751 is 0.07258368811503285 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8752 is 0.0725828930487 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8753 is 0.07258222209524133 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8754 is 0.07258150770117541 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8755 is 0.07258086911343722 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8756 is 0.07258059558424373 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8757 is 0.07258005793795233 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8758 is 0.07257925411889257 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8759 is 0.07257849336040446 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8760 is 0.07257780133778167 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8761 is 0.07257768920492369 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8762 is 0.07257687331359775 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8763 is 0.07257610533883871 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8764 is 0.07257543551796933 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8765 is 0.07257474302459574 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8766 is 0.07257445994033944 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8767 is 0.072573938859553 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8768 is 0.07257314300909204 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8769 is 0.07257238873905593 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8770 is 0.07257175571250428 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8771 is 0.07257117594591894 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8772 is 0.0725709716991931 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8773 is 0.07257016384921977 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8774 is 0.07256940259778799 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8775 is 0.07256870846697384 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8776 is 0.07256805161008421 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8777 is 0.07256783565217768 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8778 is 0.07256725579155113 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8779 is 0.07256646513250706 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8780 is 0.07256572015589252 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8781 is 0.0725650688921273 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8782 is 0.07256459018054383 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8783 is 0.07256421155098876 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8784 is 0.07256343685488538 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8785 is 0.07256276845401753 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8786 is 0.0725620837345016 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8787 is 0.07256167672037675 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8788 is 0.07256131109810131 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8789 is 0.07256052084333678 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8790 is 0.07255978341436355 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8791 is 0.07255915559601779 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8792 is 0.07255855041877919 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8793 is 0.07255838843892187 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8794 is 0.0725575937958945 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8795 is 0.07255684526173117 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8796 is 0.0725561914527873 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8797 is 0.0725555198508708 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8798 is 0.07255530009408748 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8799 is 0.07255475210251579 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8800 is 0.07255397336886403 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8801 is 0.0725532358560444 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8802 is 0.07255262273375912 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8803 is 0.07255210868352316 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8804 is 0.07255187318765116 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8805 is 0.0725510813882489 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8806 is 0.07255033622280095 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8807 is 0.07254966743600912 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8808 is 0.07254905707575454 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8809 is 0.07254884984531079 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8810 is 0.07254807623732436 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8811 is 0.07254740842943228 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8812 is 0.07254673484623363 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8813 is 0.07254622971492088 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8814 is 0.07254598225678578 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8815 is 0.07254519789814683 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8816 is 0.07254447309916408 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8817 is 0.07254384873736272 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8818 is 0.07254318855580877 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8819 is 0.0725427464323729 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8820 is 0.07254237887157101 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8821 is 0.07254161483754877 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8822 is 0.07254094591593183 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8823 is 0.07254028681630412 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8824 is 0.07253989195192931 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8825 is 0.07253954117744728 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8826 is 0.07253876262791573 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8827 is 0.0725380323076326 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8828 is 0.07253742342142892 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8829 is 0.07253683187100651 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8830 is 0.07253668250165195 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8831 is 0.07253589999209564 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8832 is 0.07253516386574355 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8833 is 0.07253452447018115 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8834 is 0.07253386493338375 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8835 is 0.0725336545405752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8836 is 0.07253312283296863 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8837 is 0.07253235638519984 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8838 is 0.07253163272830465 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8839 is 0.07253103241726666 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8840 is 0.07253055189254433 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8841 is 0.07253029769286695 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8842 is 0.07252952151536704 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8843 is 0.07252879078074576 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8844 is 0.07252815018984254 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8845 is 0.07252751767808159 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8846 is 0.07252734218511901 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8847 is 0.07252658158442861 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8848 is 0.07252594323719001 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8849 is 0.0725252728775957 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8850 is 0.07252467516264785 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8851 is 0.07252432431148606 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8852 is 0.07252394562140423 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8853 is 0.07252317774182258 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8854 is 0.07252245353725864 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8855 is 0.07252181607526369 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8856 is 0.07252127440615855 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8857 is 0.07252101625962985 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8858 is 0.0725202605156368 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8859 is 0.07251962469290017 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8860 is 0.07251896370839982 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8861 is 0.07251838111661892 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8862 is 0.07251808464883021 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8863 is 0.07251766867053981 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8864 is 0.0725169112632165 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8865 is 0.07251619645247846 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8866 is 0.0725155597384854 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8867 is 0.0725150773101977 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8868 is 0.07251478569407016 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8869 is 0.07251403822723959 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8870 is 0.07251340178624217 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8871 is 0.07251274765098775 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8872 is 0.07251235125281992 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8873 is 0.07251204341639222 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8874 is 0.07251128246964514 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8875 is 0.07251059282360119 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8876 is 0.0725099813159836 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8877 is 0.07250940103031561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8878 is 0.07250928139221569 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8879 is 0.07250851669533463 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8880 is 0.07250779862389123 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8881 is 0.07250720892416707 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8882 is 0.07250655698533369 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8883 is 0.07250609451371685 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8884 is 0.07250582458620364 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8885 is 0.07250508004211714 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8886 is 0.07250441878015428 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8887 is 0.07250379737518654 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8888 is 0.0725033678660904 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8889 is 0.0725031023163695 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8890 is 0.07250234502968504 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8891 is 0.07250163405638899 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8892 is 0.07250105243730114 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8893 is 0.07250044163558184 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8894 is 0.07250036154868553 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8895 is 0.07249960081462417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8896 is 0.07249888685124319 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8897 is 0.07249827890977698 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8898 is 0.07249763497753801 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8899 is 0.07249741861214204 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8900 is 0.07249694221329024 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8901 is 0.07249619762952314 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8902 is 0.07249551372743705 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8903 is 0.07249492017602968 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8904 is 0.07249443982693073 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8905 is 0.07249423422348374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8906 is 0.07249347969534489 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8907 is 0.07249277084096137 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8908 is 0.07249218031029628 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8909 is 0.07249153691782748 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8910 is 0.07249115854647147 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8911 is 0.07249082809901228 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8912 is 0.07249009147837736 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8913 is 0.07248942947224565 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8914 is 0.07248882474201492 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8915 is 0.07248844624805381 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8916 is 0.07248814388101162 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8917 is 0.07248739395751085 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8918 is 0.07248668914036704 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8919 is 0.0724861157726148 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8920 is 0.07248551283999394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8921 is 0.07248544941591085 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8922 is 0.07248469211240519 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8923 is 0.07248398295400361 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8924 is 0.07248337379419659 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8925 is 0.07248274378174559 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8926 is 0.07248254601453993 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8927 is 0.07248206509345545 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8928 is 0.07248132644868374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8929 is 0.07248064538666728 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8930 is 0.07248006253600114 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8931 is 0.07247959979026893 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8932 is 0.0724793902338613 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8933 is 0.07247864202384754 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8934 is 0.07247793967043506 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8935 is 0.07247735551258105 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8936 is 0.0724767197736587 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8937 is 0.07247635357960411 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8938 is 0.0724760242394814 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8939 is 0.07247529405392407 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8940 is 0.07247464057500883 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8941 is 0.07247404105898342 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8942 is 0.07247366975625384 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8943 is 0.0724733735249307 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8944 is 0.07247262993695106 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8945 is 0.07247193155541061 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8946 is 0.07247136949389568 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8947 is 0.07247076392076261 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8948 is 0.07247071216890277 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8949 is 0.07246996110049803 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8950 is 0.07246925828201058 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8951 is 0.07246866249492093 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8952 is 0.07246803252698016 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8953 is 0.07246783107551437 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8954 is 0.07246755998796275 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8955 is 0.07246666552743468 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8956 is 0.07246615563097235 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8957 is 0.07246586608797581 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8958 is 0.07246513127354741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8959 is 0.07246451612580172 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8960 is 0.07246388223408305 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8961 is 0.07246333097468954 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8962 is 0.07246280134196649 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8963 is 0.07246267563760733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8964 is 0.07246193852977394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8965 is 0.07246124749238879 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8966 is 0.0724606383013221 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8967 is 0.07246003849287162 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8968 is 0.07245978991536006 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8969 is 0.07245937670676575 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8970 is 0.0724586531124508 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8971 is 0.07245797086908018 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8972 is 0.0724574090213708 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8973 is 0.07245679966692392 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8974 is 0.07245677151914656 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8975 is 0.07245603311664107 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8976 is 0.07245534159432118 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8977 is 0.07245473066786699 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8978 is 0.07245413430623002 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8979 is 0.07245383415301859 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8980 is 0.07245356720494461 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8981 is 0.07245279626455749 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8982 is 0.07245215056391073 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8983 is 0.07245160664742431 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8984 is 0.07245138289413929 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8985 is 0.0724506704472964 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8986 is 0.0724500861377911 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8987 is 0.07244945926152048 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8988 is 0.07244890371987138 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8989 is 0.07244854015257471 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8990 is 0.07244827335193492 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8991 is 0.07244754551268662 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8992 is 0.07244686299728495 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8993 is 0.07244624678785591 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8994 is 0.07244566902033493 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8995 is 0.07244544507100129 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8996 is 0.07244501734279832 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8997 is 0.07244430117619813 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8998 is 0.07244362620358548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 8999 is 0.07244305172336099 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9000 is 0.07244246550351513 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9001 is 0.07244231595505063 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9002 is 0.07244160575954721 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9003 is 0.07244102551435003 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9004 is 0.07244040321544086 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9005 is 0.07243984635537672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9006 is 0.07243944760464585 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9007 is 0.07243971343068664 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9008 is 0.07243851536522096 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9009 is 0.07243787519641867 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9010 is 0.07243731307687953 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9011 is 0.07243715002420799 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9012 is 0.07243643654380783 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9013 is 0.07243581594108897 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9014 is 0.07243523666052616 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9015 is 0.07243464541551596 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9016 is 0.0724340889491424 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9017 is 0.07243391319295077 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9018 is 0.07243346749073497 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9019 is 0.07243274959396716 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9020 is 0.0724320755226562 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9021 is 0.07243145447386651 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9022 is 0.07243091054281 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9023 is 0.07243074565985008 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9024 is 0.07243043735805682 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9025 is 0.07242958617371885 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9026 is 0.07242901070292629 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9027 is 0.0724289017614376 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9028 is 0.07242817217784427 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9029 is 0.07242750331064046 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9030 is 0.072426898134947 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9031 is 0.07242634883088381 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9032 is 0.07242578689141438 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9033 is 0.07242561798533068 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9034 is 0.07242491427990337 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9035 is 0.07242433012440501 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9036 is 0.07242372966607522 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9037 is 0.07242318418666022 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9038 is 0.07242259058985824 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9039 is 0.0724223824956204 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9040 is 0.07242200608047154 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9041 is 0.07242129884017054 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9042 is 0.07242063647360354 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9043 is 0.07242004678391546 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9044 is 0.07241947767576931 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9045 is 0.07241933801381759 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9046 is 0.07241938306028198 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9047 is 0.0724182242423525 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9048 is 0.0724176181317962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9049 is 0.07241752453368111 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9050 is 0.07241680618513607 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9051 is 0.07241614848675951 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9052 is 0.07241558816592267 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9053 is 0.07241501424006144 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9054 is 0.07241445870847028 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9055 is 0.07241443110662735 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9056 is 0.07241371613226866 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9057 is 0.07241304866965663 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9058 is 0.07241246118077665 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9059 is 0.07241190365470111 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9060 is 0.07241144302391057 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9061 is 0.0724113438465489 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9062 is 0.07241064645581245 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9063 is 0.07241002088156472 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9064 is 0.0724094562143235 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9065 is 0.07240914499877998 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9066 is 0.07240884354306966 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9067 is 0.07240813911074467 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9068 is 0.07240749263291263 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9069 is 0.07240688638998567 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9070 is 0.07240638439252198 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9071 is 0.07240629443928553 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9072 is 0.07240558581285673 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9073 is 0.072404925558952 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9074 is 0.07240437854537272 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9075 is 0.07240380162345474 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9076 is 0.07240324673747217 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9077 is 0.07240280620930775 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9078 is 0.07240259179399569 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9079 is 0.0724019034001714 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9080 is 0.07240128414603916 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9081 is 0.07240072923406424 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9082 is 0.07240020969257253 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9083 is 0.07240074707085296 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9084 is 0.07239948852014168 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9085 is 0.07239886748672063 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9086 is 0.07239828692081736 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9087 is 0.07239796809157323 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9088 is 0.0723976884009928 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9089 is 0.0723969854935995 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9090 is 0.0723963376035445 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9091 is 0.07239575366776332 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9092 is 0.07239522097659411 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9093 is 0.07239478882207653 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9094 is 0.0723945264963891 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9095 is 0.07239384130825649 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9096 is 0.07239327094235232 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9097 is 0.07239268911000038 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9098 is 0.07239215595480927 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9099 is 0.07239166726811114 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9100 is 0.07239164986287148 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9101 is 0.07239098782799255 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9102 is 0.07239036865425795 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9103 is 0.07239016856605973 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9104 is 0.07238947465510805 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9105 is 0.07238889652981606 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9106 is 0.07238832482753116 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9107 is 0.07238776401409433 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9108 is 0.07238721242086736 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9109 is 0.07238673316110032 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9110 is 0.0723866452005403 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9111 is 0.07238594099269267 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9112 is 0.07238528392984026 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9113 is 0.0723846910910133 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9114 is 0.07238415872983363 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9115 is 0.0723837473772279 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9116 is 0.07238384544597244 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9117 is 0.07238291840083057 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9118 is 0.07238230156825866 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9119 is 0.07238176619505225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9120 is 0.07238148818498095 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9121 is 0.07238104781815964 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9122 is 0.07238038555338577 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9123 is 0.07237981631868674 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9124 is 0.07237926247875631 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9125 is 0.07237869541803858 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9126 is 0.07237824442974722 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9127 is 0.07237808332749997 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9128 is 0.07237739385941894 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9129 is 0.07237674793808496 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9130 is 0.07237623718701422 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9131 is 0.07237564752159914 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9132 is 0.07237543379614679 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9133 is 0.07237530620451856 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9134 is 0.07237447689545785 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9135 is 0.07237386240901048 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9136 is 0.07237332271949741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9137 is 0.07237316207020386 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9138 is 0.07237248269602885 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9139 is 0.07237189864920412 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9140 is 0.07237135349922436 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9141 is 0.07237077962491363 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9142 is 0.07237025643087902 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9143 is 0.07236999525685624 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9144 is 0.07236957768552858 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9145 is 0.07236890258955285 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9146 is 0.07236833385071906 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9147 is 0.07236776849816609 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9148 is 0.07236732795097825 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9149 is 0.07236743541769049 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9150 is 0.07236658252375594 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9151 is 0.0723659705040971 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9152 is 0.07236538940423555 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9153 is 0.07236513831614448 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9154 is 0.07236480964117878 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9155 is 0.07236411654301916 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9156 is 0.07236347957836486 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9157 is 0.07236291266186211 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9158 is 0.07236238302491481 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9159 is 0.07236199764710594 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9160 is 0.07236183575318858 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9161 is 0.07236113948472461 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9162 is 0.0723604904261726 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9163 is 0.07235988363341768 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9164 is 0.07235938101651379 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9165 is 0.07235904394891528 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9166 is 0.07235912277202254 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9167 is 0.07235814387283476 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9168 is 0.07235753389512507 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9169 is 0.0723570284536685 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9170 is 0.07235692768198225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9171 is 0.07235624544202643 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9172 is 0.07235563414080838 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9173 is 0.07235508391713678 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9174 is 0.07235454213592603 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9175 is 0.07235407616264154 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9176 is 0.07235399751269163 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9177 is 0.07235330374925072 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9178 is 0.07235265721235075 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9179 is 0.07235206738918441 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9180 is 0.0723515526047419 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9181 is 0.0723511320375581 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9182 is 0.07235122160537115 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9183 is 0.07235033742497625 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9184 is 0.07234972934427239 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9185 is 0.0723492119618194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9186 is 0.07234892085182158 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9187 is 0.07234851900714503 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9188 is 0.07234786066446945 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9189 is 0.07234729062384745 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9190 is 0.07234675649862764 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9191 is 0.07234618815458072 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9192 is 0.07234572781146449 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9193 is 0.07234561329150799 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9194 is 0.07234493322829465 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9195 is 0.07234429632028748 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9196 is 0.07234378841756711 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9197 is 0.07234320281217833 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9198 is 0.07234301276275801 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9199 is 0.07234287737993791 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9200 is 0.07234206901256653 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9201 is 0.07234146295999873 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9202 is 0.0723409179941744 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9203 is 0.07234078595173236 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9204 is 0.0723401130799105 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9205 is 0.07233953535918027 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9206 is 0.0723390030292935 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9207 is 0.07233843460823436 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9208 is 0.07233792502134674 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9209 is 0.07233764719827378 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9210 is 0.07233727002859787 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9211 is 0.07233660455401156 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9212 is 0.07233603543330233 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9213 is 0.0723354742271715 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9214 is 0.07233507306166642 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9215 is 0.07233519047254929 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9216 is 0.07233433368459506 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9217 is 0.07233373003220682 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9218 is 0.07233315305222962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9219 is 0.07233290348136757 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9220 is 0.07233259430979125 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9221 is 0.0723319113513371 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9222 is 0.07233128222894825 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9223 is 0.07233072591448918 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9224 is 0.0723302043535744 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9225 is 0.07232980249716219 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9226 is 0.07232967938500344 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9227 is 0.07232899247451688 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9228 is 0.072328352908072 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9229 is 0.072327749942199 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9230 is 0.07232726228968354 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9231 is 0.0723268947644243 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9232 is 0.07232717973646206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9233 is 0.07232604878980864 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9234 is 0.07232544766419963 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9235 is 0.07232495463468054 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9236 is 0.07232473480060049 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9237 is 0.07232428215705176 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9238 is 0.07232362467027156 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9239 is 0.07232304335979733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9240 is 0.07232253389049573 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9241 is 0.07232195886096394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9242 is 0.07232182002564723 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9243 is 0.07232143044071725 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9244 is 0.07232075245491276 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9245 is 0.07232011949033004 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9246 is 0.07231958772864326 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9247 is 0.0723190373533531 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9248 is 0.07231887591787015 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9249 is 0.07231901636489158 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9250 is 0.07231789683455614 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9251 is 0.07231729717923244 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9252 is 0.07231683448033142 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9253 is 0.07231666494335662 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9254 is 0.07231599421358409 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9255 is 0.07231540703061784 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9256 is 0.07231488558703698 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9257 is 0.07231432030732252 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9258 is 0.07231382336300672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9259 is 0.07231364569917524 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9260 is 0.07231318526961265 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9261 is 0.07231252757761417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9262 is 0.07231195727894428 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9263 is 0.0723114121352494 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9264 is 0.07231108909180452 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9265 is 0.07231138553748165 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9266 is 0.07231028168484122 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9267 is 0.07230968405818111 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9268 is 0.0723091250621302 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9269 is 0.07230894685564206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9270 is 0.0723085848282309 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9271 is 0.0723079080505421 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9272 is 0.07230728195384761 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9273 is 0.07230672005542607 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9274 is 0.07230621918581291 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9275 is 0.07230589341637832 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9276 is 0.07230559029419188 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9277 is 0.07230492995617208 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9278 is 0.0723043694918555 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9279 is 0.07230381787015909 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9280 is 0.07230337674570177 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9281 is 0.07230379539798851 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9282 is 0.07230270725150167 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9283 is 0.07230211196629574 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9284 is 0.07230154749006633 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9285 is 0.07230125228368334 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9286 is 0.07230101248898785 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9287 is 0.07230035141319587 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9288 is 0.07229974339873979 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9289 is 0.07229920066348443 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9290 is 0.07229870369113485 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9291 is 0.07229829425976778 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9292 is 0.07229824030319934 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9293 is 0.07229757171448285 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9294 is 0.0722969487796927 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9295 is 0.07229636991444494 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9296 is 0.07229587817495091 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9297 is 0.07229570886057009 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9298 is 0.07229592142596933 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9299 is 0.0722947645940419 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9300 is 0.07229420368952608 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9301 is 0.0722942173782888 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9302 is 0.07229353793758043 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9303 is 0.0722929170496911 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9304 is 0.07229238961559092 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9305 is 0.07229187166199784 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9306 is 0.07229148933088382 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9307 is 0.07229141217147793 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9308 is 0.07229073774068194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9309 is 0.0722901120813813 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9310 is 0.07228957308295747 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9311 is 0.07228905686163904 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9312 is 0.07228891086509247 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9313 is 0.0722887585861106 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9314 is 0.07228797297679257 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9315 is 0.07228743627519268 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9316 is 0.07228740511694395 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9317 is 0.07228672517133385 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9318 is 0.07228611251867811 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9319 is 0.07228561044567677 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9320 is 0.07228507086045945 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9321 is 0.07228474722553693 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9322 is 0.07228460773461581 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9323 is 0.07228393489499318 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9324 is 0.07228331119681002 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9325 is 0.0722828055357764 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9326 is 0.07228226253720908 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9327 is 0.07228210666850829 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9328 is 0.07228181488660217 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9329 is 0.07228114547279778 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9330 is 0.07228052379470148 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9331 is 0.07228001324841164 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9332 is 0.07227953613662445 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9333 is 0.07227986880725638 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9334 is 0.07227899084679826 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9335 is 0.07227847327746649 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9336 is 0.07227828592492805 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9337 is 0.07227761575253021 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9338 is 0.07227710792350196 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9339 is 0.07227654331689304 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9340 is 0.07227606372867106 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9341 is 0.07227551156324294 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9342 is 0.07227538063530883 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9343 is 0.07227506215398376 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9344 is 0.07227439310945984 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9345 is 0.07227377274113259 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9346 is 0.07227328080946553 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9347 is 0.07227280570812215 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9348 is 0.07227278978965336 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9349 is 0.07227226573398948 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9350 is 0.07227176361192723 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9351 is 0.07227154848332974 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9352 is 0.07227088617020185 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9353 is 0.07227038807080892 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9354 is 0.07226981765236537 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9355 is 0.07226934317384597 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9356 is 0.07226878468326692 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9357 is 0.07226870244651543 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9358 is 0.07226833051523919 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9359 is 0.07226766657240824 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9360 is 0.07226705025923062 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9361 is 0.07226657400376875 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9362 is 0.07226610166991715 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9363 is 0.07226601529759591 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9364 is 0.07226535705140849 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9365 is 0.07226483544823388 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9366 is 0.07226428336834698 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9367 is 0.07226379237666185 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9368 is 0.0722636749002119 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9369 is 0.07226418796784344 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9370 is 0.07226270659721287 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9371 is 0.07226223916434286 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9372 is 0.07226217000742065 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9373 is 0.07226149342495337 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9374 is 0.07226088389944639 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9375 is 0.07226038690193816 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9376 is 0.07225985645062072 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9377 is 0.07225962844095679 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9378 is 0.07225941288709935 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9379 is 0.07225874579779164 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9380 is 0.07225812844157685 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9381 is 0.07225762966333055 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9382 is 0.07225710290020561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9383 is 0.07225727682739912 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9384 is 0.07225661327809445 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9385 is 0.07225604545787657 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9386 is 0.07225560307377757 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9387 is 0.07225549842921246 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9388 is 0.072254825620977 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9389 is 0.07225422506906576 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9390 is 0.07225373325981012 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9391 is 0.07225320204585017 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9392 is 0.0722529864396406 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9393 is 0.07225275644183075 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9394 is 0.07225209153064262 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9395 is 0.07225147787083942 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9396 is 0.07225097511849994 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9397 is 0.07225045991820615 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9398 is 0.07225035513505285 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9399 is 0.07225024318961915 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9400 is 0.07224940188637793 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9401 is 0.07224893334148823 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9402 is 0.07224887319796584 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9403 is 0.07224820091652087 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9404 is 0.07224761232773824 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9405 is 0.07224708706830085 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9406 is 0.07224658755677499 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9407 is 0.07224629205843922 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9408 is 0.07224615035053307 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9409 is 0.07224548437215988 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9410 is 0.0722448690993527 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9411 is 0.07224434893388182 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9412 is 0.0722438439358861 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9413 is 0.07224374423503384 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9414 is 0.07224341879729808 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9415 is 0.07224275851682345 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9416 is 0.0722421466536693 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9417 is 0.0722416222763748 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9418 is 0.07224125985706592 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9419 is 0.07224148977303053 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9420 is 0.07224062584055051 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9421 is 0.0722401964696871 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9422 is 0.07223997359903701 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9423 is 0.0722393175562442 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9424 is 0.07223878652483472 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9425 is 0.07223826590648254 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9426 is 0.07223776270144079 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9427 is 0.07223726187428246 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9428 is 0.07223725907081335 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9429 is 0.07223660441978193 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9430 is 0.07223604887697194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9431 is 0.07223554213350762 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9432 is 0.07223508223919248 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9433 is 0.07223523018659074 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9434 is 0.07223449485654548 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9435 is 0.07223393297991132 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9436 is 0.0722333989457853 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9437 is 0.07223330471334868 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9438 is 0.0722329399352428 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9439 is 0.07223228517716763 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9440 is 0.07223170825109053 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9441 is 0.07223118533515878 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9442 is 0.07223069824786434 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9443 is 0.07223060834213688 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9444 is 0.0722302718526885 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9445 is 0.07222961250189423 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9446 is 0.07222900281105182 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9447 is 0.07222847469280821 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9448 is 0.0722281597968555 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9449 is 0.07222800162141138 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9450 is 0.07222735095736522 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9451 is 0.07222677652608005 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9452 is 0.07222627789397078 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9453 is 0.07222603808139309 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9454 is 0.07222640268351699 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9455 is 0.07222523642862534 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9456 is 0.0722246775179807 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9457 is 0.07222430236734721 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9458 is 0.07222412589371205 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9459 is 0.07222348723758934 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9460 is 0.07222296035273326 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9461 is 0.07222245361869353 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9462 is 0.07222200412704641 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9463 is 0.07222203951927912 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9464 is 0.07222136874034343 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9465 is 0.07222075254998384 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9466 is 0.07222025874453505 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9467 is 0.0722197343531823 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9468 is 0.07221958165252788 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9469 is 0.07221946743256065 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9470 is 0.07221871113284714 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9471 is 0.07221818408436453 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9472 is 0.07221818452230667 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9473 is 0.07221752271678658 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9474 is 0.07221694097660979 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9475 is 0.07221643757878365 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9476 is 0.07221593080652661 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9477 is 0.07221561548198431 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9478 is 0.07221550937381475 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9479 is 0.07221484966720804 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9480 is 0.07221424541934951 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9481 is 0.07221373721959154 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9482 is 0.07221324418436495 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9483 is 0.0722130829747978 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9484 is 0.07221284083367369 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9485 is 0.07221218396659092 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9486 is 0.07221157685004935 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9487 is 0.07221105859175221 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9488 is 0.07221067312530127 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9489 is 0.07221082217155804 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9490 is 0.07221008017765095 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9491 is 0.07220963940772489 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9492 is 0.07220944899589152 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9493 is 0.07220880081242256 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9494 is 0.07220827450809467 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9495 is 0.0722077628024222 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9496 is 0.07220726480480376 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9497 is 0.07220678010644378 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9498 is 0.07220678016712553 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9499 is 0.07220613158159596 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9500 is 0.07220558380346044 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9501 is 0.07220508427711203 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9502 is 0.07220458747119703 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9503 is 0.07220469555435263 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9504 is 0.07220402817124352 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9505 is 0.07220341498168018 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9506 is 0.07220291467686397 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9507 is 0.0722023968395654 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9508 is 0.07220228890359177 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9509 is 0.07220260037278475 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9510 is 0.07220138865478283 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9511 is 0.07220088647588506 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9512 is 0.07220085899217266 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9513 is 0.07220019773203827 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9514 is 0.07219962054899058 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9515 is 0.07219914077107871 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9516 is 0.07219861916735827 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9517 is 0.07219835810979815 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9518 is 0.07219821381342637 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9519 is 0.07219755751332362 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9520 is 0.07219695340794159 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9521 is 0.07219646936724337 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9522 is 0.07219596021657503 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9523 is 0.07219587089571558 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9524 is 0.072195782010866 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9525 is 0.07219494054650648 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9526 is 0.0721944928670275 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9527 is 0.07219444444411083 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9528 is 0.07219378346353952 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9529 is 0.07219320665695565 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9530 is 0.07219269864577527 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9531 is 0.07219220729721802 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9532 is 0.07219198244501447 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9533 is 0.07219180441543092 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9534 is 0.07219114916356502 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9535 is 0.0721905473161669 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9536 is 0.07219003459323448 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9537 is 0.07218956852726316 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9538 is 0.07218959399030282 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9539 is 0.07218894636701843 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9540 is 0.07218837721238933 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9541 is 0.07218788559143707 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9542 is 0.07218754474521866 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9543 is 0.07218779180649001 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9544 is 0.07218686767808621 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9545 is 0.07218631706674655 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9546 is 0.07218586303446539 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9547 is 0.07218578992267327 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9548 is 0.0721851597198253 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9549 is 0.07218464047370023 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9550 is 0.07218414246072886 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9551 is 0.0721836444633776 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9552 is 0.07218334823627734 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9553 is 0.07218318302237359 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9554 is 0.07218254195243977 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9555 is 0.07218198773859934 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9556 is 0.07218150628887267 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9557 is 0.07218117045404239 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9558 is 0.07218113361128538 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9559 is 0.07218047166952832 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9560 is 0.07217986387401258 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9561 is 0.07217935403669228 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9562 is 0.07217888272026157 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9563 is 0.07217914536891991 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9564 is 0.07217839287730025 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9565 is 0.07217789876023867 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9566 is 0.07217777577451474 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9567 is 0.0721771311646014 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9568 is 0.07217662194226768 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9569 is 0.07217610523630046 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9570 is 0.07217562580507556 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9571 is 0.0721751220298262 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9572 is 0.07217508212700294 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9573 is 0.07217473013863489 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9574 is 0.0721740821204326 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9575 is 0.07217348458687538 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9576 is 0.07217298998132504 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9577 is 0.0721726658191013 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9578 is 0.07217254853826874 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9579 is 0.07217190514269509 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9580 is 0.07217135257675254 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9581 is 0.07217085231249414 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9582 is 0.07217068351046038 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9583 is 0.07217099817681158 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9584 is 0.07216985448787817 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9585 is 0.07216934727081917 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9586 is 0.07216934702797911 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9587 is 0.07216868762629998 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9588 is 0.07216811428639598 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9589 is 0.0721676466997022 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9590 is 0.07216712436193178 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9591 is 0.07216692151043029 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9592 is 0.07216673802029654 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9593 is 0.07216608640341117 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9594 is 0.07216549011353986 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9595 is 0.07216502082016328 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9596 is 0.07216452648046663 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9597 is 0.07216455659628093 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9598 is 0.07216391304908759 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9599 is 0.07216338809168978 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9600 is 0.07216287896349356 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9601 is 0.07216253516090733 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9602 is 0.07216304094529435 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9603 is 0.07216188829955 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9604 is 0.07216134343625968 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9605 is 0.07216088107195417 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9606 is 0.0721608124686482 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9607 is 0.07216018369795721 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9608 is 0.07215969448214313 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9609 is 0.07215917560876084 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9610 is 0.07215874779842764 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9611 is 0.0721588018425419 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9612 is 0.07215814167752865 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9613 is 0.07215753874000141 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9614 is 0.07215707604817374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9615 is 0.07215655720792943 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9616 is 0.07215642333386493 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9617 is 0.07215619841109149 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9618 is 0.07215557795335528 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9619 is 0.07215509033868772 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9620 is 0.07215508863074395 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9621 is 0.07215443562512394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9622 is 0.07215386570201202 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9623 is 0.0721533848011087 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9624 is 0.0721528821539832 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9625 is 0.07215268175910855 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9626 is 0.07215250125387747 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9627 is 0.07215185275746404 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9628 is 0.07215126196741017 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9629 is 0.07215077658537629 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9630 is 0.07215032283772242 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9631 is 0.07215033738363745 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9632 is 0.07214969685238569 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9633 is 0.07214915622614133 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9634 is 0.07214866886692022 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9635 is 0.07214833032173797 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9636 is 0.07214835917297759 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9637 is 0.072147669621259 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9638 is 0.0721471271182815 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9639 is 0.07214671415343825 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9640 is 0.07214662574910088 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9641 is 0.07214600131055444 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9642 is 0.07214549041856941 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9643 is 0.07214499900302662 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9644 is 0.0721445765076181 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9645 is 0.07214463195163034 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9646 is 0.07214397458591111 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9647 is 0.07214337582751805 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9648 is 0.07214288956236974 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9649 is 0.07214240014180294 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9650 is 0.07214227548992679 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9651 is 0.07214204369810949 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9652 is 0.07214139707201302 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9653 is 0.07214080194113276 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9654 is 0.07214031198377904 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9655 is 0.07213999639592064 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9656 is 0.07213985194637099 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9657 is 0.07213922116745683 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9658 is 0.07213871414309957 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9659 is 0.0721381891563862 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9660 is 0.07213786211209121 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9661 is 0.07213823488532888 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9662 is 0.0721372544159436 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9663 is 0.07213688737027865 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9664 is 0.07213670197179703 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9665 is 0.07213606078654958 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9666 is 0.07213552587465191 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9667 is 0.07213505021712795 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9668 is 0.0721345465118434 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9669 is 0.07213424279953581 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9670 is 0.07213412946635318 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9671 is 0.07213349301986723 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9672 is 0.07213294018499081 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9673 is 0.07213247526432202 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9674 is 0.07213217597967202 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9675 is 0.07213213219314554 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9676 is 0.07213147726498893 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9677 is 0.07213087758403497 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9678 is 0.07213037469109823 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9679 is 0.07212999039261472 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9680 is 0.07213018682732256 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9681 is 0.07212944067389634 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9682 is 0.07212904736526089 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9683 is 0.07212885922346987 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9684 is 0.07212822606947271 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9685 is 0.07212771838363376 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9686 is 0.07212721935336239 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9687 is 0.07212674200572962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9688 is 0.07212638508850817 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9689 is 0.07212629951147857 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9690 is 0.0721256647599474 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9691 is 0.0721251422566299 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9692 is 0.0721246553167249 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9693 is 0.07212435273601313 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9694 is 0.0721243115815054 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9695 is 0.07212365812869374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9696 is 0.07212305998253941 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9697 is 0.0721225860516305 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9698 is 0.07212215505554671 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9699 is 0.07212231198802502 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9700 is 0.07212164603952453 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9701 is 0.07212118715655616 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9702 is 0.07212106909992565 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9703 is 0.07212043440281096 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9704 is 0.0721199323228074 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9705 is 0.07211942829875034 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9706 is 0.07211895809375887 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9707 is 0.07211855466953943 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9708 is 0.07211851354449483 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9709 is 0.0721178792889749 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9710 is 0.07211736546636777 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9711 is 0.07211687277061594 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9712 is 0.07211654764084105 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9713 is 0.07211653286415 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9714 is 0.07211588033604271 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9715 is 0.07211528331068823 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9716 is 0.07211481866949865 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9717 is 0.07211435806372091 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9718 is 0.07211441979150975 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9719 is 0.07211388331798803 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9720 is 0.07211340447038762 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9721 is 0.07211330346773964 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9722 is 0.07211267090464919 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9723 is 0.07211217630497528 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9724 is 0.07211166749142503 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9725 is 0.07211120471821854 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9726 is 0.07211078235284557 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9727 is 0.07211075766099993 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9728 is 0.07211012466545905 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9729 is 0.07210961887352837 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9730 is 0.07210912196867456 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9731 is 0.07210879454830067 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9732 is 0.07210878556623741 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9733 is 0.07210813428625007 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9734 is 0.0721075386126609 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9735 is 0.07210708144788561 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9736 is 0.07210661280523488 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9737 is 0.0721066352285235 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9738 is 0.07210600134263656 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9739 is 0.07210550509039194 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9740 is 0.07210498864297674 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9741 is 0.07210475029747575 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9742 is 0.07210526575818432 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9743 is 0.07210404671129961 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9744 is 0.07210351302699987 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9745 is 0.07210316336400126 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9746 is 0.07210314075082358 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9747 is 0.07210248684064512 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9748 is 0.07210190547643167 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9749 is 0.07210139612471458 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9750 is 0.07210099627732801 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9751 is 0.07210100819571469 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9752 is 0.07210037268819156 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9753 is 0.07209982127471123 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9754 is 0.07209936459129715 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9755 is 0.07209901348759565 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9756 is 0.07209904061179498 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9757 is 0.07209838926901119 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9758 is 0.07209779413663596 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9759 is 0.07209729770762638 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9760 is 0.07209689802400919 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9761 is 0.07209716533657813 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9762 is 0.07209637061013575 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9763 is 0.07209593049953039 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9764 is 0.07209583662836841 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9765 is 0.07209520307504332 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9766 is 0.07209468096818379 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9767 is 0.07209420582413563 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9768 is 0.07209371609840111 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9769 is 0.07209338316389981 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9770 is 0.07209331288501047 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9771 is 0.07209268245639035 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9772 is 0.07209214718937923 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9773 is 0.07209168351225549 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9774 is 0.07209140025306349 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9775 is 0.072091360515359 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9776 is 0.07209071178038962 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9777 is 0.07209011895212124 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9778 is 0.07208963317630583 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9779 is 0.07208928160796178 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9780 is 0.07208929091761383 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9781 is 0.0720887118249354 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9782 is 0.0720883242776022 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9783 is 0.07208817472432681 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9784 is 0.07208754494500273 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9785 is 0.07208702822404975 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9786 is 0.07208655084837239 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9787 is 0.07208606613628171 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9788 is 0.07208578413820924 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9789 is 0.07208566171147111 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9790 is 0.07208503285551798 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9791 is 0.07208450364460481 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9792 is 0.0720840389522015 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9793 is 0.07208381404527747 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9794 is 0.07208371823520109 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9795 is 0.07208307105393635 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9796 is 0.072082479820079 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9797 is 0.07208199870196225 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9798 is 0.07208170339934677 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9799 is 0.0720815960106996 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9800 is 0.0720809663310467 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9801 is 0.0720804452684816 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9802 is 0.07207996298484896 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9803 is 0.07207985522977672 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9804 is 0.07208019754201261 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9805 is 0.07207900577007972 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9806 is 0.07207861041624053 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9807 is 0.07207856439794275 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9808 is 0.07207791744043515 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9809 is 0.07207735887634975 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9810 is 0.0720769030948741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9811 is 0.07207640274974005 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9812 is 0.07207641061996303 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9813 is 0.07207607047520048 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9814 is 0.07207543285324787 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9815 is 0.07207485531682539 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9816 is 0.07207445511039488 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9817 is 0.07207454415886852 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9818 is 0.0720738903237239 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9819 is 0.07207329544222407 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9820 is 0.07207285557303847 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9821 is 0.07207236840676991 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9822 is 0.07207291928172307 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9823 is 0.07207183777114295 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9824 is 0.07207130913877519 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9825 is 0.07207096963051435 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9826 is 0.07207092040177555 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9827 is 0.07207030106494655 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9828 is 0.07206975462223332 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9829 is 0.07206931830568883 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9830 is 0.07206893573560742 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9831 is 0.07206887451513413 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9832 is 0.07206824773760871 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9833 is 0.07206776208494947 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9834 is 0.07206727171911656 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9835 is 0.07206699361282924 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9836 is 0.07206696395626344 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9837 is 0.07206631582480481 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9838 is 0.07206572500659691 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9839 is 0.07206527547988355 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9840 is 0.07206490188711345 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9841 is 0.07206485272277462 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9842 is 0.07206422432257015 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9843 is 0.07206373657822011 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9844 is 0.0720632253020892 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9845 is 0.07206312306840906 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9846 is 0.07206343490214075 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9847 is 0.07206230782418332 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9848 is 0.07206189363569583 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9849 is 0.07206184580220408 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9850 is 0.07206120043192304 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9851 is 0.07206065230234278 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9852 is 0.07206020924517101 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9853 is 0.07205970243116164 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9854 is 0.07205990169142482 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9855 is 0.07205924863423654 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9856 is 0.07205865590644808 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9857 is 0.07205815664389482 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9858 is 0.07205770750705202 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9859 is 0.07205764996483206 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9860 is 0.07205740489754527 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9861 is 0.07205676905259903 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9862 is 0.07205618646290014 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9863 is 0.07205580213051305 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9864 is 0.0720561186037407 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9865 is 0.07205520011038209 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9866 is 0.0720546738832708 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9867 is 0.07205436136788292 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9868 is 0.07205425774812232 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9869 is 0.07205364415886258 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9870 is 0.07205312403982134 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9871 is 0.0720526727836432 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9872 is 0.07205239491567501 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9873 is 0.07205236151545395 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9874 is 0.0720517170956441 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9875 is 0.07205113466454979 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9876 is 0.07205064043172184 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9877 is 0.0720503120341445 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9878 is 0.07205028664952753 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9879 is 0.07204965813113669 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9880 is 0.07204911200720177 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9881 is 0.07204866235992496 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9882 is 0.07204850294818037 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9883 is 0.07204835200012699 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9884 is 0.07204771182029596 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9885 is 0.07204712733147484 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9886 is 0.07204669894293783 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9887 is 0.07204721532224793 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9888 is 0.07204617501762575 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9889 is 0.07204565033616442 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9890 is 0.07204524732834874 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9891 is 0.07204520693035313 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9892 is 0.07204459387283817 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9893 is 0.07204410941643526 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9894 is 0.07204362467699538 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9895 is 0.07204334208096479 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9896 is 0.07204331902512444 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9897 is 0.07204267523380041 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9898 is 0.07204209452853741 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9899 is 0.07204163715135506 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9900 is 0.07204124635736402 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9901 is 0.0720412525892878 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9902 is 0.07204062509847275 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9903 is 0.07204011683573394 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9904 is 0.07203963171327002 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9905 is 0.07203949453866772 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9906 is 0.0720393751240152 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9907 is 0.07203870606524358 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9908 is 0.07203828830729907 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9909 is 0.07203828252655023 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9910 is 0.07203764379990314 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9911 is 0.07203709123937374 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9912 is 0.07203664302235589 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9913 is 0.07203615394159184 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9914 is 0.07203617254368046 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9915 is 0.07203584866112257 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9916 is 0.07203522238951497 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9917 is 0.07203465777262791 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9918 is 0.07203427832769124 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9919 is 0.07203437531639892 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9920 is 0.07203373102129255 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9921 is 0.07203314578587144 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9922 is 0.07203270619842882 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9923 is 0.07203229121238011 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9924 is 0.07203230709554732 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9925 is 0.07203168500330637 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9926 is 0.07203120753052995 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9927 is 0.07203070072198399 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9928 is 0.07203060488180592 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9929 is 0.07203051284713899 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9930 is 0.07202981053706789 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9931 is 0.07202941854354682 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9932 is 0.07202937451967868 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9933 is 0.0720287392255075 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9934 is 0.07202819469565393 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9935 is 0.07202776334077858 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9936 is 0.07202731518139832 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9937 is 0.07202747870993688 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9938 is 0.07202683245338361 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9939 is 0.07202625104363075 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9940 is 0.07202575436338865 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9941 is 0.07202535848933729 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9942 is 0.07202542979355785 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9943 is 0.07202480460096243 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9944 is 0.07202426036774758 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9945 is 0.07202381891284236 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9946 is 0.07202364017815306 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9947 is 0.07202353659563378 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9948 is 0.07202289981019533 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9949 is 0.0720223225492238 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9950 is 0.07202188744966855 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9951 is 0.07202218681721174 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9952 is 0.07202140037528974 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9953 is 0.07202088282649094 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9954 is 0.07202049391030241 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9955 is 0.07202047625770983 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9956 is 0.07201987433683422 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9957 is 0.07201938062570083 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9958 is 0.07201892516215384 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9959 is 0.07201863394049894 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9960 is 0.07201864609553614 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9961 is 0.07201801248279266 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9962 is 0.07201744079187342 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9963 is 0.07201696442484752 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9964 is 0.07201663485352917 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9965 is 0.07201663631356307 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9966 is 0.07201601855094056 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9967 is 0.0720154838471999 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9968 is 0.07201504410261392 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9969 is 0.07201492439939794 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9970 is 0.0720147652985476 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9971 is 0.07201413577972147 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9972 is 0.07201356195199811 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9973 is 0.07201319423325807 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9974 is 0.0720135493745183 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9975 is 0.07201263762689539 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9976 is 0.07201212152447452 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9977 is 0.07201182076780246 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9978 is 0.07201172278353969 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9979 is 0.07201111786816398 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9980 is 0.07201062781268591 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9981 is 0.07201016943073324 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9982 is 0.07200999626765212 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9983 is 0.07200989713562628 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9984 is 0.07200926344687895 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9985 is 0.07200869124693769 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9986 is 0.07200822148530746 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9987 is 0.07200801506938512 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9988 is 0.0720078934724602 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9989 is 0.07200727621384144 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9990 is 0.07200674827154066 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9991 is 0.07200630369559709 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9992 is 0.07200632967362405 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9993 is 0.07200603111167818 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9994 is 0.07200540187034887 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9995 is 0.07200482903047561 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9996 is 0.07200461314540844 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9997 is 0.07200487733798568 -------- Training accuracy = 97.0\n",
            "Cost after iteration 9998 is 0.07200391525185432 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 9999 is 0.07200349355932811 -------- Training accuracy = 96.88888888888889\n",
            "Cost after iteration 10000 is 0.07200353999080258 -------- Training accuracy = 97.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGMrrC5urNrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f4da9111-35ca-4b3d-a5c0-13bf27dfc989"
      },
      "source": [
        "#cross_val(X_cv,y_cv,parameters,print_values=True)\n",
        "test(X_te,y_te,parameters,print_values=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST RESULTS: \n",
            "Testing accuracy = 99.0\n",
            "Precision: 0.9787234042553191\n",
            "Recall: 1.0\n",
            "F1 score: 0.989247311827957\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99.0, 0.9787234042553191, 1.0, 0.989247311827957)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFrS1HpMpjdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "3ad65fac-d906-4582-81b8-7fe69dfd7ca7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "itera = np.arange(1,len(costs)+1,1)\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Cost Function variation')\n",
        "plt.plot(itera,costs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6cb3b14be0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2jSaEHdpnxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "sns.set_style(\"whitegrid\")\n",
        "# boundary of the graph\n",
        "GRID_X_START = -1.5\n",
        "GRID_X_END = 2.5\n",
        "GRID_Y_START = -1.0\n",
        "GRID_Y_END = 2\n",
        "# output directory (the folder must be created on the drive)\n",
        "OUTPUT_DIR = \"/content/drive/My Drive/Colab Notebooks/moonvis_hyb\"\n",
        "grid = np.mgrid[GRID_X_START:GRID_X_END:100j,GRID_X_START:GRID_Y_END:100j]\n",
        "grid_2d = grid.reshape(2,-1)\n",
        "XX, YY = grid\n",
        "def make_plot(X, y, plot_name, file_name=None, XX=None, YY=None, preds=None, dark=False):\n",
        "    if (dark):\n",
        "        plt.style.use('dark_background')\n",
        "    else:\n",
        "        sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(16,12))\n",
        "    axes = plt.gca()\n",
        "    axes.set(xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n",
        "    plt.title(plot_name, fontsize=30)\n",
        "    plt.subplots_adjust(left=0.20)\n",
        "    plt.subplots_adjust(right=0.80)\n",
        "    if(XX is not None and YY is not None and preds is not None):\n",
        "        plt.contourf(XX, YY, preds.reshape(XX.shape), 25, alpha = 1, cmap=cm.Spectral)\n",
        "        plt.contour(XX, YY, preds.reshape(XX.shape), levels=[.5], cmap=\"Greys\", vmin=0, vmax=.6)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y.ravel(), s=40, cmap=plt.cm.Spectral, edgecolors='black')\n",
        "    if(file_name):\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "import os\n",
        "def callback_numpy_plot(index, params):\n",
        "    plot_title = \"Iteration {:05}\".format(index)\n",
        "    file_name = \"numpy_model_{:05}.png\".format(index//50)\n",
        "    file_path = os.path.join(OUTPUT_DIR, file_name)\n",
        "    out,act = forw_prop(np.transpose(grid_2d),params,act_fn)\n",
        "    prediction_probs = act[\"A\" + str(len(layer_dims)-1)]\n",
        "    prediction_probs = prediction_probs.reshape(prediction_probs.shape[1], 1)\n",
        "    make_plot(X_te, y_te, plot_title, file_name=file_path, XX=XX, YY=YY, preds=prediction_probs, dark=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaBatc_6p62v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dims_vis = layer_dims\n",
        "layer_dims_vis[0] = 2\n",
        "parameters_dat = initialize_parameters(layer_dims_vis,act_fn)\n",
        "_,params_values = fit(X_tr, y_tr, m_tr, 10000, 0.015, parameters_dat,activation_fn = act_fn,print_cost=False,callback = callback_numpy_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZW1bV68p_Gx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "outputId": "60bae3f7-75f9-4849-8db6-66ca5a488287"
      },
      "source": [
        "out,act = forw_prop(np.transpose(grid_2d),params_values,act_fn)\n",
        "prediction_probs_np = act[\"A\" + str(len(layer_dims)-1)]\n",
        "prediction_probs_np = prediction_probs_np.reshape(prediction_probs_np.shape[1], 1)\n",
        "make_plot(X_te, y_te, \"Final Iteration\", file_name=None, XX=XX, YY=YY, preds=prediction_probs_np, dark=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDkIxUOcqR56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}